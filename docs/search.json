[{"path":"index.html","id":"overview","chapter":"Overview","heading":"Overview","text":"Authors: Phil McAleerAim: Handy Workbook help students understand Research Methods Statistics worked examples self-tests.Note: book living document regularly checked updated improvements. book still development issues suggestions can emailed please Phil McAleer logged issue Github repositoryR Version: book written R version 4.1.1 (2021-08-10)Citation: McAleer, P., (2022). Handy Workbook Research Methods & Statistics (0.0.9012). Zenodo. https://doi.org/10.5281/zenodo.5934243 ","code":""},{"path":"foreword.html","id":"foreword","chapter":"Foreword","heading":"Foreword","text":"book designed help people understand statistical tests commonly taught Psychology undergraduate course walking tests step--step process.run analytical tests often employ statistical software carry tests us role, researchers, reduced inputting data correct format interpreting output. However, us understand verify software working correctly must working knowledge test used. example, t-test comes back positive negative, understanding processes involved calculation can understand happens means terms research question set. Likewise, understanding degrees freedom relate different tests can verify output software, making sure values get appropriate. whilst , researchers, rarely run full analysis hand, memory, fully understand analyses bases papers write, important know way around tests work; unwise just use analytical software blindly without grasp using output make claims human behavior.hope book helps understanding turn improves research practice. suggestions improvements book like see test added, please let us know!","code":""},{"path":"point-estimates.html","id":"point-estimates","chapter":"1 Point Estimates","heading":"1 Point Estimates","text":"","code":""},{"path":"point-estimates.html","id":"a-note-on-descriptives-and-inferentials","chapter":"1 Point Estimates","heading":"1.1 A note on Descriptives and Inferentials","text":"first part book going look descriptive statistics use summarise describe data collected - normally sample population interest. Remember population members group wish generalise findings , sample subset population gathered data . draw sample population, speak. population determine based research question - everyone Psychology Glasgow; everyone study Psychology Scotland; everyone studying Psychology world! time, testing everyone population unrealistic goal take sample population make inferences sample population using statistics. first step take describe sample.Descriptive statistics can broken three kinds:point estimates - tend single values, points, summarise set data. common ones summarise center data mean median.interval estimates - tend range values summarise set data. common ones summarise spread data variance standard deviation.visualisations - figures help display point interval estimates data can take various different forms depending data type.described data sample use inferential statistics make predictions , comparisons , data. infer general population perform based sample collected described. look inferential statistics later book first start descriptives statistics, looking point estimates first, moving interval estimates.Point EstimatesWe start looking three point estimates. :Meanthe Medianthe Mode","code":""},{"path":"point-estimates.html","id":"the-mean","chapter":"1 Point Estimates","heading":"1.2 The Mean","text":"mean descriptive statistic measures average value set numbers.symbol mean generally written \\(\\overline{X}\\) (pronounced X-bar) formula mean :\\[\\overline{X} = \\frac{\\sum_i^n{x_i}}{n}\\]reads sum (\\(\\sum\\)) values \\(\\) (first value) \\(n\\) (last value) divide number total number values (\\(n\\)). look example.Say interested years experience driving impacts metric peformance. recruit 25 participants ask many years driving. responses:\\[7, 1, 2, 6, 3, 4, 3, 4, 3, 4, 5, 4, 7, 5, 6, 5, 5, 4, 5, 6, 5, 6, 3, 2, 5\\]start fill information get:\\[\\overline{X} = \\frac{7 +\n1 +\n2+\n6+\n3+\\\\\n4+\n3+\n4+\n3+\n4+\\\\\n5+\n4+\n7+\n5+\n6+\\\\\n5+\n5+\n4+\n5+\n6+\\\\\n5+\n6+\n3+\n2+\n5}{25}\\]first step add values top half formula together, called numerator, giving us:\\[\\overline{X} =\\frac{110}{25}\\]can also read :\\[\\overline{X} = 110/25\\]divide top formula, numerator, bottom half, called denominator, get:\\[\\overline{X} = 4.4\\], using standard APA write-format M = ..., write M = 4.4.","code":""},{"path":"point-estimates.html","id":"test-yourself---the-mean","chapter":"1 Point Estimates","heading":"1.2.1 Test Yourself - The Mean","text":"5 sets data practice calculating mean . Calculate mean one answer questions see correct.DataSet 1 - \\(22, 7, 26, 1, 2, 12, 13, 26, 23, 29\\)DataSet 2 - \\(17, 26, 12, 30, 26, 15, 21, 24, 23, 26\\)DataSet 3 - \\(10, 24, 25, 10, 2, 24, 11, 4, 25, 9\\)DataSet 4 - \\(6, 5, 8, 10, 27, 10, 29, 15, 4, 9\\)DataSet 5 - \\(4, 27, 15, 19, 23, 22, 11, 16, 8, 29\\)\n\n\nmean DataSet 1? 15.216.116.816.9What mean DataSet 2? 21.6222322.2What mean DataSet 3? 13.513.914.413.4What mean DataSet 4? 12.111.912.312.8What mean DataSet 5? 17.618.417.418.3","code":""},{"path":"point-estimates.html","id":"the-median","chapter":"1 Point Estimates","heading":"1.3 The Median","text":"median next point estimate look middle number distribution half values data larger half smaller. literally value divides data half.standard way calculating Median involves two steps:Sort values lowest highest (.e. \\(\\) (first value) \\(n\\) (last value))median value position \\(\\frac{(n + 1)}{2}\\)look driving data , responses :\\[7, 1, 2, 6, 3, 4, 3, 4, 3, 4, 5, 4, 7, 5, 6, 5, 5, 4, 5, 6, 5, 6, 3, 2, 5\\]sort lowest value highest value get:\\[1, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7\\]Now need figure value median position dataset, median position \\(\\frac{(n + 1)}{2}\\) n = 25 participants.\\[Median\\space Position = \\frac{(n + 1)}{2} = \\frac{(25 + 1)}{2} = \\frac{26}{2} = 13\\]Meaning Median Position n = 25 13th position Median value position 13 sorted data smallest largest:\\[1, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7\\]count along line get Median Position, can see value position 13 5, meaning data Median = 5. , using standard APA write-format Mdn = ..., write Mdn = 5.","code":""},{"path":"point-estimates.html","id":"test-yourself---the-median","chapter":"1 Point Estimates","heading":"1.3.1 Test Yourself - The Median","text":"5 sets data practice calculating median . Calculate median one answer questions see correct.DataSet 1 - \\(7, 8, 10, 10, 7, 6, 9, 6, 7, 8, 10, 6, 10\\)DataSet 2 - \\(5, 4, 3, 1, 5, 4, 3, 3, 5, 1, 3, 3, 5, 4, 2\\)DataSet 3 - \\(18, 18, 17, 39, 39, 18, 15, 15, 18, 15, 33, 17, 18, 18, 39\\)DataSet 4 - \\(3, 4, 6, 4, 6, 6, 2, 2, 3, 6, 6\\)DataSet 5 - \\(20, 20, 10, 12, 10, 14, 12, 20, 14, 14, 14, 13\\)\n\n\nmedian DataSet 1? 897.58.5What median DataSet 2? 3.522.53What median DataSet 3? 17.5181917What median DataSet 4? 33.54.54What median DataSet 5? 13.5131414.5","code":""},{"path":"point-estimates.html","id":"the-mode","chapter":"1 Point Estimates","heading":"1.4 The Mode","text":"mode last point estimate consider value category appears often, frequently, data set. formula mode involves counting many category value finding common one. values :\\[7, 1, 2, 6, 3, 4, 3, 4, 3, 4, 5, 4, 7, 5, 6, 5, 5, 4, 5, 6, 5, 6, 3, 2, 5\\]sort largest smallest easy reading get:\\[1, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7\\]start count different values see :Meaning, example, 4 people three years driving experience, 5 people four years driving experience. looking table can see common number years driving experience 5 7 number years experience. therefore write Mode = 5","code":""},{"path":"point-estimates.html","id":"test-yourself---the-mode","chapter":"1 Point Estimates","heading":"1.4.1 Test Yourself - The Mode","text":"5 sets data practice calculating mode . Calculate mean one answer questions see correct.DataSet 1 - \\(5, 4, 3, 1, 5, 4, 3, 3, 5, 1, 3, 3, 5, 4, 2\\)DataSet 2 - \\(7, 8, 10, 10, 7, 6, 9, 6, 7, 8, 10, 6, 10\\)DataSet 3 - \\(18, 18, 17, 39, 39, 18, 15, 15, 18, 15, 33, 17, 18, 18, 39\\)DataSet 4 - \\(20, 20, 10, 12, 10, 14, 12, 20, 14, 14, 14, 13\\)DataSet 5 - \\(3, 4, 6, 4, 6, 6, 2, 2, 3, 6, 6\\)\n\n\nmode DataSet 1? 4135What mode DataSet 2? 87106What mode DataSet 3? 18391715What mode DataSet 4? 20121410What mode DataSet 5? 4326","code":""},{"path":"point-estimates.html","id":"section-glossary","chapter":"1 Point Estimates","heading":"1.5 Section glossary","text":"","code":""},{"path":"interval-estimates.html","id":"interval-estimates","chapter":"2 Interval Estimates","heading":"2 Interval Estimates","text":"far looked descriptives take whole dataset summarise center point data - point estimates - whilst useful, really tell much distribution. information aspect distribution look spread distribution - wide drv3a values data fall . look four measures spread. :RangeThe Interquartile RangeThe VarianceThe Standard DeviationIn addition, look :z-scoresStandard Error MeanConfidence Intervals","code":""},{"path":"interval-estimates.html","id":"the-range","chapter":"2 Interval Estimates","heading":"2.1 The Range","text":"Range basic least informative measure spread data really tells distance largest value smallest value data set. never really see formula range can written :\\[Range(X) = max(X) - min(X)\\]\nread maximum value dataset (\\(max(X)\\)) minus minimum value dataset (\\(min(X)\\)). look driving data :\\[7, 1, 2, 6, 3, 4, 3, 4, 3, 4, 5, 4, 7, 5, 6, 5, 5, 4, 5, 6, 5, 6, 3, 2, 5\\]\ncan see largest value 7 smallest value 1, put formula get:\\[Range(X) = max(X) - min(X) = 7 - 1 = 6\\]\nMeaning dataset range Range = 6. worth pointing matter many people largest value smallest value matter, just smallest largest values.range however can deceptive heavily influenced outliers. Look data example:\\[7, 1, 2, 6, 3, 4, 3, 4, 3, 4, 5, 4, 30, 5, 6, 5, 5, 4, 5, 6, 5, 6, 3, 2, 5\\]\ncan see largest value 30 smallest value 1, put formula get:\\[Range(X) = max(X) - min(X) = 30 - 1 = 29\\]Meaning dataset range Range = 29 probably really reflect spread data well one data point really large. range informative state great analyses .","code":""},{"path":"interval-estimates.html","id":"test-yourself---range","chapter":"2 Interval Estimates","heading":"2.1.1 Test Yourself - Range","text":"DataSet1: \\(5, 4, 3, 1, 5, 4, 3, 3, 5, 1, 3, 3, 5, 4, 2\\)range Dataset1: 354","code":""},{"path":"interval-estimates.html","id":"variance","chapter":"2 Interval Estimates","heading":"2.2 Variance","text":"symbol variance generally written \\(s^2\\) (pronounced sigma-squared) can also written \\(Var\\). formula variance :\\[s^2 = \\frac{\\sum_i^n(x_{} - \\overline{x})^2}{n-1}\\]use data keep bit simple just using first 10 participants:\\[7, 1, 2, 6, 3, 4, 3, 4, 3, 4\\]start filling numbers formula:\\[s^2 = \\frac{(7 - 3.7)^2 + (1 - 3.7)^2 + (2 - 3.7)^2 + (6 - 3.7)^2 + (3 - 3.7)^2 + \\\\(4 - 3.7)^2 + (3 - 3.7)^2 + (4 - 3.7)^2 + (3 - 3.7)^2 + (4 - 3.7)^2}{10 - 1}\\]subtractions brackets top half one bottom:\\[s^2 = \\frac{(3.3)^2 + (-2.7)^2 + (-1.7)^2 + (2.3)^2 + (-0.7)^2 + \\\\(0.3)^2 + (-0.7)^2 + (0.3)^2 + (-0.7)^2 + (0.3)^2}{9}\\]square values top half:\\[s^2 = \\frac{10.89 + 7.29+ 2.89+ 5.29+ 0.49+ 0.09+ 0.49+ 0.09+ 0.49+ 0.09}{9}\\]Sum values together:\\[s^2 = \\frac{28.1}{9}\\]divide top half bottom half:\\[s^2 = 3.1222222\\]Showing variance, rounded two decimal places, \\(s^2 = 3.12\\)","code":""},{"path":"interval-estimates.html","id":"standard-deviation","chapter":"2 Interval Estimates","heading":"2.3 Standard Deviation","text":"symbol standard deviation generally written \\(s\\) (pronounced sigma) can also written \\(SD\\). formula standard deviation :\\[s = \\sqrt\\frac{\\sum_i^n(x_{} - \\overline{x})^2}{n-1}\\]start filling numbers formula:\\[s = \\sqrt\\frac{(7 - 3.7)^2 + (1 - 3.7)^2 + (2 - 3.7)^2 + (6 - 3.7)^2 + (3 - 3.7)^2 + \\\\(4 - 3.7)^2 + (3 - 3.7)^2 + (4 - 3.7)^2 + (3 - 3.7)^2 + (4 - 3.7)^2}{10 - 1}\\]subtractions brackets top half one bottom:\\[s = \\sqrt\\frac{(3.3)^2 + (-2.7)^2 + (-1.7)^2 + (2.3)^2 + (-0.7)^2 + \\\\(0.3)^2 + (-0.7)^2 + (0.3)^2 + (-0.7)^2 + (0.3)^2}{9}\\]square values top half:\\[s = \\sqrt\\frac{10.89 + 7.29+ 2.89+ 5.29+ 0.49+ 0.09+ 0.49+ 0.09+ 0.49+ 0.09}{9}\\]Sum values together:\\[s = \\sqrt\\frac{28.1}{9}\\]\nDivide top half bottom half:\\[s = \\sqrt{3.1222222}\\]finally take square root:\\[s = 1.7669811\\]find standard deviation, rounded two decimal places, \\(s = 1.77\\)","code":""},{"path":"interval-estimates.html","id":"var-to-sd","chapter":"2 Interval Estimates","heading":"2.3.1 Var to SD","text":"Remembering standard deviation square root variance, know variance (\\(s^2\\)) need standard deviation (\\(s\\)) can :\\[s = \\sqrt{s^2}\\]example, \\(s^2 = 3.1222222\\) \\[s = \\sqrt{3.1222222}\\]giving:\\[s = 1.7669811\\]","code":""},{"path":"interval-estimates.html","id":"sd-to-var","chapter":"2 Interval Estimates","heading":"2.3.2 SD to Var","text":"Sometimes need go standard deviation variance, remembering variance standard deviation squared, standard deviation multiplied , can :\\[s^2 = s \\times s\\]know standard deviation example \\(s = 1.7669811\\) :\\[s^2 = 1.7669811 \\times 1.7669811\\]giving us:\\[s^2 = 3.1222222\\]","code":""},{"path":"interval-estimates.html","id":"z-scores","chapter":"2 Interval Estimates","heading":"2.4 z-scores","text":"value continuous scale can converted z-score (standard deviation units) formula:\\[z = \\frac{x - \\overline{x}}{s_{x}}\\]can read value (\\(x\\)) minus mean value data (\\(\\overline{x}\\)), divided standard deviation data (\\(s_{X}\\)). example, look Participant 1:\\(x = 7\\)\\(\\overline{x} = 3.7\\)\\(s_{x} = 1.7669811\\)fill formula get:\\[z = \\frac{7 - 3.7}{1.7669811}\\]sort top half first:\\[z = \\frac{3.3}{1.7669811}\\]Leaving us :\\[z = 1.8675921\\]Participant 1, converted z-score rounded two decimal places, z = 1.87","code":""},{"path":"interval-estimates.html","id":"test-yourself---z-scores","chapter":"2 Interval Estimates","heading":"2.4.1 Test Yourself - z-scores","text":"12 expressed z-score, assuming sample following values, M = 15, SD = 1.5: -21.24-1.67What 8 expressed z-score, assuming sample following values, M = 10, SD = 2: 0.94-1-1.67What 31 expressed z-score, assuming sample following values, M = 28, SD = 3.2: 1.24-20.94What 21.2 expressed z-score, assuming sample following values, M = 19.1, SD = 1.7: 1.24-1-2What 3.8 expressed z-score, assuming sample following values, M = 4, SD = 0.12: -1.67-11.24","code":""},{"path":"interval-estimates.html","id":"standard-error-of-the-mean","chapter":"2 Interval Estimates","heading":"2.5 Standard Error of the Mean","text":"symbol standard error usually \\(SE\\) can also written \\(SEM\\) specificaly mean - short standard error mean. formula standard error standard deviation (\\(s\\)) divided square root number observations (\\(\\sqrt{n}\\)), written :\\[SE = \\frac{s}{\\sqrt{n}}\\]can also written :\\[SE = \\frac{SD}{\\sqrt{n}}\\]know \\(SD = 1.7669811\\) \\(n = 10\\) participants, :\\[SE = \\frac{1.7669811}{\\sqrt{10}}\\]square root bottom half (denominator):\\[SE = \\frac{1.7669811}{3.1622777}\\]divide top bottom:\\[SE = 0.5587685\\]find standard error, rounded two decimal places, \\(SE = 0.56\\)","code":""},{"path":"interval-estimates.html","id":"test-yourself---standard-error","chapter":"2 Interval Estimates","heading":"2.5.1 Test Yourself - Standard Error","text":"Dataset1: SD = 10.44, N = 10Dataset2: SD = 5.7, N = 10Dataset3: SD = 9.13, N = 10Dataset4: SD = 8.84, N = 10Dataset5: SD = 8.15, N = 10What SEM Dataset1? 1.543.233.35.09What SEM Dataset2? 1.82.822.394.69What SEM Dataset3? 2.891.761.893.79What SEM Dataset4? 1.822.81.923.51What SEM Dataset5? 4.172.581.982","code":""},{"path":"interval-estimates.html","id":"confidence-intervals","chapter":"2 Interval Estimates","heading":"2.6 Confidence Intervals","text":"specifically focus 95% Confidence Interval using cut-value (assuming \\(\\alpha = .05\\) two-tailed) \\(z = 1.96\\). key formulas :\\[Upper \\space 95\\%CI = \\overline{x} + (z \\times SE)\\]\\[Lower \\space 95\\%CI = \\overline{x} - (z \\times SE)\\]know :\\(\\overline{x} = 3.7\\)\\(SE = 0.5587685\\)\\(z = 1.96\\)Upper 95% CIDealing Upper 95% CI get:\\[Upper \\space 95\\%CI = 3.7 + (1.96 \\times 0.5587685)\\]sort bracket first:\\[Upper \\space 95\\%CI = 3.7 + 1.0951862\\]leaves us :\\[Upper \\space 95\\%CI = 4.7951862\\]Lower 95% CIAnd now Lower 95% CI get:\\[Lower \\space 95\\%CI = 3.7 - (1.96 \\times 0.5587685)\\]sort bracket first:\\[Lower \\space 95\\%CI = 3.7 - 1.0951862\\]leaves us :\\[Lower \\space 95\\%CI = 2.6048138\\]round values two decimal places, get Lower 95%CI = 2.6 $Upper 95%CI = 4.8. often see Confidence Intervals written 95%CI = [LowerCI, UpperCI], summarise values , 95%CI = [2.6, 4.8].","code":""},{"path":"interval-estimates.html","id":"test-yourself---95-confidence-intervals","chapter":"2 Interval Estimates","heading":"2.6.1 Test Yourself - 95% Confidence Intervals","text":"Means Standard Errors 5 datasets.Dataset 1: M = 16.1, SE = 3.3What Upper 95% CI DataSet 1? 9.6327.93222.56828.468What Lower 95% CI DataSet 1? 9.63222.5687.93228.468Dataset 2: M = 22, SE = 1.8What Upper 95% CI DataSet 2? 25.5289.6327.93218.768What Lower 95% CI DataSet 2? 22.56818.4727.93218.768Dataset 3: M = 14.4, SE = 2.89What Upper 95% CI DataSet 3? 28.46820.06449.63210.932What Lower 95% CI DataSet 3? 10.9328.735628.46822.568Dataset 4: M = 12.3, SE = 2.8What Upper 95% CI DataSet 4? 7.93228.46817.78810.932What Lower 95% CI DataSet 4? 6.8127.93223.86828.468Dataset 5: M = 17.4, SE = 2.58What Upper 95% CI DataSet 5? 22.456822.5685.8327.932What Lower 95% CI DataSet 5? 18.76822.5687.93212.3432","code":""},{"path":"a-full-descriptive.html","id":"a-full-descriptive","chapter":"3 A full descriptive","heading":"3 A full descriptive","text":"look full descriptive example including mean, standard deviation, standard error, 95% Confidence Intervals, z-scores, use following data 10 participants:","code":""},{"path":"a-full-descriptive.html","id":"the-mean-1","chapter":"3 A full descriptive","heading":"3.0.1 The Mean","text":"know formula mean :\\[\\overline{X} = \\frac{\\sum_i^n{x_i}}{n}\\]start fill information get:\\[\\overline{X} = \\frac{8 + 11 + 6 +3 +1 +6 +1 +0 +1 +4}{10}\\]sum values top half together get:\\[\\overline{X} = \\frac{41}{10}\\]finally divide top half bottom half, leaving:\\[\\overline{X} = 4.1\\]find mean, rounded two decimal places, \\(\\overline{X} = 4.1\\)","code":""},{"path":"a-full-descriptive.html","id":"standard-deviation-1","chapter":"3 A full descriptive","heading":"3.0.2 Standard Deviation","text":"Next want interval estimate, commonly standard deviation. formula standard deviation :\\[s = \\sqrt\\frac{\\sum_i^n(x_{} - \\overline{x})^2}{n-1}\\]\nstart filling numbers formula:\\[s = \\sqrt\\frac{(8 - 4.1)^2 + (11 - 4.1)^2 + (6 - 4.1)^2 + (3 - 4.1)^2 + (1 - 4.1)^2 + \\\\(6 - 4.1)^2 + (1 - 4.1)^2 + (0 - 4.1)^2 + (1 - 4.1)^2 + (4 - 4.1)^2}{10 - 1}\\]subtractions brackets top half one bottom:\\[s = \\sqrt\\frac{(3.9)^2 + (6.9)^2 + (1.9)^2 + (-1.1)^2 + (-3.1)^2 + \\\\(1.9)^2 + (-3.1)^2 + (-4.1)^2 + (-3.1)^2 + (-0.1)^2}{9}\\]square values top half:\\[s = \\sqrt\\frac{15.21 + 47.61+ 3.61+ 1.21+ 9.61+ 3.61+ 9.61+ 16.81+ 9.61+ 0.01}{9}\\]Sum values together:\\[s = \\sqrt\\frac{116.9}{9}\\]\nDivide top half bottom half:\\[s = \\sqrt{12.9888889}\\]finally take square root:\\[s = 3.6040101\\]find standard deviation, rounded two decimal places, \\(s = 3.6\\)","code":""},{"path":"a-full-descriptive.html","id":"standard-error-of-the-mean-1","chapter":"3 A full descriptive","heading":"3.0.3 Standard Error of the Mean","text":"also want include measure sample relates population interest can use Standard Error Mean 95% Confidence Intervals. formula standard error can written :\\[SE = \\frac{SD}{\\sqrt{n}}\\]know \\(SD = 3.6040101\\) \\(n = 10\\) participants, :\\[SE = \\frac{3.6040101}{\\sqrt{10}}\\]square root bottom half (denominator):\\[SE = \\frac{3.6040101}{3.1622777}\\]divide top bottom:\\[SE = 1.1396881\\]find standard error, rounded two decimal places, \\(SE = 1.14\\)","code":""},{"path":"a-full-descriptive.html","id":"confidence-intervals-1","chapter":"3 A full descriptive","heading":"3.0.4 Confidence Intervals","text":"can use standard error calculate Upper Lower 95% Confidence Intervals using cut-value (assuming \\(\\alpha = .05\\) two-tailed) \\(z = 1.96\\). key formulas :\\[Upper \\space 95\\%CI = \\overline{x} + (z \\times SE)\\]\\[Lower \\space 95\\%CI = \\overline{X} - (z \\times SE)\\]know :\\(\\overline{x} = 4.1\\)\\(SE = 1.1396881\\)\\(z = 1.96\\)Upper 95% CIDealing Upper 95% CI get:\\[Upper \\space 95\\%CI = 4.1 + (1.96 \\times 1.1396881)\\]sort bracket first:\\[Upper \\space 95\\%CI = 4.1 + 2.2337886\\]leaves us :\\[Upper \\space 95\\%CI = 6.3337886\\]Lower 95% CIAnd now Lower 95% CI get:\\[Lower \\space 95\\%CI = 4.1 - (1.96 \\times 1.1396881)\\]sort bracket first:\\[Lower \\space 95\\%CI = 4.1 - 2.2337886\\]leaves us :\\[Lower \\space 95\\%CI = 1.8662114\\]round values two decimal places, get Lower 95%CI = 1.87 Upper 95%CI = 6.33","code":""},{"path":"a-full-descriptive.html","id":"the-write-up","chapter":"3 A full descriptive","heading":"3.0.5 The Write-Up","text":"decent presentation data, including measure central tendency (mean), measure spread relating sample (standard deviation), measure spread relating population (95% CI), start something like: \"ran 10 participants (M = 4.1, SD = 3.6, 95%CI = [1.87, 6.33]).....\"","code":""},{"path":"one-sample-chi-square.html","id":"one-sample-chi-square","chapter":"4 One-Sample Chi-Square","heading":"4 One-Sample Chi-Square","text":"","code":""},{"path":"one-sample-chi-square.html","id":"the-worked-example","chapter":"4 One-Sample Chi-Square","heading":"4.1 The Worked Example","text":"data:add column showing total number participants, adding numbers different conditions together, (.e. 4 + 5 + 8 + 15 = 32), get:Now formula chi-square :\\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\]Expected values condition, one-sample chi-square assuming uniform (equal) distribution calculated \\(N \\times \\frac{1}{k}\\) \\(k\\) number conditions \\(N\\) total number participants. can also written straightforward \\(N/k\\). means example expected value condition :\\[Expected = \\frac{N}{k} = \\frac{32}{4} = 8\\]now add Expected values table looks like:now data, start putting formula, said :\\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\]really means:\\[\\chi^2 = \\frac{(Observed_{} - Expected_{})^2}{Expected_{}} + \\frac{(Observed_{B} - Expected_{B})^2}{Expected_{B}} +  \\frac{(Observed_{C} - Expected_{C})^2}{Expected_{C}} + \\\\ \\frac{(Observed_{D} - Expected_{D})^2}{Expected_{D}}\\]\\[\\chi^2 = \\frac{(4 - 8)^2}{8}+\\frac{(5 - 8)^2}{8}+\\frac{(8 - 8)^2}{8}+\\frac{(15 - 8)^2}{8}\\]becomes:\\[\\chi^2 = \\frac{(-4)^2}{8} + \\frac{(-3)^2}{8} + \\frac{(0)^2}{8} + \\frac{(7)^2}{8}\\]now square top halves (numerators):\\[\\chi^2 = \\frac{16}{8} + \\frac{9}{8} + \\frac{0}{8} + \\frac{49}{8}\\]divide top half bottom half condition:\\[\\chi^2 = {2}+{1.125}+{0}+{6.125}\\]\nfinally add altogether\\[\\chi^2 = 9.25\\]find \\(\\chi^2 = 9.25\\)degrees freedom test \\(k - 1\\) given 4 conditions:\\[df = k - 1\\]\n\\[df = 4 - 1\\]\n\\[df = 3\\]effect sizeA common effect size one-sample chi-square test \\(\\phi\\) (pronounced \"ph-aye\" can written \"phi\"). formula \\(\\phi\\) :\\[\\phi = \\sqrt\\frac{\\chi^2}{N}\\]know \\(\\chi^2 =9.25\\) \\(N = 32\\), putting formula get:\\[\\phi = \\sqrt\\frac{9.25}{32}\\]\\[\\phi = 0.5376453\\]write-upIf look critical value look-table, see critical value associated \\(df = 3\\) \\(\\alpha = .05\\), three decimal places, \\(\\chi^2_{crit} = 7.815\\). chi-square value test (.e. \\(\\chi^2 = 9.25\\)) larger \\(\\chi^2_{crit}\\) can say test significant, written \\(\\chi^2(df = 3, N = 32) = 9.25,p < .05\\).Finally, test significant need state condition highest frequency (.e. mode), case Condition D","code":""},{"path":"one-sample-chi-square.html","id":"test-yourself","chapter":"4 One-Sample Chi-Square","heading":"4.2 Test Yourself","text":"","code":""},{"path":"one-sample-chi-square.html","id":"dataset-1","chapter":"4 One-Sample Chi-Square","heading":"4.2.1 DataSet 1","text":"data:add column showing total number participants, adding numbers different conditions together, (.e. 6 + 0 + 1 + 11 = 18), get:Now formula chi-square :\\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\]Expected values condition, one-sample chi-square assuming uniform (equal) distribution calculated \\(N \\times \\frac{1}{k}\\) \\(k\\) number conditions \\(N\\) total number participants. can also written straightforward \\(N/k\\). means example expected value condition :\\[Expected = \\frac{N}{k} = \\frac{18}{4} = 4.5\\]now add Expected values table looks like:now data, start putting formula, said :\\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\]\\[\\chi^2 = \\frac{(6 - 4.5)^2}{4.5}+\\frac{(0 - 4.5)^2}{4.5}+\\frac{(1 - 4.5)^2}{4.5}+\\frac{(11 - 4.5)^2}{4.5}\\]becomes:\\[\\chi^2 = \\frac{(1.5)^2}{4.5} + \\frac{(-4.5)^2}{4.5} + \\frac{(-3.5)^2}{4.5} + \\frac{(6.5)^2}{4.5}\\]now square top halves (numerators):\\[\\chi^2 = \\frac{2.25}{4.5} + \\frac{20.25}{4.5} + \\frac{12.25}{4.5} + \\frac{42.25}{4.5}\\]divide top half bottom half condition:\\[\\chi^2 = {0.5}+{4.5}+{2.7222222}+{9.3888889}\\]\nfinally add altogether\\[\\chi^2 = 17.1111111\\]find \\(\\chi^2 = 17.1111111\\)degrees freedom test \\(k - 1\\) given 4 conditions:\\[df = k - 1\\]\n\\[df = 4 - 1\\]\n\\[df = 3\\]effect sizeA common effect size one-sample chi-square test \\(\\phi\\) (pronounced \"ph-aye\" can written \"phi\"). formula \\(\\phi\\) :\\[\\phi = \\sqrt\\frac{\\chi^2}{N}\\]know \\(\\chi^2 =17.1111111\\) \\(N = 18\\), putting formula get:\\[\\phi = \\sqrt\\frac{17.1111111}{18}\\]\\[\\phi = 0.974996\\]write-upIf look critical value look-table, see critical value associated \\(df = 3\\) \\(\\alpha = .05\\), three decimal places, \\(\\chi^2_{crit} = 7.815\\). chi-square value test (.e. \\(\\chi^2 = 17.1111111\\)) larger \\(\\chi^2_{crit}\\) can say test significant, written \\(\\chi^2(df = 3, N = 18) = 17.1111111,p < .05\\).Finally, test significant need state condition highest frequency (.e. mode), case Condition D","code":""},{"path":"one-sample-chi-square.html","id":"dataset-2","chapter":"4 One-Sample Chi-Square","heading":"4.2.2 DataSet 2","text":"data:add column showing total number participants, adding numbers different conditions together, (.e. 12 + 16 + 11 + 14 = 53), get:Now formula chi-square :\\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\]Expected values condition, one-sample chi-square assuming uniform (equal) distribution calculated \\(N \\times \\frac{1}{k}\\) \\(k\\) number conditions \\(N\\) total number participants. can also written straightforward \\(N/k\\). means example expected value condition :\\[Expected = \\frac{N}{k} = \\frac{53}{4} = 13.25\\]now add Expected values table looks like:now data, start putting formula, said :\\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\]\\[\\chi^2 = \\frac{(12 - 13.25)^2}{13.25}+\\frac{(16 - 13.25)^2}{13.25}+\\frac{(11 - 13.25)^2}{13.25}+\\frac{(14 - 13.25)^2}{13.25}\\]becomes:\\[\\chi^2 = \\frac{(-1.25)^2}{13.25} + \\frac{(2.75)^2}{13.25} + \\frac{(-2.25)^2}{13.25} + \\frac{(0.75)^2}{13.25}\\]now square top halves (numerators):\\[\\chi^2 = \\frac{1.5625}{13.25} + \\frac{7.5625}{13.25} + \\frac{5.0625}{13.25} + \\frac{0.5625}{13.25}\\]divide top half bottom half condition:\\[\\chi^2 = {0.1179245}+{0.5707547}+{0.3820755}+{0.0424528}\\]\nfinally add altogether\\[\\chi^2 = 1.1132075\\]find \\(\\chi^2 = 1.1132075\\)degrees freedom test \\(k - 1\\) given 4 conditions:\\[df = k - 1\\]\n\\[df = 4 - 1\\]\n\\[df = 3\\]effect sizeA common effect size one-sample chi-square test \\(\\phi\\) (pronounced \"ph-aye\" can written \"phi\"). formula \\(\\phi\\) :\\[\\phi = \\sqrt\\frac{\\chi^2}{N}\\]know \\(\\chi^2 =1.1132075\\) \\(N = 53\\), putting formula get:\\[\\phi = \\sqrt\\frac{1.1132075}{53}\\]\\[\\phi = 0.1449273\\]write-upIf look critical value look-table, see critical value associated \\(df = 3\\) \\(\\alpha = .05\\), three decimal places, \\(\\chi^2_{crit} = 7.815\\). chi-square value test (.e. \\(\\chi^2 = 1.1132075\\)) smaller \\(\\chi^2_{crit}\\) can say test non-significant, written \\(\\chi^2(df = 3, N = 53) = 1.1132075,p > .05\\).Finally, test significant need state condition highest frequency (.e. mode), case Condition B","code":""},{"path":"one-sample-chi-square.html","id":"dataset-3","chapter":"4 One-Sample Chi-Square","heading":"4.2.3 DataSet 3","text":"data:add column showing total number participants, adding numbers different conditions together, (.e. 20 + 9 + 19 + 1 = 49), get:Now formula chi-square :\\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\]Expected values condition, one-sample chi-square assuming uniform (equal) distribution calculated \\(N \\times \\frac{1}{k}\\) \\(k\\) number conditions \\(N\\) total number participants. can also written straightforward \\(N/k\\). means example expected value condition :\\[Expected = \\frac{N}{k} = \\frac{49}{4} = 12.25\\]now add Expected values table looks like:now data, start putting formula, said :\\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\]\\[\\chi^2 = \\frac{(20 - 12.25)^2}{12.25}+\\frac{(9 - 12.25)^2}{12.25}+\\frac{(19 - 12.25)^2}{12.25}+\\frac{(1 - 12.25)^2}{12.25}\\]becomes:\\[\\chi^2 = \\frac{(7.75)^2}{12.25} + \\frac{(-3.25)^2}{12.25} + \\frac{(6.75)^2}{12.25} + \\frac{(-11.25)^2}{12.25}\\]now square top halves (numerators):\\[\\chi^2 = \\frac{60.0625}{12.25} + \\frac{10.5625}{12.25} + \\frac{45.5625}{12.25} + \\frac{126.5625}{12.25}\\]divide top half bottom half condition:\\[\\chi^2 = {4.9030612}+{0.8622449}+{3.7193878}+{10.3316327}\\]\nfinally add altogether\\[\\chi^2 = 19.8163265\\]find \\(\\chi^2 = 19.8163265\\)degrees freedom test \\(k - 1\\) given 4 conditions:\\[df = k - 1\\]\n\\[df = 4 - 1\\]\n\\[df = 3\\]effect sizeA common effect size one-sample chi-square test \\(\\phi\\) (pronounced \"ph-aye\" can written \"phi\"). formula \\(\\phi\\) :\\[\\phi = \\sqrt\\frac{\\chi^2}{N}\\]know \\(\\chi^2 =19.8163265\\) \\(N = 49\\), putting formula get:\\[\\phi = \\sqrt\\frac{19.8163265}{49}\\]\\[\\phi = 0.6359362\\]write-upIf look critical value look-table, see critical value associated \\(df = 3\\) \\(\\alpha = .05\\), three decimal places, \\(\\chi^2_{crit} = 7.815\\). chi-square value test (.e. \\(\\chi^2 = 19.8163265\\)) larger \\(\\chi^2_{crit}\\) can say test significant, written \\(\\chi^2(df = 3, N = 49) = 19.8163265,p < .05\\).Finally, test significant need state condition highest frequency (.e. mode), case Condition ","code":""},{"path":"one-sample-chi-square.html","id":"chi-square-chi2-look-up-table","chapter":"4 One-Sample Chi-Square","heading":"4.3 Chi-Square (\\(\\chi^2\\)) Look-up Table","text":"","code":""},{"path":"chi-square-cross-tabulation.html","id":"chi-square-cross-tabulation","chapter":"5 Chi-Square Cross-Tabulation","heading":"5 Chi-Square Cross-Tabulation","text":"","code":""},{"path":"chi-square-cross-tabulation.html","id":"the-worked-example-1","chapter":"5 Chi-Square Cross-Tabulation","heading":"5.1 The Worked Example","text":"data:going need know Column Totals Row Totals Total number participants (N), lets calculate add tables:Group Row Total = 88 + 93 = 181Group B Row Total = 160 + 59 = 219Yes Column Total = 88 + 160 = 248No Column Total = 93 + 59 = 152N = 88 + 93 +160 + 59 = 400And add table see:Now formula chi-square :\\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\]Expected values condition, cross-tabulation ways one use probably easiest use :\\[Expected = \\frac{Total_{row} \\times Total_{column}}{N_{total}}\\]versions might seen :\\[Expected = \\frac{Total_{row}}{N_{total}} \\times \\frac{Total_{column}}{N_{total}} \\times N_{total}\\]give result. using first approach see Expected values :Group people said Yes:\\[Expected_{-Yes} = \\frac{181 \\times 248}{400} = \\frac{44888}{400} = 112.22\\]Group people said :\\[Expected_{-} = \\frac{181 \\times 152}{400} = \\frac{27512}{400} = 68.78\\]Group B people said Yes:\\[Expected_{B-Yes} = \\frac{219 \\times 248}{400} = \\frac{54312}{400} = 135.78\\]Group B people said :\\[Expected_{B-} = \\frac{219 \\times 152}{400} = \\frac{33288}{400} = 83.22\\]now data, start putting formula, said :\\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\]really means:\\[\\chi^2 = \\frac{(Observed_{-Yes} - Expected_{-Yes})^2}{Expected_{-Yes}} + \\frac{(Observed_{-} - Expected_{-})^2}{Expected_{-}} + \\\\ \\frac{(Observed_{B-Yes} - Expected_{B-Yes})^2}{Expected_{B-Yes}} +  \\frac{(Observed_{B-} - Expected_{B-})^2}{Expected_{B-}}\\]start putting values, becomes:\\[\\chi^2 = \\frac{(88 - 112.22)^2}{112.22}+ \\frac{(93 - 68.78)^2}{68.78}+\\frac{(160 - 135.78)^2}{135.78}+\\frac{(59 - 83.22)^2}{83.22}\\]start tidy top halves little becomes:\\[\\chi^2 = \\frac{(-24.22)^2}{112.22}+ \\frac{(24.22)^2}{68.78}+\\frac{(24.22)^2}{135.78}+\\frac{(-24.22)^2}{83.22}\\]now square top halves give:\\[\\chi^2 = \\frac{586.6084}{112.22} + \\frac{586.6084}{68.78} + \\frac{586.6084}{135.78} + \\frac{586.6084}{83.22} \\]divide top halves bottom halves\\[\\chi^2 = {5.2273071} + {8.5287642} + {4.3202858} + {7.0488873}\\]sum altogether find:\\[\\chi^2 = 25.1252443 \\]Meaning , rounded two decimal places, find \\(\\chi^2 = 25.13\\)Degrees FreedomThe degrees freedom cross-tabulation calculated :\\[df = (Rows - 1) \\times (Columns - 1)\\]read number Rows minus 1 times number Columns minus 1. look original data :Looking table see 2 rows 2 columns actual observed data (looking titles group names), :\\[Rows - 1 = 2 - 1 = 1\\]\\[Columns - 1 = 2 - 1 = 1\\]Meaning :\\[df = (Rows - 1) \\times (Columns - 1)\\]becomes:\\[df = (2 - 1) \\times (2 - 1)\\]reduces :\\[df = (1) \\times (1)\\]leaving us :\\[df = 1\\]see \\(df = 1\\)effect sizeOne common effect sizes cross-tabulation chi-square test Cramer's \\(V\\) calculated :\\[V = \\sqrt\\frac{\\chi^2}{N \\times \\min(C-1, R-1)}\\]key thing note \\(\\min(C-1, R-1)\\) read minimum EITHER number Columns (C) minus 1 number Rows (R) minus 1; whichever two values smallest.minimum Columns minus 1 Rows minus 1 :\\[\\min(C-1, R-1) = \\min( 2 - 1,  2 - 1)\\]\n\\[\\min(C-1, R-1) = \\min( 1,  1)\\]\ngives us:\\[\\min(C-1, R-1) = 1\\]now can start completing Cramer's \\(V\\) formula know:\\(\\chi^2 = 25.13\\)\\(N = 400\\)\\(\\min(C-1, R-1) = 1\\)Giving us:\\[V = \\sqrt\\frac{25.13}{400 \\times 1}\\]deal bottom half first get:\\[V = \\sqrt\\frac{25.13}{400}\\]divide top bottom get\\[V = \\sqrt{0.062825}\\]Giving us:\\[V = 0.2506492\\]see , rounded two decimal places, effect size \\(V = 0.25\\)write-upIf look critical value look-table, see critical value associated \\(df = 1\\) \\(\\alpha = .05\\), three decimal places, \\(\\chi^2_{crit} = 3.841\\). chi-square value test (.e. \\(\\chi^2 = 25.13\\)) larger \\(\\chi^2_{crit}\\) can say test significant, written \\(\\chi^2(df = 1, N = 400) = 25.13,p < .05, V = 0.25\\).Following significant findingIf test significant go carry relevant one-sample chi-squares breakdown association manifests . key thing remember however one-sample chi-squares, following cross-tabulation, MUST use expected values cross-tabulation calculate new expected values.instance looking one-sample chi-square within Group , use expected values \\(Expected_{-Yes} = 112.22\\) \\(Expected_{-} = 68.78\\) compare observed values \\(Observed_{-Yes} = 88\\) \\(Observed_{-} = 93\\) :\\[\\chi^2 = \\frac{(88 - 112.22)^2}{112.22}+ \\frac{(93 - 68.78)^2}{68.78}\\]walk process find:\\[\\chi^2 = 13.7560713\\]Meaning , rounded two decimal places, find \\(\\chi^2 = 13.76\\). degrees freedom, based \\(df = k - 1\\) (one-sample chi-square now), two groups (YES , \\(k = 2\\)), :\\[df = k - 1 = 2 - 1 = 1\\]effect size \\(\\phi\\) one-sample chi-square , remind us, formula:\\[\\phi = \\sqrt\\frac{\\chi^2}{N}\\]know:\\(\\chi^2 = 13.76\\)N = 88 + 93 = 181and put formula get:\\[\\phi = \\sqrt\\frac{13.76}{181}\\]becomes:\\[\\phi = \\sqrt{0.0760221} = 0.2757211\\]\nrounded two decimal places show \\(\\phi = 0.28\\)thinking writing one-sample , looking critical value table, see critical value associated \\(df = 1\\) \\(\\alpha = .05\\), three decimal places, \\(\\chi^2_{crit} = 3.841\\). chi-square value test (.e. \\(\\chi^2 = 13.76\\)) larger \\(\\chi^2_{crit}\\) can say test significant, written \\(\\chi^2(df = 1, N = 181) = 13.76,p < .05, \\phi = 0.28\\).Likewise, one-sample chi-square within Group B use expected values \\(Expected_{B-Yes} = 135.78\\) \\(Expected_{B-} = 83.22\\) compare observed values \\(Observed_{B-Yes} = 160\\) \\(Observed_{B-} = 59\\) :\\[\\chi^2 = \\frac{(160 - 135.78)^2}{135.78}+ \\frac{(59 - 83.22)^2}{83.22}\\]walk process find:\\[\\chi^2 = 11.369173\\]Meaning , rounded two decimal places, find \\(\\chi^2 = 11.37\\). degrees freedom, based \\(df = k - 1\\) (one-sample chi-square now), two groups (YES , \\(k = 2\\)), :\\[df = k - 1 = 2 - 1 = 1\\]effect size \\(\\phi\\) one-sample chi-square , remind us, formula:\\[\\phi = \\sqrt\\frac{\\chi^2}{N}\\]know:\\(\\chi^2 = 11.37\\)N = 160 + 59 = 219and put formula get:\\[\\phi = \\sqrt\\frac{12.85}{253}\\]becomes:\\[\\phi = \\sqrt{0.0519178} = 0.2278548\\]\nrounded two decimal places show \\(\\phi = 0.23\\)thinking writing one-sample , looking critical value table, see critical value associated \\(df = 1\\) \\(\\alpha = .05\\), three decimal places, \\(\\chi^2_{crit} = 3.841\\). chi-square value test (.e. \\(\\chi^2 = 11.37\\)) larger \\(\\chi^2_{crit}\\) can sa test significant, written \\(\\chi^2(df = 1, N = 219) = 11.37,p < .05, \\phi = 0.23\\).finally can round everything stating common answer group common answer group B Yes.","code":""},{"path":"chi-square-cross-tabulation.html","id":"chi-square-chi2-look-up-table-1","chapter":"5 Chi-Square Cross-Tabulation","heading":"5.2 Chi-Square (\\(\\chi^2\\)) Look-up Table","text":"","code":""},{"path":"one-sample-t-test.html","id":"one-sample-t-test","chapter":"6 One-Sample t-test","heading":"6 One-Sample t-test","text":"one-sample t-test: Compare sample mean known test value. example, compare sample IQ population norm 100.","code":""},{"path":"one-sample-t-test.html","id":"the-worked-example-2","chapter":"6 One-Sample t-test","heading":"6.1 The Worked Example","text":"formula follows:\\[t = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}\\]\ncan translate symbols :\\(\\bar{x}\\) mean value sample interest\\(\\mu\\) test value compare (also called criterion value)\\(s\\) standard deviation sample interest\\(n\\) number observations (e.g. participants) sample interestSo example, sample 25 people, knew mean standard deviation IQ M = 110, SD = 7.5, wanted compare sample criterion value \\(\\mu\\) = 100, following:\\[t = \\frac{110  - 100}{\\frac{7.5}{\\sqrt{25}}}\\]top half formula first, becomes:\\[t = \\frac{10}{\\frac{7.5}{\\sqrt{25}}}\\]start complete bottom half taking sqaure root n first, (.e. \\(\\sqrt{n}\\)), get:\\[t = \\frac{10}{\\frac{7.5}{5}}\\]\ncomplete bottom half dividing standard deviation sample (\\(s\\)) square root n (\\(\\sqrt{n}\\)), get:\\[t = \\frac{10}{1.5}\\]finally, divide top half formula bottom half get:\\[t = \\frac{10}{1.5} = 6.6666667\\]Giving us t-value t = 6.6666667 can round two decimal places, giving us t = 6.67","code":""},{"path":"one-sample-t-test.html","id":"degrees-of-freedom","chapter":"6 One-Sample t-test","heading":"6.2 Degrees of Freedom","text":"degrees freedom one-sample t-test calculated :\\[df = N - 1\\]know 25 participants sample get:\\[df = N - 1 = 25 - 1 = 24\\]Giving us \\(df\\) = 24","code":""},{"path":"one-sample-t-test.html","id":"effect-size","chapter":"6 One-Sample t-test","heading":"6.3 Effect Size","text":"common effect size used t-test Cohen's d. formula effect size, one-sample t-test, know t-value number participants :\\[d = \\frac{t}{\\sqrt{N}}\\]know :\\(t\\) = 6.67\\(N\\) = 25Which put formula get:\\[d = \\frac{6.67}{\\sqrt{25}}\\]\nresolve bottom half first:\\[d = \\frac{6.67}{5}\\]divide top bottom get:\\[d = \\frac{6.67}{5} = 1.334\\]Giving us effect size \\(d\\) = 1.33, rounded two decimal places.","code":""},{"path":"one-sample-t-test.html","id":"write-up","chapter":"6 One-Sample t-test","heading":"6.4 Write-up","text":"look critical values look-table \\(df = 24\\) \\(\\alpha = .05\\) (two-tailed), see critical value \\(t_{crit} = 2.064\\).Given t-value, ignoring polarity just looking absolute value, \\(t = 6.67\\), equal larger \\(t_{crit}\\) can say result significant, written t(24) = 6.67, p < .05, d = 1.33","code":""},{"path":"one-sample-t-test.html","id":"look-up-table","chapter":"6 One-Sample t-test","heading":"6.5 Look-Up table","text":"Remembering \\(t_{crit}\\) value smallest t-value need find significant effect, find \\(t_{crit}\\) df, assuming \\(\\alpha = .05\\). \\(t\\) value calculated equal larger \\(t_{crit}\\) test significant.","code":""},{"path":"between-subjects-students-t-test.html","id":"between-subjects-students-t-test","chapter":"7 Between-Subjects Student's t-test","heading":"7 Between-Subjects Student's t-test","text":"-subjects t-test: Compare two groups conditions participants different group matched matched broad demographics, e.g. age.","code":""},{"path":"between-subjects-students-t-test.html","id":"the-worked-example-3","chapter":"7 Between-Subjects Student's t-test","heading":"7.1 The Worked Example","text":"data:look main t-test formula:\\[t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p \\times \\sqrt{\\frac{1}{N_1} + \\frac{1}{N_2}}}\\]Now, table know:mean Group \\(\\bar{X_1} = 25.58\\),mean Group B \\(\\bar{X_2} = 29.07\\),N Group \\(N_1 = 18\\),N Group B \\(N_2 = 18\\),can put equation right now:\\[t = \\frac{25.58 - 29.07}{s_p \\times \\sqrt{\\frac{1}{18} + \\frac{1}{18}}}\\]now can see thing yet know pooled standard deviation (\\(s_p\\)). look formula:Calculating pooled standard deviation\\[s_p = \\sqrt{\\frac{(n_1 -1)  \\times s^2_{X_1} + (n_2 -1)\\times s^2_{X_2}}{n_1 + n_2 - 2}}\\]start fill details:\\[s_p = \\sqrt{\\frac{(18 -1)  \\times s^2_{X_1} + (18 -1)\\times s^2_{X_2}}{18 + 18 - 2}}\\]Now looking formula, clear missing:\\(s^2_{X_1}\\) - variance Group (written \\(s^2_{}\\))\\(s^2_{X_2}\\) - variance Group B (written \\(s^2_{B}\\))know though, table, standard deviations groups (\\(SD_A\\) = 2.25; \\(SD_B\\) = 2.53), know variance group equal standard deviation squared. :\\(s^2_{X_1}\\) = \\(s^2_A\\) = \\(SD_A \\times SD_A\\) = \\(2.25 \\times 2.25\\) = \\(5.0625\\)\\(s^2_{X_2}\\) = \\(s^2_B\\) = \\(SD_B \\times SD_B\\) = \\(2.53 \\times 2.53\\) = \\(6.4009\\)now add values formula get:\\[s_p = \\sqrt{\\frac{(18 -1)  \\times 5.0625 + (18 -1)\\times 6.4009}{18 + 18 - 2}}\\]can start working formula, taking stage turn make sure make mistakes. get rid brackets first:\\[s_p = \\sqrt{\\frac{(17  \\times 5.0625) + (17 \\times 6.4009)}{34}}\\]Now deal multiplications:\\[s_p = \\sqrt{\\frac{86.0625 + 108.8153}{34}}\\]tidy top half equation (numerator):\\[s_p = \\sqrt{\\frac{194.8778}{34}}\\]divide numerator denominator (bottom half), take square root get:\\[s_p = \\sqrt{5.7317}\\]Giving pooled standard deviation :\\[s_p = 2.3940969\\]Meaning pooled standard deviation, rounded three decimal places, \\(s_p = 2.394\\) can now add t-test formula give us:Calculating t-value\\[t = \\frac{25.58 - 29.07}{2.394 \\times \\sqrt{\\frac{1}{18} + \\frac{1}{18}}}\\]just start working formula. deal fractions relating sample size first:\\[t = \\frac{25.58 - 29.07}{2.394 \\times \\sqrt{0.0555556 + 0.0555556}}\\]can tidy little give:\\[t = \\frac{-3.49}{2.394 \\times \\sqrt{0.1111111}}\\]sort square root denominator left :\\[t = \\frac{-3.49}{2.394 \\times 0.3333333}\\]can tidy denominator give us:\\[t = \\frac{-3.49}{0.798}\\]can finally solve give us t-value, rounded two decimal places, \\(t = -4.37\\)Degrees FreedomGreat! Now just need degrees freedom formula :\\[df = (n_1 - 1) + (n_2 - 1)\\]already know :N Group \\(N_1 = 18\\),N Group B \\(N_2 = 18\\),putting equation get:\\[df = (18 - 1) + (18 - 1)\\]\n\\[df = 17 + 17\\]\n\\[df = 34\\]Effect Size: Cohen's dAnd finally Cohen's d, effect size:\\[d = \\frac{2t}{\\sqrt{df}}\\], based info , know:\\(t = -4.37\\)\\(df = 34\\)Putting formula get:\\[d = \\frac{2 \\times -4.37}{\\sqrt{34}}\\]tidy nominator denominator get:\\[d = \\frac{-8.74}{5.8309519}\\]can solve learn \\(d = -1.5\\)Determining SignificanceIf look critical values look-table \\(df = 34\\) \\(\\alpha = .05\\) (two-tailed), see critical value \\(t_{crit} = 2.032\\). Given t-value, ignoring polarity just looking absolute value, \\(t = 4.37\\), equal larger \\(t_{crit}\\) can say result significant, written t(34) = 4.37, p < .05, d = 1.5Remember: writing report, analysis data R, see p-value actually p = 1.1081944^{-4}, written p < .001","code":""},{"path":"between-subjects-students-t-test.html","id":"test-yourself-1","chapter":"7 Between-Subjects Student's t-test","heading":"7.2 Test Yourself","text":"","code":""},{"path":"between-subjects-students-t-test.html","id":"dataset-1-1","chapter":"7 Between-Subjects Student's t-test","heading":"7.2.1 DataSet 1","text":"data:look main t-test formula:\\[t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p \\times \\sqrt{\\frac{1}{N_1} + \\frac{1}{N_2}}}\\]Now, table know:mean Group \\(\\bar{X_1} = 68.01\\),mean Group B \\(\\bar{X_2} = 67.8\\),N Group \\(N_1 = 5\\),N Group B \\(N_2 = 5\\),can put equation right now:\\[t = \\frac{68.01 - 67.8}{s_p \\times \\sqrt{\\frac{1}{5} + \\frac{1}{5}}}\\]now can see thing yet know pooled standard deviation (\\(s_p\\)). look formula:\\[s_p = \\sqrt{\\frac{(n_1 -1)  \\times s^2_{X_1} + (n_2 -1)\\times s^2_{X_2}}{n_1 + n_2 - 2}}\\]start fill details:\\[s_p = \\sqrt{\\frac{(5 -1)  \\times s^2_{X_1} + (5 -1)\\times s^2_{X_2}}{5 + 5 - 2}}\\]Now looking formula, clear missing:\\(s^2_{X_1}\\) - variance Group (written \\(s^2_{}\\))\\(s^2_{X_2}\\) - variance Group B (written \\(s^2_{B}\\))know though, table, standard deviations groups (\\(SD_A\\) = 0.34; \\(SD_B\\) = 0.67), know variance group equal standard deviation squared. :\\(s^2_{X_1}\\) = \\(s^2_A\\) = \\(SD_A \\times SD_A\\) = \\(0.34 \\times 0.34\\) = \\(0.1156\\)\\(s^2_{X_2}\\) = \\(s^2_B\\) = \\(SD_B \\times SD_B\\) = \\(0.67 \\times 0.67\\) = \\(0.4489\\)now add values formula get:\\[s_p = \\sqrt{\\frac{(5 -1)  \\times 0.1156 + (5 -1)\\times 0.4489}{5 + 5 - 2}}\\]can start working formula, taking stage turn make sure make mistakes. get rid brackets first:\\[s_p = \\sqrt{\\frac{(4  \\times 0.1156) + (4 \\times 0.4489)}{8}}\\]Now deal multiplications:\\[s_p = \\sqrt{\\frac{0.4624 + 1.7956}{8}}\\]tidy top half equation (numerator):\\[s_p = \\sqrt{\\frac{2.258}{8}}\\]divide numerator denominator (bottom half), take square root get:\\[s_p = \\sqrt{0.28225}\\]Giving pooled standard deviation :\\[s_p = 0.5312721\\]Meaning pooled standard deviation, rounded three decimal places, \\(s_p = 0.531\\) can now add t-test formula give us:\\[t = \\frac{68.01 - 67.8}{0.531 \\times \\sqrt{\\frac{1}{5} + \\frac{1}{5}}}\\]just start working formula. deal fractions relating sample size first:\\[t = \\frac{68.01 - 67.8}{0.531 \\times \\sqrt{0.2 + 0.2}}\\]can tidy little give:\\[t = \\frac{0.21}{0.531 \\times \\sqrt{0.4}}\\]sort square root denominator left :\\[t = \\frac{0.21}{0.531 \\times 0.6324555}\\]can tidy denominator give us:\\[t = \\frac{0.21}{0.3358339}\\]can finally solve give us t-value, rounded two decimal places, \\(t = 0.63\\)Great! Now just need degrees freedom formula :\\[df = (n_1 - 1) + (n_2 - 1)\\]already know :N Group \\(N_1 = 5\\),N Group B \\(N_2 = 5\\),putting equation get:\\[df = (5 - 1) + (5 - 1)\\]\n\\[df = 4 + 4\\]\n\\[df = 8\\]finally Cohen's d, effect size:\\[d = \\frac{2t}{\\sqrt{df}}\\], based info , know:\\(t = 0.63\\)\\(df = 8\\)Putting formula get:\\[d = \\frac{2 \\times 0.63}{\\sqrt{8}}\\]tidy nominator denominator get:\\[d = \\frac{1.26}{2.8284271}\\]can solve learn \\(d = 0.45\\)Determining SignificanceIf look critical values look-table \\(df = 8\\) \\(\\alpha = .05\\) (two-tailed), see critical value \\(t_{crit} = 2.306\\). Given t-value, ignoring polarity just looking absolute value, \\(t = 0.63\\), smaller \\(t_{crit}\\) can say result non-significant, written t(8) = 0.63, p > .05, d = 0.45Remember: writing report, analysis data R, see p-value actually p = 0.5462633, written p = 0.548","code":""},{"path":"between-subjects-students-t-test.html","id":"dataset-2-1","chapter":"7 Between-Subjects Student's t-test","heading":"7.2.2 DataSet 2","text":"data:look main t-test formula:\\[t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p \\times \\sqrt{\\frac{1}{N_1} + \\frac{1}{N_2}}}\\]Now, table know:mean Group \\(\\bar{X_1} = 66.18\\),mean Group B \\(\\bar{X_2} = 66.42\\),N Group \\(N_1 = 47\\),N Group B \\(N_2 = 47\\),can put equation right now:\\[t = \\frac{66.18 - 66.42}{s_p \\times \\sqrt{\\frac{1}{47} + \\frac{1}{47}}}\\]now can see thing yet know pooled standard deviation (\\(s_p\\)). look formula:\\[s_p = \\sqrt{\\frac{(n_1 -1)  \\times s^2_{X_1} + (n_2 -1)\\times s^2_{X_2}}{n_1 + n_2 - 2}}\\]start fill details:\\[s_p = \\sqrt{\\frac{(47 -1)  \\times s^2_{X_1} + (47 -1)\\times s^2_{X_2}}{47 + 47 - 2}}\\]Now looking formula, clear missing:\\(s^2_{X_1}\\) - variance Group (written \\(s^2_{}\\))\\(s^2_{X_2}\\) - variance Group B (written \\(s^2_{B}\\))know though, table, standard deviations groups (\\(SD_A\\) = 1.79; \\(SD_B\\) = 1.78), know variance group equal standard deviation squared. :\\(s^2_{X_1}\\) = \\(s^2_A\\) = \\(SD_A \\times SD_A\\) = \\(1.79 \\times 1.79\\) = \\(3.2041\\)\\(s^2_{X_2}\\) = \\(s^2_B\\) = \\(SD_B \\times SD_B\\) = \\(1.78 \\times 1.78\\) = \\(3.1684\\)now add values formula get:\\[s_p = \\sqrt{\\frac{(47 -1)  \\times 3.2041 + (47 -1)\\times 3.1684}{47 + 47 - 2}}\\]can start working formula, taking stage turn make sure make mistakes. get rid brackets first:\\[s_p = \\sqrt{\\frac{(46  \\times 3.2041) + (46 \\times 3.1684)}{92}}\\]Now deal multiplications:\\[s_p = \\sqrt{\\frac{147.3886 + 145.7464}{92}}\\]tidy top half equation (numerator):\\[s_p = \\sqrt{\\frac{293.135}{92}}\\]divide numerator denominator (bottom half), take square root get:\\[s_p = \\sqrt{3.18625}\\]Giving pooled standard deviation :\\[s_p = 1.785007\\]Meaning pooled standard deviation, rounded three decimal places, \\(s_p = 1.785\\) can now add t-test formula give us:\\[t = \\frac{66.18 - 66.42}{1.785 \\times \\sqrt{\\frac{1}{47} + \\frac{1}{47}}}\\]just start working formula. deal fractions relating sample size first:\\[t = \\frac{66.18 - 66.42}{1.785 \\times \\sqrt{0.0212766 + 0.0212766}}\\]can tidy little give:\\[t = \\frac{-0.24}{1.785 \\times \\sqrt{0.0425532}}\\]sort square root denominator left :\\[t = \\frac{-0.24}{1.785 \\times 0.2062842}\\]can tidy denominator give us:\\[t = \\frac{-0.24}{0.3682174}\\]can finally solve give us t-value, rounded two decimal places, \\(t = -0.65\\)Great! Now just need degrees freedom formula :\\[df = (n_1 - 1) + (n_2 - 1)\\]already know :N Group \\(N_1 = 47\\),N Group B \\(N_2 = 47\\),putting equation get:\\[df = (47 - 1) + (47 - 1)\\]\n\\[df = 46 + 46\\]\n\\[df = 92\\]finally Cohen's d, effect size:\\[d = \\frac{2t}{\\sqrt{df}}\\], based info , know:\\(t = -0.65\\)\\(df = 92\\)Putting formula get:\\[d = \\frac{2 \\times -0.65}{\\sqrt{92}}\\]tidy nominator denominator get:\\[d = \\frac{-1.3}{9.591663}\\]can solve learn \\(d = -0.14\\)Determining SignificanceIf look critical values look-table \\(df = 92\\) \\(\\alpha = .05\\) (two-tailed), see critical value \\(t_{crit} = 1.986\\). Given t-value, ignoring polarity just looking absolute value, \\(t = 0.65\\), smaller \\(t_{crit}\\) can say result non-significant, written t(92) = 0.65, p > .05, d = 0.14Remember: writing report, analysis data R, see p-value actually p = 0.517312, written p = 0.513","code":""},{"path":"between-subjects-students-t-test.html","id":"dataset-3-1","chapter":"7 Between-Subjects Student's t-test","heading":"7.2.3 DataSet 3","text":"data:look main t-test formula:\\[t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p \\times \\sqrt{\\frac{1}{N_1} + \\frac{1}{N_2}}}\\]Now, table know:mean Group \\(\\bar{X_1} = 31.8\\),mean Group B \\(\\bar{X_2} = 32.18\\),N Group \\(N_1 = 8\\),N Group B \\(N_2 = 8\\),can put equation right now:\\[t = \\frac{31.8 - 32.18}{s_p \\times \\sqrt{\\frac{1}{8} + \\frac{1}{8}}}\\]now can see thing yet know pooled standard deviation (\\(s_p\\)). look formula:\\[s_p = \\sqrt{\\frac{(n_1 -1)  \\times s^2_{X_1} + (n_2 -1)\\times s^2_{X_2}}{n_1 + n_2 - 2}}\\]start fill details:\\[s_p = \\sqrt{\\frac{(8 -1)  \\times s^2_{X_1} + (8 -1)\\times s^2_{X_2}}{8 + 8 - 2}}\\]Now looking formula, clear missing:\\(s^2_{X_1}\\) - variance Group (written \\(s^2_{}\\))\\(s^2_{X_2}\\) - variance Group B (written \\(s^2_{B}\\))know though, table, standard deviations groups (\\(SD_A\\) = 0.42; \\(SD_B\\) = 0.57), know variance group equal standard deviation squared. :\\(s^2_{X_1}\\) = \\(s^2_A\\) = \\(SD_A \\times SD_A\\) = \\(0.42 \\times 0.42\\) = \\(0.1764\\)\\(s^2_{X_2}\\) = \\(s^2_B\\) = \\(SD_B \\times SD_B\\) = \\(0.57 \\times 0.57\\) = \\(0.3249\\)now add values formula get:\\[s_p = \\sqrt{\\frac{(8 -1)  \\times 0.1764 + (8 -1)\\times 0.3249}{8 + 8 - 2}}\\]can start working formula, taking stage turn make sure make mistakes. get rid brackets first:\\[s_p = \\sqrt{\\frac{(7  \\times 0.1764) + (7 \\times 0.3249)}{14}}\\]Now deal multiplications:\\[s_p = \\sqrt{\\frac{1.2348 + 2.2743}{14}}\\]tidy top half equation (numerator):\\[s_p = \\sqrt{\\frac{3.5091}{14}}\\]divide numerator denominator (bottom half), take square root get:\\[s_p = \\sqrt{0.25065}\\]Giving pooled standard deviation :\\[s_p = 0.5006496\\]Meaning pooled standard deviation, rounded three decimal places, \\(s_p = 0.501\\) can now add t-test formula give us:\\[t = \\frac{31.8 - 32.18}{0.501 \\times \\sqrt{\\frac{1}{8} + \\frac{1}{8}}}\\]just start working formula. deal fractions relating sample size first:\\[t = \\frac{31.8 - 32.18}{0.501 \\times \\sqrt{0.125 + 0.125}}\\]can tidy little give:\\[t = \\frac{-0.38}{0.501 \\times \\sqrt{0.25}}\\]sort square root denominator left :\\[t = \\frac{-0.38}{0.501 \\times 0.5}\\]can tidy denominator give us:\\[t = \\frac{-0.38}{0.2505}\\]can finally solve give us t-value, rounded two decimal places, \\(t = -1.52\\)Great! Now just need degrees freedom formula :\\[df = (n_1 - 1) + (n_2 - 1)\\]already know :N Group \\(N_1 = 8\\),N Group B \\(N_2 = 8\\),putting equation get:\\[df = (8 - 1) + (8 - 1)\\]\n\\[df = 7 + 7\\]\n\\[df = 14\\]finally Cohen's d, effect size:\\[d = \\frac{2t}{\\sqrt{df}}\\], based info , know:\\(t = -1.52\\)\\(df = 14\\)Putting formula get:\\[d = \\frac{2 \\times -1.52}{\\sqrt{14}}\\]tidy nominator denominator get:\\[d = \\frac{-3.04}{3.7416574}\\]can solve learn \\(d = -0.81\\)Determining SignificanceIf look critical values look-table \\(df = 14\\) \\(\\alpha = .05\\) (two-tailed), see critical value \\(t_{crit} = 2.145\\). Given t-value, ignoring polarity just looking absolute value, \\(t = 1.52\\), smaller \\(t_{crit}\\) can say result non-significant, written t(14) = 1.52, p > .05, d = 0.81Remember: writing report, analysis data R, see p-value actually p = 0.1507698, written p = 0.144","code":""},{"path":"between-subjects-students-t-test.html","id":"look-up-table-1","chapter":"7 Between-Subjects Student's t-test","heading":"7.3 Look-Up table","text":"Remembering \\(t_{crit}\\) value smallest t-value need find significant effect, find \\(t_{crit}\\) df, assuming \\(\\alpha = .05\\). \\(t\\) value calculated equal larger \\(t_{crit}\\) test significant.","code":""},{"path":"between-subjects-welchs-t-test.html","id":"between-subjects-welchs-t-test","chapter":"8 Between-Subjects Welch's t-test","heading":"8 Between-Subjects Welch's t-test","text":"-subjects Welch's t-test: Compare two groups conditions participants different group matched matched broad demographics, e.g. age.","code":""},{"path":"between-subjects-welchs-t-test.html","id":"the-worked-example-4","chapter":"8 Between-Subjects Welch's t-test","heading":"8.1 The Worked Example","text":"data:look main t-test formula Welch's t-test:\\[t = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{s_1^2}{n_1}+\\frac{s_2^2}{n_2}}}\\]Now, table know:mean Group \\(\\bar{X_1} = 25.58\\),mean Group B \\(\\bar{X_2} = 29.07\\),N Group \\(N_1 = 18\\),N Group B \\(N_2 = 18\\)table also know standard deviation (\\(s_1\\) = 2.25 \\(s_2\\) = 2.53) two groups, Welch's t-test formula uses variance groups (\\(s_1^2\\) \\(s_2^2\\)). Fortunately, know standard deviation set values, can calculate variance formula:\\[variance = SD \\times SD\\]Meaning :variance Group , \\(s_1^2 = 2.25 \\times 2.25\\) = 5.0625and variance Group B, \\(s_2^2 = 2.53 \\times 2.53\\) = 6.4009And can now start fill t-test formula follows:\\[t = \\frac{25.58 - 29.07}{\\sqrt{\\frac{5.0625}{18}+\\frac{6.4009}{18}}}\\]start resolving fractions bottom half formula dividing variance group number participants group:\\[t = \\frac{25.58 - 29.07}{\\sqrt{0.28125+0.3556056}}\\]can add together:\\[t = \\frac{25.58 - 29.07}{\\sqrt{0.6368556}}\\]take square root value give us one value bottom half formula:\\[t = \\frac{25.58 - 29.07}{0.7980323}\\]can resolve top half formula taking one mean :\\[t = \\frac{-3.49}{0.7980323}\\]finally, dividing top bottom give us t-value:\\[t = -4.3732566\\]\nMeaning t-value, rounded two decimal places, \\(t = -4.37\\)Degrees FreedomThe degrees freedom formula Welch's -subjects t-test actually little bit complicated shown . However, anything, break ok really need variance groups number people groups. just requires careful order different parts.\\[df = \\frac{\\left(\\frac{s^2_{x_1}}{n_1}+\\frac{s^2_{x_2}}{n_2}\\right)^2}{\\frac{\\left(\\frac{s^2_{x_1}}{n_1}\\right)^2}{n_1 - 1}+\\frac{\\left(\\frac{s^2_{x_2}}{n_2}\\right)^2}{n_2 - 1}}\\]\nknow :variance Group , \\(s^2_{x_1} = 5.0625\\)variance Group B, \\(s^2_{x_2} = 6.4009\\)N Group , \\(n_1 = 18\\)N Group B, \\(n_1 = 18\\)can start fill follows:\\[df = \\frac{\\left(\\frac{5.0625}{18}+\\frac{6.4009}{18}\\right)^2}{\\frac{\\left(\\frac{5.0625}{18}\\right)^2}{18 - 1}+\\frac{\\left(\\frac{6.4009}{18}\\right)^2}{18 - 1}}\\]\nslowly reduce one fractions dividing variance first group number people group.\\[df = \\frac{\\left(\\frac{5.0625}{18}+\\frac{6.4009}{18}\\right)^2}{\\frac{\\left(0.28125\\right)^2}{18 - 1}+\\frac{\\left(\\frac{6.4009}{18}\\right)^2}{18 - 1}}\\]\nnow second group:\\[df = \\frac{\\left(\\frac{5.0625}{18}+\\frac{6.4009}{18}\\right)^2}{\\frac{\\left(0.28125\\right)^2}{18 - 1}+\\frac{\\left(0.3556056\\right)^2}{18 - 1}}\\]also reduce formula little dealing \\(n-1\\) bottom half formula:\\[df = \\frac{\\left(\\frac{5.0625}{18}+\\frac{6.4009}{18}\\right)^2}{\\frac{\\left(0.28125\\right)^2}{17}+\\frac{\\left(0.3556056\\right)^2}{17}}\\]\nnow maybe reduce top half formula dividing variance first group number people group, second group.\\[df = \\frac{\\left(0.28125+0.3556056\\right)^2}{\\frac{\\left(0.28125\\right)^2}{17}+\\frac{\\left(0.3556056\\right)^2}{17}}\\]now stick top half add two values together:\\[df = \\frac{0.6368556^2}{\\frac{\\left(0.28125\\right)^2}{17}+\\frac{\\left(0.3556056\\right)^2}{17}}\\]\nsquare value:\\[df = \\frac{0.405585}{\\frac{\\left(0.28125\\right)^2}{17}+\\frac{\\left(0.3556056\\right)^2}{17}}\\]looking back bottom half formula can reduce bit squaring two values:\\[df = \\frac{0.405585}{\\frac{0.0791016}{17}+\\frac{0.1264553}{17}}\\]now resolve fractions bottom half dividing top part bottom part group:\\[df = \\frac{0.405585}{0.004653+0.0074385}\\]add two values bottom part formula together:\\[df = \\frac{0.405585}{0.0120916}\\]finally divide top half formula bottom half get degrees freedom:\\[df = 33.5427605\\]\nMeaning df, rounded two decimal places, \\(df = 33.54\\)Effect SizeAnd finally Cohen's d, effect size:\\[d = \\frac{2t}{\\sqrt{df}}\\], based info , know:t-value \\(t = -4.37\\)degrees freedom \\(df = 33.54\\)putting formula get:\\[d = \\frac{2 \\times -4.37}{\\sqrt{33.54}}\\]resolve square-root first get:\\[d = \\frac{2 \\times -4.37}{5.7913729}\\]work top half:\\[d = \\frac{-8.74}{5.7913729}\\]divide top bottom:\\[d = -1.5091413\\]Meaning cohen's d, rounded two decimal places, d = -1.51Determining SignificanceIf look critical values look-table \\(df = 33.54\\) \\(\\alpha = .05\\), see critical value \\(t_{crit} = 2.033\\). Given t-value, ignoring polarity just looking absolute value, \\(t = 4.37\\), equal larger \\(t_{crit}\\) can say result significant, written t(33.54) = -4.37, p < .05, d = -1.51.","code":""},{"path":"between-subjects-welchs-t-test.html","id":"look-up-table-2","chapter":"8 Between-Subjects Welch's t-test","heading":"8.2 Look-Up table","text":"Remembering \\(t_{crit}\\) value smallest t-value need find significant effect, find \\(t_{crit}\\) df, assuming \\(\\alpha = .05\\).\\(df\\) test look-table, use next smallest \\(df\\). example, test \\(df = 37\\) table \\(df = 30\\) \\(df = 40\\), use \\(df = 30\\).\\(t\\) value calculated equal larger \\(t_{crit}\\) test significant.","code":""},{"path":"within-subjects-t-test.html","id":"within-subjects-t-test","chapter":"9 Within-Subjects t-test","heading":"9 Within-Subjects t-test","text":"within-subjects t-test: Compare two conditions participants conditions (rarely different participants highly matched number demographics IQ, reading ability, etc - must matched number demographics).","code":""},{"path":"within-subjects-t-test.html","id":"the-worked-example-5","chapter":"9 Within-Subjects t-test","heading":"9.1 The Worked Example","text":"say starting data:first thing need calculate difference PostTest PreTest participant, based \\(D = PostTest - PreTest\\). example:Participant 1 : 68 - 60 = 8Participant 2 : 75 - 64 = 11etcAnd Participant added column differences (\\(D\\)) see:Now, within-subjects t-test formula :\\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\]can see \\(N = 10\\), need calculate \\(\\bar{D}\\) (called D-Bar, mean \\(D\\) column) \\(SD_{D}\\).Calculating D-barSo \\(\\bar{D}\\) formula mean formula:\\[\\bar{D} = \\frac{\\sum{D}}{N}\\]\\(D\\) \\(PostTest - PreTest\\) Participant.:\\[\\bar{D} = \\frac{(68 - 60) + (75 - 64) + (62 - 56) + (85 - 82) + (73 - 74) + \\\\ (85- 79) + (64 - 63) + (59 - 59) + (73 - 72) + (70 - 66)}{10}\\]resolve brackets becomes:\\[\\bar{D} = \\frac{8 + 11 + 6 + 3 + -1 + 6 + 1 + 0 + 1 + 4}{10}\\]sum top half together\\[\\bar{D} = \\frac{39}{10}\\]Leaving us :\\[\\bar{D} = 3.9\\]find \\(\\bar{D}\\) = 3.9, mean difference Post test Pre test values.Standard Deviation DThe standard deviation formula :\\[SD = \\sqrt\\frac{\\sum(X - \\bar{X})^2}{N-1}\\]translate using D, becomes:\\[SD_{D} = \\sqrt\\frac{\\sum(D - \\bar{D})^2}{N-1}\\]:\\[SD_{D} =\\sqrt\\frac{(8 - 3.9)^2 + (11 - 3.9)^2 + (6 - 3.9)^2 + (3 - 3.9)^2 + (-1 - 3.9)^2 + \\\\ (6 - 3.9)^2 + (1 - 3.9)^2 + (0 - 3.9)^2 + (1 - 3.9)^2 + (4 - 3.9)^2}{10 - 1}\\]start stepping analysis dealing brackets:\\[SD_{D} =\\sqrt\\frac{(4.1)^2 + (7.1)^2 + (2.1)^2 + (-0.9)^2 + (-4.9)^2 + \\\\ (2.1)^2 + (-2.9)^2 + (-3.9)^2 + (-2.9)^2 + (0.1)^2}{10 - 1}\\]square brackets\\[SD_{D} =\\sqrt\\frac{16.81 + 50.41 + 4.41 + 0.81 + 24.01 + 4.41 + 8.41 + 15.21 + 8.41 + 0.01}{10 - 1}\\]sum values top half:\\[SD_{D} =\\sqrt\\frac{132.9}{10 - 1}\\]need sort bottom half\\[SD_{D} =\\sqrt\\frac{132.9}{9}\\]dividing top half bottom half reduces :\\[SD_{D} =\\sqrt{14.7666667}\\]finally take square root, leaves us :\\[SD_{D} =3.8427421\\]find \\(SD_{D}\\) = 3.8427421 two decimal places , \\(SD_{D} = 3.84\\)Calculating t-valueAnd finally t-test formula :\\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\]start filling values know see:\\[t = \\frac{3.9}{\\frac{3.8427421}{\\sqrt{10}}} \\]deal square root first:\\[t = \\frac{3.9}{\\frac{3.8427421}{3.1622777}} \\]divide \\(SD_{D}\\) \\(\\sqrt{N}\\) - tidying bottom formula:\\[t = \\frac{3.9}{1.2151817} \\]solve \\(t\\) dividing top half bottom half gives us:\\[t = 3.2093965 \\], rounding two decimal places, find \\(t = 3.21\\)Degrees FreedomGreat! Now just need degrees freedom formula :\\[df = N - 1\\]already know \\(N= 10\\) putting equation get:\\[df = 10 - 1\\]reduces :\\[df = 9\\]Meaning find \\(df = 9\\)Effect Size - Cohen's dAnd finally Cohen's d, effect size. One common formulas based knowing t-value N :\\[d = \\frac{t}{\\sqrt{N}}\\], based info , know:\\(t = 3.21\\)\\(N = 10\\)putting formula get:\\[d = \\frac{3.21}{\\sqrt{10}}\\]gives us:\\[d = \\frac{3.21}{3.1622777}\\]:\\[d = 1.0150911\\]Meaning effect size, two decimal places, d = 1.01.Determining SignificanceIf look critical values look-table \\(df = 9\\) \\(\\alpha = .05\\) (two-tailed), see critical value \\(t_{crit} = 2.262\\). Given t-value, ignoring polarity just looking absolute value, \\(t = 3.21\\), equal larger \\(t_{crit}\\) can say result significant, written t(9) = 3.21, p < .05, d = 1.01.Remember: writing report, analysis data R, see p-value actually p = 0.011, written p = 0.011","code":""},{"path":"within-subjects-t-test.html","id":"test-yourself-2","chapter":"9 Within-Subjects t-test","heading":"9.2 Test Yourself","text":"","code":""},{"path":"within-subjects-t-test.html","id":"dataset-1-2","chapter":"9 Within-Subjects t-test","heading":"9.2.1 DataSet 1","text":"say starting data:first thing need calculate difference PostTest PreTest participant, based \\(D = PostTest - PreTest\\). example:Participant 1 : 64 - 71 = -7Participant 2 : 54 - 56 = -2etcAnd Participant added column differences (\\(D\\)) see:Now, within-subjects t-test formula :\\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\]can see \\(N = 10\\), need calculate \\(\\bar{D}\\) (called D-Bar, mean \\(D\\) column) \\(SD_{D}\\).Calculating D-barSo \\(\\bar{D}\\) formula mean formula:\\[\\bar{D} = \\frac{\\sum{D}}{N}\\]\\(D\\) \\(PostTest - PreTest\\) Participant.:\\[\\bar{D} = \\frac{(64 - 71) + (54 - 56) + (70 - 75) + (46 - 50) + (52 - 51) + \\\\ (58- 61) + (61 - 62) + (74 - 72) + (60 - 66) + (78 - 78)}{10}\\]resolve brackets becomes:\\[\\bar{D} = \\frac{-7 + -2 + -5 + -4 + 1 + -3 + -1 + 2 + -6 + 0}{10}\\]sum top half together\\[\\bar{D} = \\frac{-25}{10}\\]Leaving us :\\[\\bar{D} = -2.5\\]find \\(\\bar{D}\\) = -2.5, mean difference Post test Pre test values.Standard Deviation DThe standard deviation formula :\\[SD = \\sqrt\\frac{\\sum(X - \\bar{X})^2}{N-1}\\]translate using D, becomes:\\[SD_{D} = \\sqrt\\frac{\\sum(D - \\bar{D})^2}{N-1}\\]:\\[SD_{D} =\\sqrt\\frac{(-7 - -2.5)^2 + (-2 - -2.5)^2 + (-5 - -2.5)^2 + (-4 - -2.5)^2 + \\\\ (1 - -2.5)^2 + (-3 - -2.5)^2 + (-1 - -2.5)^2 + (2 - -2.5)^2 + \\\\ (-6 - -2.5)^2 + (0 - -2.5)^2}{10 - 1}\\]start stepping analysis dealing brackets:\\[SD_{D} =\\sqrt\\frac{(-4.5)^2 + (0.5)^2 + (-2.5)^2 + (-1.5)^2 + (3.5)^2 + \\\\ (-0.5)^2 + (1.5)^2 + (4.5)^2 + (-3.5)^2 + (2.5)^2}{10 - 1}\\]square brackets\\[SD_{D} =\\sqrt\\frac{20.25 + 0.25 + 6.25 + 2.25 + 12.25 + \\\\ 0.25 + 2.25 + 20.25 + 12.25 + 6.25}{10 - 1}\\]sum values top half:\\[SD_{D} =\\sqrt\\frac{82.5}{10 - 1}\\]need sort bottom half\\[SD_{D} =\\sqrt\\frac{82.5}{9}\\]dividing top half bottom half reduces :\\[SD_{D} =\\sqrt{9.1666667}\\]finally take square root, leaves us :\\[SD_{D} =3.0276504\\]find \\(SD_{D}\\) = 3.0276504 two decimal places , \\(SD_{D} = 3.03\\)Calculating t-valueAnd finally t-test formula :\\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\]start filling values know see:\\[t = \\frac{-2.5}{\\frac{3.0276504}{\\sqrt{10}}} \\]deal square root first:\\[t = \\frac{-2.5}{\\frac{3.0276504}{3.1622777}} \\]divide \\(SD_{D}\\) \\(\\sqrt{N}\\) - tidying bottom formula:\\[t = \\frac{-2.5}{0.9574271} \\]solve \\(t\\) dividing top half bottom half gives us:\\[t = -2.6111648 \\], rounding two decimal places, find \\(t = -2.61\\)Degrees FreedomGreat! Now just need degrees freedom formula :\\[df = N - 1\\]already know \\(N= 10\\) putting equation get:\\[df = 10 - 1\\]reduces :\\[df = 9\\]Meaning find \\(df = 9\\)Effect Size - Cohen's dAnd finally Cohen's d, effect size. One common formulas based knowing t-value N :\\[d = \\frac{t}{\\sqrt{N}}\\], based info , know:\\(t = -2.61\\)\\(N = 10\\)putting formula get:\\[d = \\frac{-2.61}{\\sqrt{10}}\\]gives us:\\[d = \\frac{-2.61}{3.1622777}\\]:\\[d = -0.8253545\\]Meaning effect size, two decimal places, d = -0.83.Determining SignificanceIf look critical values look-table \\(df = 9\\) \\(\\alpha = .05\\) (two-tailed), see critical value \\(t_{crit} = 2.262\\). Given t-value, ignoring polarity just looking absolute value, \\(t = 2.61\\), equal larger \\(t_{crit}\\) can say result significant, written t(9) = 2.61, p < .05, d = 0.83.Remember: writing report, analysis data R, see p-value actually p = 0.028, written p = 0.028","code":""},{"path":"within-subjects-t-test.html","id":"dataset-2-2","chapter":"9 Within-Subjects t-test","heading":"9.2.2 DataSet 2","text":"say starting data:first thing need calculate difference PostTest PreTest participant, based \\(D = PostTest - PreTest\\). example:Participant 1 : 72 - 73 = -1Participant 2 : 54 - 60 = -6etcAnd Participant added column differences (\\(D\\)) see:Now, within-subjects t-test formula :\\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\]can see \\(N = 10\\), need calculate \\(\\bar{D}\\) (called D-Bar, mean \\(D\\) column) \\(SD_{D}\\).Calculating D-barSo \\(\\bar{D}\\) formula mean formula:\\[\\bar{D} = \\frac{\\sum{D}}{N}\\]\\(D\\) \\(PostTest - PreTest\\) Participant.:\\[\\bar{D} = \\frac{(72 - 73) + (54 - 60) + (52 - 53) + (74 - 74) + (54 - 58) + \\\\ (52- 55) + (49 - 54) + (58 - 57) + (60 - 59) + (72 - 72)}{10}\\]resolve brackets becomes:\\[\\bar{D} = \\frac{-1 + -6 + -1 + 0 + -4 + -3 + -5 + 1 + 1 + 0}{10}\\]sum top half together\\[\\bar{D} = \\frac{-18}{10}\\]Leaving us :\\[\\bar{D} = -1.8\\]find \\(\\bar{D}\\) = -1.8, mean difference Post test Pre test values.Standard Deviation DThe standard deviation formula :\\[SD = \\sqrt\\frac{\\sum(X - \\bar{X})^2}{N-1}\\]translate using D, becomes:\\[SD_{D} = \\sqrt\\frac{\\sum(D - \\bar{D})^2}{N-1}\\]:\\[SD_{D} =\\sqrt\\frac{(-1 - -1.8)^2 + (-6 - -1.8)^2 + (-1 - -1.8)^2 + (0 - -1.8)^2 + \\\\ (-4 - -1.8)^2 + (-3 - -1.8)^2 + (-5 - -1.8)^2 + (1 - -1.8)^2 + \\\\ (1 - -1.8)^2 + (0 - -1.8)^2}{10 - 1}\\]start stepping analysis dealing brackets:\\[SD_{D} =\\sqrt\\frac{(0.8)^2 + (-4.2)^2 + (0.8)^2 + (1.8)^2 + (-2.2)^2 + \\\\ (-1.2)^2 + (-3.2)^2 + (2.8)^2 + (2.8)^2 + (1.8)^2}{10 - 1}\\]square brackets\\[SD_{D} =\\sqrt\\frac{0.64 + 17.64 + 0.64 + 3.24 + 4.84 + \\\\ 1.44 + 10.24 + 7.84 + 7.84 + 3.24}{10 - 1}\\]sum values top half:\\[SD_{D} =\\sqrt\\frac{57.6}{10 - 1}\\]need sort bottom half\\[SD_{D} =\\sqrt\\frac{57.6}{9}\\]dividing top half bottom half reduces :\\[SD_{D} =\\sqrt{6.4}\\]finally take square root, leaves us :\\[SD_{D} =2.5298221\\]find \\(SD_{D}\\) = 2.5298221 two decimal places , \\(SD_{D} = 2.53\\)Calculating t-valueAnd finally t-test formula :\\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\]start filling values know see:\\[t = \\frac{-1.8}{\\frac{2.5298221}{\\sqrt{10}}} \\]deal square root first:\\[t = \\frac{-1.8}{\\frac{2.5298221}{3.1622777}} \\]divide \\(SD_{D}\\) \\(\\sqrt{N}\\) - tidying bottom formula:\\[t = \\frac{-1.8}{0.8} \\]solve \\(t\\) dividing top half bottom half gives us:\\[t = -2.25 \\], rounding two decimal places, find \\(t = -2.25\\)Degrees FreedomGreat! Now just need degrees freedom formula :\\[df = N - 1\\]already know \\(N= 10\\) putting equation get:\\[df = 10 - 1\\]reduces :\\[df = 9\\]Meaning find \\(df = 9\\)Effect Size - Cohen's dAnd finally Cohen's d, effect size. One common formulas based knowing t-value N :\\[d = \\frac{t}{\\sqrt{N}}\\], based info , know:\\(t = -2.25\\)\\(N = 10\\)putting formula get:\\[d = \\frac{-2.25}{\\sqrt{10}}\\]gives us:\\[d = \\frac{-2.25}{3.1622777}\\]:\\[d = -0.7115125\\]Meaning effect size, two decimal places, d = -0.71.Determining SignificanceIf look critical values look-table \\(df = 9\\) \\(\\alpha = .05\\) (two-tailed), see critical value \\(t_{crit} = 2.262\\). Given t-value, ignoring polarity just looking absolute value, \\(t = 2.25\\), smaller \\(t_{crit}\\) can say result significant, written t(9) = 2.25, p > .05, d = 0.71.Remember: writing report, analysis data R, see p-value actually p = 0.051, written p = 0.051","code":""},{"path":"within-subjects-t-test.html","id":"dataset-3-2","chapter":"9 Within-Subjects t-test","heading":"9.2.3 DataSet 3","text":"say starting data:first thing need calculate difference PostTest PreTest participant, based \\(D = PostTest - PreTest\\). example:Participant 1 : 56 - 62 = -6Participant 2 : 72 - 75 = -3etcAnd Participant added column differences (\\(D\\)) see:Now, within-subjects t-test formula :\\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\]can see \\(N = 10\\), need calculate \\(\\bar{D}\\) (called D-Bar, mean \\(D\\) column) \\(SD_{D}\\).Calculating D-barSo \\(\\bar{D}\\) formula mean formula:\\[\\bar{D} = \\frac{\\sum{D}}{N}\\]\\(D\\) \\(PostTest - PreTest\\) Participant.:\\[\\bar{D} = \\frac{(56 - 62) + (72 - 75) + (55 - 56) + (79 - 80) + (55 - 55) + \\\\ (69- 70) + (79 - 79) + (52 - 50) + (49 - 51) + (77 - 78)}{10}\\]resolve brackets becomes:\\[\\bar{D} = \\frac{-6 + -3 + -1 + -1 + 0 + -1 + 0 + 2 + -2 + -1}{10}\\]sum top half together\\[\\bar{D} = \\frac{-13}{10}\\]Leaving us :\\[\\bar{D} = -1.3\\]find \\(\\bar{D}\\) = -1.3, mean difference Post test Pre test values.Standard Deviation DThe standard deviation formula :\\[SD = \\sqrt\\frac{\\sum(X - \\bar{X})^2}{N-1}\\]translate using D, becomes:\\[SD_{D} = \\sqrt\\frac{\\sum(D - \\bar{D})^2}{N-1}\\]:\\[SD_{D} =\\sqrt\\frac{(-6 - -1.3)^2 + (-3 - -1.3)^2 + (-1 - -1.3)^2 + (-1 - -1.3)^2 + \\\\ (0 - -1.3)^2 + (-1 - -1.3)^2 + (0 - -1.3)^2 + (2 - -1.3)^2 + \\\\ (-2 - -1.3)^2 + (-1 - -1.3)^2}{10 - 1}\\]start stepping analysis dealing brackets:\\[SD_{D} =\\sqrt\\frac{(-4.7)^2 + (-1.7)^2 + (0.3)^2 + (0.3)^2 + (1.3)^2 + \\\\ (0.3)^2 + (1.3)^2 + (3.3)^2 + (-0.7)^2 + (0.3)^2}{10 - 1}\\]square brackets\\[SD_{D} =\\sqrt\\frac{22.09 + 2.89 + 0.09 + 0.09 + 1.69 + \\\\ 0.09 + 1.69 + 10.89 + 0.49 + 0.09}{10 - 1}\\]sum values top half:\\[SD_{D} =\\sqrt\\frac{40.1}{10 - 1}\\]need sort bottom half\\[SD_{D} =\\sqrt\\frac{40.1}{9}\\]dividing top half bottom half reduces :\\[SD_{D} =\\sqrt{4.4555556}\\]finally take square root, leaves us :\\[SD_{D} =2.1108187\\]find \\(SD_{D}\\) = 2.1108187 two decimal places , \\(SD_{D} = 2.11\\)Calculating t-valueAnd finally t-test formula :\\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\]start filling values know see:\\[t = \\frac{-1.3}{\\frac{2.1108187}{\\sqrt{10}}} \\]deal square root first:\\[t = \\frac{-1.3}{\\frac{2.1108187}{3.1622777}} \\]divide \\(SD_{D}\\) \\(\\sqrt{N}\\) - tidying bottom formula:\\[t = \\frac{-1.3}{0.6674995} \\]solve \\(t\\) dividing top half bottom half gives us:\\[t = -1.9475671 \\], rounding two decimal places, find \\(t = -1.95\\)Degrees FreedomGreat! Now just need degrees freedom formula :\\[df = N - 1\\]already know \\(N= 10\\) putting equation get:\\[df = 10 - 1\\]reduces :\\[df = 9\\]Meaning find \\(df = 9\\)Effect Size - Cohen's dAnd finally Cohen's d, effect size. One common formulas based knowing t-value N :\\[d = \\frac{t}{\\sqrt{N}}\\], based info , know:\\(t = -1.95\\)\\(N = 10\\)putting formula get:\\[d = \\frac{-1.95}{\\sqrt{10}}\\]gives us:\\[d = \\frac{-1.95}{3.1622777}\\]:\\[d = -0.6166441\\]Meaning effect size, two decimal places, d = -0.62.Determining SignificanceIf look critical values look-table \\(df = 9\\) \\(\\alpha = .05\\) (two-tailed), see critical value \\(t_{crit} = 2.262\\). Given t-value, ignoring polarity just looking absolute value, \\(t = 1.95\\), smaller \\(t_{crit}\\) can say result significant, written t(9) = 1.95, p > .05, d = 0.62.Remember: writing report, analysis data R, see p-value actually p = 0.083, written p = 0.083","code":""},{"path":"within-subjects-t-test.html","id":"look-up-table-3","chapter":"9 Within-Subjects t-test","heading":"9.3 Look-Up table","text":"Remembering \\(t_{crit}\\) value smallest t-value need find significant effect, find \\(t_{crit}\\) df, assuming \\(\\alpha = .05\\). \\(t\\) value calculated equal larger \\(t_{crit}\\) test significant.","code":""},{"path":"pearson-correlation.html","id":"pearson-correlation","chapter":"10 Pearson Correlation","heading":"10 Pearson Correlation","text":"Pearson correlation otherwise known Pearson Product-Moment correlation measures relationship two variables relationship monotonic linear. go step , relating measures covariance two variables, shared variance, standardises measure values -1 1 -1 perfect negative relationship 1 perfect positive relationship.","code":""},{"path":"pearson-correlation.html","id":"the-worked-example-6","chapter":"10 Pearson Correlation","heading":"10.1 The Worked Example","text":"say starting data:formula Pearson correlation :\\[r_{(x,y)} = \\frac{cov(x,y)}{\\sigma_{x}\\sigma_{y}}\\]Meaning , assuming consider HeadSize variable \\(x\\) IQ variable \\(y\\), determine correlation HeadSize IQ (\\(r_{(HeadSize, IQ)}\\)) first need know covariance HeadSize IQ, (\\(cov(HeadSize, IQ)\\)), well standard deviation HeadSize (\\(\\sigma_{HeadSize}\\)) standard deviation IQ (\\(\\sigma_{IQ}\\)). going look . run start finish, assuming know values. know certain aspects like covariance standard deviations can skip just running correlation good see analysis entirety.CovarianceThe formula covariance two continuous variables :\\[cov(x,y) = \\frac{\\sum_i^n(x_i - \\overline{x})(y_i - \\overline{y})}{n-1}\\]\\(\\sum_i^n\\) translates sum (.e. add ) values \\((x_i - \\overline{x})(y_i - \\overline{y})\\) pair observations data. first need know mean x (\\(\\overline{x}\\)) mean y, (\\(\\overline{y}\\)). Now know mean value sum values variable divided number values - also written :\\[\\overline{x} = \\frac{\\sum_i^n x_i}{n}\\].mean x (.e. HeadSize) :\\[\\overline{x} = \\frac{50.8 + 63.5 +  45.7  + 25.4  + 29.2  + 49.5  + 38.1  + 30.5  + 35.6  + 58.4}{10}\\]reduces :\\[\\overline{x} = \\frac{426.7}{10} = 42.67\\]repeat procedure y (.e. IQ), get:\\[\\overline{y} = \\frac{107 + 121 +  106  + 72  + 85  + 105  + 93  + 88  + 97  + 123}{10}\\]reduces :\\[\\overline{y} = \\frac{997}{10} = 99.7\\]Ok great now enough information start filling covariance formula. First, however, looking participants, look part, \\((x_i - \\overline{x})(y_i - \\overline{y})\\), one participant just make sure understand . one thing remember two sets parentheses (.e. brackets) side--side like means multiply together. , take Participant 1, see :mean x \\(\\overline{x} = 42.67\\)mean y \\(\\overline{y} = 99.7\\)HeadSize (x) \\(x_1\\) = 50.8They IQ (y) \\(y_1\\) = 107And note now saying \\(x_1\\) \\(y_1\\), longer \\(x_i\\) \\(y_i\\), know specifically dealing 1st Participant. 2nd Participants write \\(x_2\\) \\(y_2\\), 8th \\(x_8\\) \\(y_8\\), etcPutting formula Participant 1 (P1) give us:P1 = \\((x_1 - \\overline{x})(y_1 - \\overline{y}) = (50.8 - 42.67)\\times(107 - 99.7) = 8.13 \\times 7.3 = 59.349\\)can participants look like:P2 = \\((x_2 - \\overline{x})(y_2 - \\overline{y}) = (63.5 - 42.67)\\times(121 - 99.7) = 20.83\\times21.3 = 443.679\\)P3 = \\((x_3 - \\overline{x})(y_3 - \\overline{y}) = (45.7 - 42.67)\\times(106 - 99.7) = 3.03\\times6.3 = 19.089\\)P4 = \\((x_4 - \\overline{x})(y_4 - \\overline{y}) = (25.4 - 42.67)\\times(72 - 99.7) = -17.27\\times-27.7 = 478.379\\)P5 = \\((x_5 - \\overline{x})(y_5 - \\overline{y}) = (29.2 - 42.67)\\times(85 - 99.7) = -13.47\\times-14.7 = 198.009\\)P6 = \\((x_6 - \\overline{x})(y_6 - \\overline{y}) = (49.5 - 42.67)\\times(105 - 99.7) = 6.83\\times5.3 = 36.199\\)P7 = \\((x_7 - \\overline{x})(y_7 - \\overline{y}) = (38.1 - 42.67)\\times(93 - 99.7) = -4.57\\times-6.7 = 30.619\\)P8 = \\((x_8 - \\overline{x})(y_8 - \\overline{y}) = (30.5 - 42.67)\\times(88 - 99.7) = -12.17\\times-11.7 = 142.389\\)P9 = \\((x_9 - \\overline{x})(y_9 - \\overline{y}) = (35.6 - 42.67)\\times(97 - 99.7) = -7.07\\times-2.7 = 19.089\\)P10 = \\((x_10 - \\overline{x})(y_10 - \\overline{y}) = (58.4 - 42.67)\\times(123 - 99.7) = 15.73\\times23.3 = 366.509\\)remember \\(\\sum_i^n\\) part formula means formula, example 10 participants, really\\[cov(x,y) = \\frac{(x_1 - \\overline{x})(y_1 - \\overline{y})+(x_2 - \\overline{x})(y_2 - \\overline{y})+(x_3 - \\overline{x})(y_3 - \\overline{y})+(x_4 - \\overline{x})(y_4 - \\overline{y})+\\\\(x_5 - \\overline{x})(y_5 - \\overline{y})+(x_6 - \\overline{x})(y_6 - \\overline{y})+(x_7 - \\overline{x})(y_7 - \\overline{y})+(x_8 - \\overline{x})(y_8 - \\overline{y})+\\\\(x_9 - \\overline{x})(y_9 - \\overline{y})+(x_{10} - \\overline{x})(y_{10} - \\overline{y})}{n-1}\\]becomes:\\[cov(x,y) = \\frac{((50.8 - 42.67)\\times(107 - 99.7)) + ((63.5 - 42.67)\\times(121 - 99.7)) +\\\\ ((45.7 - 42.67)\\times(106 - 99.7)) + ((25.4 - 42.67)\\times(72 - 99.7)) +\\\\ ((29.2 - 42.67)\\times(85 - 99.7)) + ((49.5 - 42.67)\\times(105 - 99.7)) + \\\\((38.1 - 42.67)\\times(93 - 99.7)) + ((30.5 - 42.67)\\times(88 - 99.7)) + \\\\((35.6 - 42.67)\\times(97 - 99.7)) + ((58.4 - 42.67)\\times(123 - 99.7))}{n-1}\\], remembering rules BODMAS/PEMDAS, reduces :\\[cov(x,y) = \\frac{59.349 + 443.679 + 19.089 + 478.379 + 198.009\\\\+ 36.199 + 30.619 + 142.389 + 19.089 + 366.509}{n-1}\\]values match value calculated , know correct. know n = 10 number participants, bottom formula becomes n = 10 - 1 = 9, can reduce :\\[cov(x,y) = \\frac{1793.31}{9}\\]Leaving us covariance HeadSize (\\(x\\)) IQ (\\(y\\)) :\\[cov(x,y) = 199.2566667\\]Great! Now look back formula Pearson correlation, see:\\[r_{(x,y)} = \\frac{cov(x,y)}{\\sigma_{x}\\sigma_{y}}\\]covariance x y, divided product (multiply together) standard deviation x \\(\\sigma_{x}\\) (pronounced sigma-x) standard deviation y \\(\\sigma_{y}\\) (pronounced sigma-y). Remember \\(\\sigma\\) can also written \\(S\\) \\(SD\\) symbol Standard Deviation \\(\\sigma^2\\) (pronounced sigma-squared) symbol variance. reality, pearson correlation Head Size IQ written :\\[r_{(HeadSize,IQ)} = \\frac{cov(HeadSize,IQ)}{\\sigma_{HeadSize}\\times\\sigma_{IQ}}\\]known \\(cov(HeadSize, IQ)\\) = 199.26 (two decimal places), now need standard deviation Headsize (\\(\\sigma_{HeadSize}\\)) standard deviation IQ (\\(\\sigma_{IQ}\\)).cover standard deviation calculations Descriptives chapter, briefly recap, formula :\\[\\sigma = \\sqrt\\frac{\\sum_i^n(x_{} - \\overline{x})^2}{n-1}\\]HeadSize look like:\\[\\sigma_{HeadSize} = \\sqrt\\frac{(50.8 - 42.67)^2 + (63.5 - 42.67)^2 +(45.7 - 42.67)^2 +(25.4 - 42.67)^2 +\\\\(29.2 - 42.67)^2 +(49.5 - 42.67)^2 +(38.1 - 42.67)^2 +(30.5 - 42.67)^2 +\\\\(35.6 - 42.67)^2 +(58.4 - 42.67)^2}{10-1}\\]reduces :\\[\\sigma_{HeadSize} = \\sqrt\\frac{66.0969 + 433.8889 +9.1809 +298.2529 +\\\\181.4409 +46.6489 +20.8849 +148.1089 +\\\\49.9849 +247.4329 }{9}\\]Giving us:\\[\\sigma_{HeadSize} = \\sqrt\\frac{1501.921}{9} = \\sqrt{166.8801111} = 12.9182085\\]repeat process standard deviation IQ (\\(\\sigma_{IQ}\\)) :\\[\\sigma_{IQ} = \\sqrt\\frac{(107 - 99.7)^2 + (121 - 99.7)^2 +(106 - 99.7)^2 +(72 - 99.7)^2 +(85 - 99.7)^2 +\\\\(105 - 99.7)^2 +(93 - 99.7)^2 +(88 - 99.7)^2 +(97 - 99.7)^2 +(123 - 99.7)^2}{10-1}\\]reduces :\\[\\sigma_{IQ} = \\sqrt\\frac{53.29 + 453.69 +39.69 +767.29 +216.09 +\\\\28.09 +44.89 +136.89 +7.29 +542.89 }{9}\\]Giving us:\\[\\sigma_{IQ} = \\sqrt\\frac{2290.1}{9} = \\sqrt{254.4555556} = 15.9516631\\]know following,\\(cov(x,y)\\) = \\(cov(HeadSpace, IQ)\\) = 199.26\\(\\sigma_{x}\\) = \\(\\sigma_{HeadSpace}\\) = 12.92\\(\\sigma_{y}\\) = \\(\\sigma_{IQ}\\) = 15.95Then correlation value :\\[\\begin{align*}\nr_{(HeadSize,IQ)} &= \\frac{cov(HeadSize,IQ)}{\\sigma_{HeadSize}\\times\\sigma_{IQ}} \\\\ \\\\ &= \\frac{199.26}{12.92 \\times 15.95} \\\\ \\\\ &= \\frac{199.26}{206.074} \\\\ \\\\ &= 0.9669342\n\\end{align*}\\]Meaning correlation value , three decimal places, \\(r\\) = 0.967, , following Cohen's (1988) proposed cut-offs shown , considered show strong positive relationship. Remember cut-offs just guides value just cut-, e.g. r = .48, probably described , example, strong positive relationship.Degrees FreedomGreat! Now, finally, determine significance first need degrees freedom test. degrees freedom formula :\\[df = N - 2\\]already know \\(N= 10\\) putting equation get:\\[df = 10 - 2\\]reduces :\\[df = 8\\]Meaning find \\(df = 8\\)Writing upThe standard APA format writing Pearson correlation usually:\nr(df) = r-value, p = p-value\nknow df know r-value need now significance.Determining SignificanceIf look critical values look-table \\(df = 8\\) \\(\\alpha = .05\\), see critical value \\(r_{crit} = 0.632\\). Given r-value, ignoring polarity just looking absolute value, \\(r = 0.967\\), equal larger \\(r_{crit}\\) can say result significant, written r(8) = 0.967, p < .05.Remember: writing report, analysed data R, see p-value actually p = 0.000005014954, written p < .001","code":""},{"path":"pearson-correlation.html","id":"look-up-table-4","chapter":"10 Pearson Correlation","heading":"10.2 Look-Up table","text":"Remembering \\(r_{crit}\\) value smallest r-value need find significant effect, find \\(r_{crit}\\) value df, assuming \\(\\alpha = .05\\). \\(r\\)-value calculated equal larger \\(r_{crit}\\) value test significant.","code":""},{"path":"spearman-correlation.html","id":"spearman-correlation","chapter":"11 Spearman Correlation","heading":"11 Spearman Correlation","text":"Spearman correlation otherwise known Spearman rank correlation coefficient measures relationship two variables relationship monotonic. can used relationships linear non-linear.Pearson Correlation, Spearman correlation measures covariance two variables, shared variance, standardises measure values -1 1 -1 perfect negative relationship 1 perfect positive relationship.key difference Spearman Correlation Pearson Correlation Spearman Correlation based rank order data - .e. raw data converted ordinal ranks.ranks within variable unique - .e. tied ranks - formula Spearman Correlation follows:\\[\\rho = 1 - \\frac{6 \\times \\sum{d_i^2}}{n(n^2-1)}\\]\nstart rather simple dataset 10 participants measured two scales, B. data:orientate little, table shows Participant 1 scored 11 scale 20 scale B, Participant 2 scored 12 scale 19 scale B.Ranking dataThe first step analysis convert data scales respective rank order starting smallest value scale. example, smallest value get rank 1, second smallest value get rank 2, . data scale , get following:scores scale b, starting smallest value giving rank 1, . look like:Now scales respective rank orders, can now calculate \\(d\\), individual participants difference ranks two scales. example, Participant 1, rank 1 scale , rank 10 scale B. give \\(d\\) 1 - 10 = -9If participants get:finally want square individual values give us \\(d^2\\) participant. example, Participant 1, value d =-9, \\(d^2\\) -9 \\(\\times\\) -9 = 81And participants get:Now calculated \\(d^2\\) participant can sum altogether give us \\(\\sum{d_i^2}\\) follows:\\[\\sum{d_i^2} = 81 + 49 + 25 + 9 + 1 + 1+ 9 + 25 + 49 + 81\\]gives us:\\[\\sum{d_i^2} = 330\\]CorrelationWe can now return formula:\\[\\rho = 1 - \\frac{6 \\times \\sum{d_i^2}}{n(n^2-1)}\\]know :\\(\\sum{d_i^2} = 330\\)\\(n = 10\\)can put formula giving:\\[\\rho = 1 - \\frac{6 \\times 330}{10(10^2-1)}\\]resolve square bottom half formula, gives:\\[\\rho = 1 - \\frac{6 \\times 330}{10(100-1)}\\]subtract 1, giving:\\[\\rho = 1 - \\frac{6 \\times 330}{10(99)}\\]\nNow bottom half can really read :\\[\\rho = 1 - \\frac{6 \\times 330}{10 \\times (99)}\\], multiplication bottom half, gives us:\\[\\rho = 1 - \\frac{6 \\times 330}{990}\\]multiplication top half, get:\\[\\rho = 1 - \\frac{1980}{990}\\]divide top half bottom half give us:\\[\\rho = 1 - 2\\]final subtraction, leaving us:\\[\\rho = -1\\]Meaning Spearman rho \\(\\rho = -1\\). Following Cohen's (1988) proposed cut-offs shown , considered show strong negative relationship. Remember cut-offs just guides value just cut-, e.g. r = .48, probably described , example, strong positive relationship.Degrees FreedomGreat! Now, finally, determine significance first need degrees freedom test. degrees freedom formula :\\[df = N - 2\\]already know \\(N= 10\\) putting equation get:\\[df = 10 - 2\\]reduces :\\[df = 8\\]Meaning find \\(df = 8\\)Writing upThe standard APA format writing Spearman correlation usually:\n\\(\\rho\\)(df) = r-value, p = p-value\nalternatively\n\\(r_s\\)(df) = r-value, p = p-value\nknow df know r-value need now significance.Determining SignificanceIf look critical values look-table \\(df = 8\\) \\(\\alpha = .05\\), see critical value \\(r_{crit} = 0.632\\). Given r-value, ignoring polarity just looking absolute value, \\(r = -1\\), equal larger \\(r_{crit}\\) can say result significant, written \\(r_s\\)(8) = -1, p < .05.Remember: writing report, analysed data R, see p-value actually p = 0.00000000000000000000000000000000000000000000000000000000000001063504, written p < .001","code":""},{"path":"spearman-correlation.html","id":"look-up-table-5","chapter":"11 Spearman Correlation","heading":"11.1 Look-Up table","text":"Remembering \\(r_{crit}\\) value smallest r-value need find significant effect, find \\(r_{crit}\\) value df, assuming \\(\\alpha = .05\\). \\(r\\)-value calculated equal larger \\(r_{crit}\\) value test significant.","code":""},{"path":"simple-linear-regression.html","id":"simple-linear-regression","chapter":"12 Simple Linear Regression","heading":"12 Simple Linear Regression","text":"Simple Linear Regression analytical method looks model relationship outcome variable one explanatory predictor variables. example, thinking data used Pearson Correlation analysis book, say instead asking HeadSize IQ related, ask can reliably predict IQ scores (outcome dependent variable) HeadSize measurements (predictor independent variable), hypothesis , \"predict linear model based head size, measured cms, significantly predict IQ scores measured standard IQ test\". going look example walk analysis lets first remind data.Now order determine well Head Size predicts IQ need know underlying formula type analysis use calculate elements slope relationship intercept. might remember previous years line two-dimensional coordinate system (.e. two dimensional space made variables X Y) can described linear equation (model) form:\\[Y = b_{0} + b_{1}X + error\\]:\\(Y\\) value outcome variable Y\\(X\\) value predictor variable X\\(b_{0}\\) intercept (regression constant)  pronounced beta-zero - stated value \\(Y\\) \\(X = 0\\) X = 0\\(b_{1}\\) slope (regression coefficient)  pronounced beta-one - stated change \\(Y\\) associated one-unit increase \\(X\\)\\(error\\) measure residuals difference actual value predicted valueBefore getting full simple linear regression however look making predictions linear model formula using slope intercept, based following equations.slope:\\[b_{1} = \\frac{cov_{(x, y)}}{s^2_{x}}\\]alternatively can written ,\\[b_{1} = r_{(x,y)} \\times \\frac{s_{y}}{s_{x}}\\]intercept\\[b_{0} = \\overline{y} - b_{1} \\times \\overline{x}\\]lets spend time looking two equations turn.","code":""},{"path":"simple-linear-regression.html","id":"the-slope","chapter":"12 Simple Linear Regression","heading":"12.1 The slope:","text":", formula slope :\\[b_{1} = \\frac{cov_{(x, y)}}{s^2_{x}}\\]stated covariance x y (\\(cov_{(x,y)}\\)) divided variance x (\\(s^2_{x}\\)). translate outcome predictors , given Head Size predictor (\\(x\\)) IQ outcome (\\(y\\)), becomes:\\[b_{1} = \\frac{cov_{(HeadSize, IQ)}}{s^2_{HeadSize}}\\]can also written terms correlation two variables opposed covariance, look like:\\[b_{1} = r_{(x,y)} \\times \\frac{s_{y}}{s_{x}}\\]stated correlation x y (\\(r_{(x,y)}\\)) multiplied standard deviation y (\\(s_{y}\\)) divided standard deviation x (\\(s_{x}\\)). [Remember \\(s\\) standard deviation variable, \\(s^2\\) variance variable.]can translate back terms HeadSize (\\(x\\)) IQ (\\(y\\)) :\\[b_{1} = r \\times \\frac{s_{IQ}}{s_{HeadSize}}\\]Now think back correlation chapter actually know values need, least can calculate . know correlation chapter:\\(cov_{(x,y)}\\) = 199.26\\(s_{HeadSize}\\) = 12.92\\(s_{IQ}\\) = 15.95\\(r_{(x,y)}\\) = 0.967And can calculate variance HeadSize (\\(s^2_{HeadSize}\\)) IQ (\\(s^2_{IQ}\\)), based \\(s^2 = s \\times s\\), meaning:\\(s^2_{HeadSize}\\) = \\(12.92 \\times 12.92\\) = 166.9264\\(s^2_{IQ}\\) = \\(15.95 \\times 15.95\\) = 254.4025So really use either formula slope information, now use:\\[b_{1} = r \\times \\frac{s_{IQ}}{s_{HeadSize}}\\]start feed values, remembering IQ (\\(y\\) - outcome) HeadSize (\\(x\\) - predictor) get:\\[b_{1} = 0.967 \\times \\frac{15.95}{12.92}\\]sort fraction first, becomes:\\[b_{1} = 0.967 \\times 1.2345201\\]leads :\\[b_{1} = 1.193781\\]Giving slope \\(b_{1}\\) = 1.194, three decimal places, meaning 1 unit change \\(x\\) get 1.194 unit change \\(y\\). words, 1 unit change HeadSize get 1.194 unit change IQ.","code":""},{"path":"simple-linear-regression.html","id":"the-intercept","chapter":"12 Simple Linear Regression","heading":"12.2 The intercept","text":"Great. now know slope regression line HeadSize IQ, need next intercept. formula intercept, , :\\[b_{0} = \\overline{y} - b_{1} \\times \\overline{x}\\]stated mean y (\\(\\overline{y}\\) - case IQ, outcome) minus slope (\\(b_{1}\\)) multiplied mean x (\\(\\overline{x}\\) - case HeadSize, predictor).Looking back correlation chapter, , know:\\(b_{1}\\) = 1.194\\(\\overline{x}\\) = 42.67\\(\\overline{y}\\) = 99.7And substitute values formula get:\\[b_{0} = 99.7 - 1.194 \\times 42.67\\]Remembering BODMAS need multiplication first, gives us:\\[b_{0} = 99.7 - 50.94798\\]complete formula subtraction giving us:\\[b_{0} = 48.75202\\]Meaning intercept \\(b_{0}\\) = 48.75, two decimal places. remember intercept value \\(y\\) \\(x\\) zero, tells us \\(x\\) = 0, value \\(y\\) \\(y\\) = 48.75. stated terms HeadSize IQ, Headsize 0, IQ 48.75.","code":""},{"path":"simple-linear-regression.html","id":"making-a-prediction","chapter":"12 Simple Linear Regression","heading":"12.3 Making a Prediction","text":"Now based information gained can actually use make predictions person measured based formula:\\[\\hat{Y} = b_{0} + b_{1}X\\]Well technically \\[\\hat{Y} = b_{0} + b_{1}X + error\\]disregard error now. Also might noticed small hat \\(Y\\) making \\(\\hat{Y}\\) (pronounced Y-hat). means making prediction Y (\\(\\hat{Y}\\)) opposed actually measured (.e. observed) value (\\(Y\\)).Now say want make prediction someone HeadSize 60.1. , using information , know:slope, \\(b_{1}\\) = 1.194the intercept, \\(b_{0}\\) = 48.75and HeadSize, \\(X\\) = 60.1If put formula get:\\[\\hat{Y} = 48.75 + 1.194 \\times 60.1\\]start work , dealing multiplication first, see:\\[\\hat{Y} = 48.75 + 71.7594\\]becomes:\\[\\hat{Y} = 120.5094\\]Giving predicted value \\(\\hat{Y}\\) = 120.51, two decimal places. Meaning participant HeadSize 60.1 predict IQ 120.51. can use approach number predictions model. Say measured someone HeadSize 59.4 cm, :\\[\\hat{Y} = 48.75 + 1.194 \\times 59.4 = 119.6736\\]Meaning participant HeadSize 59.4 predict IQ 119.67.","code":""},{"path":"simple-linear-regression.html","id":"the-r-squared","chapter":"12 Simple Linear Regression","heading":"12.4 The R-squared","text":"Obviously question now good model making predictions, one measure \\(R^2\\) (pronounced R-squared). relates \\(error\\) term saw original formula, .e. \\(\\hat{Y} = b_{0} + b_{1}X + error\\), said start relates residuals. residuals might know difference predicted values observed values. example, look Participant 1 data see HeadSize 50.8 IQ 107. observed values \\(X\\) \\(Y\\) participant, predicted value participant instead (\\(\\hat{Y}\\)). Using formula see:\\[\\hat{Y} = 48.75 + 1.194 \\times 50.8 = 109.4052\\]predict Participant 1, HeadSize 50.8, IQ 109.4052. compare actually observed value participant (\\(Y = 107\\)) see difference 2.4052 IQ points (.e. \\(\\hat{Y} - Y = 2.4052\\)). difference residuals person - left part observed predicted. check observed participants get overall value summarises big small residuals , smaller residuals , better model predicting values \\(Y\\) \\(X\\), little difference predicted values observed values. \\(R^2\\) tells us. measure good model prediction, measure small residuals . \\(R^2\\) can take values 0 1 simply put, closer \\(R^2\\) 1, smaller residuals better model prediction.Now full approach calculating \\(R^2\\) show little bit, dealing simple linear regression , quick approach gives answer, :\\[R^2 = r_{(x,y)} \\times r_{(x,y)}\\]\\(r_{(x,y)}\\) correlation two variables, case Headsize (\\(x\\)) IQ (\\(y\\)). look see already know correlation HeadSize IQ, calculated correlation chapter. correlation HeadSize IQ \\(r_{(HeadSize, IQ)} = 0.967\\). put formula \\(R^2\\) see:\\[R^2 = 0.967 \\times 0.967 = 0.935089\\]Meaning \\(R^2\\) \\(R^2 = 0.935\\), three decimal places. given quite close \\(R^2\\) 1, suggest model good predicting IQ HeadSize (Y X), residuals small, strong positive relationship two variables.","code":""},{"path":"simple-linear-regression.html","id":"the-write-up-1","chapter":"12 Simple Linear Regression","heading":"12.5 The Write-up","text":"Ok great, now got lot information model including slope, intercept, \\(R^2\\). one thing actually know model significant. go means determine later part, meantime just tell model significant, (F(1, 8) = 115.07, p < .001). now everything need write :model significant - F(1, 8) = 115.07, p < .001The \\(R^2\\) = 0.935 highThe element need coefficent - relationship two variables - can take two versions; unstandardised standardised. , actually already know . just called something else:call slope, , unstandardised coefficient written \\(b\\) = 1.194what called correlation variables actually standardised coefficient written \\(\\beta\\) = 0.967And totally acceptable write-either standardised coefficient (\\(\\beta\\)) unstandardised coefficient (\\(b\\)). main thing make sure use right symbol right value mix mislead reader.Now take information , including information correlation chapter, can put blurb :team researchers interested relationship Head Size IQ, specifically whether predict IQ Head Size. researchers set hypothesis linear model based head size, measured cms, significantly predict IQ scores measured standard IQ test. Descriptive analysis suggested strong positive relationship Head Size (M = 42.67, SD = 12.92) IQ (M = 99.7, SD = 15.95), (r(8) = 0.967). analysis, linear regression model revealed head size (measured cm) significantly predicted participant scores IQ test (\\(\\beta\\) = 0.967, F(1, 8) = 115.07, p < .001, \\(R^2\\) = 0.935), head size explaining 93.5% variance IQ scores. alternative hypothesis accepted suggesting ...guess might look bit odd give standardised coeffiencient twice, just different ways, write unstandardised coefficient :team researchers interested relationship Head Size IQ, specifically whether predict IQ Head Size. researchers set hypothesis linear model based head size, measured cms, significantly predict IQ scores measured standard IQ test. Descriptive analysis suggested strong positive relationship Head Size (M = 42.67, SD = 12.92) IQ (M = 99.7, SD = 15.95), (r(8) = 0.967), head size explaining 93.5% variance IQ scores. analysis, linear regression model revealed head size (measured cm) significantly predicted participant scores IQ test (\\(b\\) = 1.194, F(1, 8) = 115.07, p < .001, \\(R^2\\) = 0.935). alternative hypothesis accepted suggesting ...","code":""},{"path":"simple-linear-regression.html","id":"test-yourself-3","chapter":"12 Simple Linear Regression","heading":"12.6 Test Yourself","text":"going try examples based . First use numbers calculated make predictions check understanding. , assuming values 1.194 slope, 48.75 intercept, try answer following questions:two decimal places, predicted value IQ HeadSize 37.8?\n\n93.88120.51119.67\nHeadSize 37.8 slope 1.194 intercept 48.75, using formula:\\[\\hat{Y} = b_{0} + b_{1}X + error\\]\nfill details:\\[\\hat{Y} = 48.75 + 1.194 \\times 37.8\\]start work , dealing multiplication first, see:\\[\\hat{Y} = 48.75 + 45.1332\\]becomes:\\[\\hat{Y} = 93.8832\\]Giving predicted value \\(\\hat{Y}\\) = 93.88, two decimal places.two decimal places, predicted value IQ HeadSize 24.2?\n\n93.8877.64119.67\nHeadSize 24.2 slope 1.194 intercept 48.75, using formula:\\[\\hat{Y} = b_{0} + b_{1}X + error\\]\nfill details:\\[\\hat{Y} = 48.75 + 1.194 \\times 24.2\\]start work , dealing multiplication first, see:\\[\\hat{Y} = 48.75 + 28.8948\\]becomes:\\[\\hat{Y} = 77.6448\\]Giving predicted value \\(\\hat{Y}\\) = 77.64, two decimal places.two decimal places, predicted value IQ HeadSize 52.9?\n\n111.91119.67120.51\nHeadSize 52.9 slope 1.194 intercept 48.75, using formula:\\[\\hat{Y} = b_{0} + b_{1}X + error\\]\nfill details:\\[\\hat{Y} = 48.75 + 1.194 \\times 52.9\\]start work , dealing multiplication first, see:\\[\\hat{Y} = 48.75 + 63.1626\\]becomes:\\[\\hat{Y} = 111.9126\\]Giving predicted value \\(\\hat{Y}\\) = 111.91, two decimal places.two decimal places, predicted value IQ HeadSize 48.4?\n\n77.64106.54119.67\nHeadSize 48.4 slope 1.194 intercept 48.75, using formula:\\[\\hat{Y} = b_{0} + b_{1}X + error\\]\nfill details:\\[\\hat{Y} = 48.75 + 1.194 \\times 48.4\\]start work , dealing multiplication first, see:\\[\\hat{Y} = 48.75 + 57.7896\\]becomes:\\[\\hat{Y} = 106.5396\\]Giving predicted value \\(\\hat{Y}\\) = 106.54, two decimal places.","code":""},{"path":"multiple-linear-regression.html","id":"multiple-linear-regression","chapter":"13 Multiple Linear Regression","heading":"13 Multiple Linear Regression","text":"say want make prediction following four people scores five OCEAN scales:say output multiple linear regression model created using five OCEAN scales predictors:","code":""},{"path":"multiple-linear-regression.html","id":"making-a-prediction-1","chapter":"13 Multiple Linear Regression","heading":"13.1 Making a Prediction","text":"Now based information gained can actually use make predictions person measured based formula:\\[\\hat{Y} = b_{0} + b_{1}X_{1} + b_{2}X_{2} + b_{3}X_{3} + b_{4}X_{4} + b_{5}X_{5}\\]Well technically \\[\\hat{Y} = b_{0} + b_{1}X_{1} + b_{2}X_{2} + b_{3}X_{3} + b_{4}X_{4} + b_{5}X_{5} + error\\]disregard error now. Also might noticed small hat \\(Y\\) making \\(\\hat{Y}\\) (pronounced Y-hat). means making prediction Y (\\(\\hat{Y}\\)) opposed actually measured (.e. observed) value (\\(Y\\)).break formula bit can say:\\(b_{0}\\) intercept model\\(b_{1}X_{1}\\), example, read non-standardised coeffecient first predictor \\(b_{1}\\) multiplied measured value first predictor \\(X_{1}\\)\\(b_{1}\\), \\(b_{2}\\), \\(b_{3}\\), \\(b_{4}\\), \\(b_{5}\\) non-standardised coefficient values different predictors model. one non-standardised coefficient predictor. example, say Openness first predictor \\(b_{1}\\) = -5.28\\(X_{1}\\), \\(X_{2}\\), \\(X_{3}\\), \\(X_{4}\\), \\(X_{5}\\) measured values different predictors participant. example, Participant 1, assuming Openness first predictor, \\(X_{1}\\) = 9. Conscientousness second predictor, Extraversion third predictor, Agreeableness fourth predictor, Neuroticism fifth predictor, \\(X_{2}\\) = 8, \\(X_{3}\\) = 5 \\(X_{4}\\) = 5., using information , know can start fill information Participant 1 follows:\\[\\hat{Y} = 197.65 + (-5.28 \\times 9) + (-5.68 \\times 8) + (-0.4 \\times 6) + (0.64 \\times 6) + (1.89 \\times 5)\\]start work , dealing multiplications first, see:\\[\\hat{Y} = 197.65 + (-47.52) + (-45.44) + (-2.4) + (3.84) + (9.45)\\]becomes:\\[\\hat{Y} = 115.58\\]Giving predicted value \\(\\hat{Y}\\) = 115.58, two decimal places.Likewise Participant 2 :\\[\\hat{Y} = 197.65 + (-5.28 \\times 8) + (-5.68 \\times 9) + (-0.4 \\times 5) + (0.64 \\times 5) + (1.89 \\times 6)\\]start work , dealing multiplications first, see:\\[\\hat{Y} = 197.65 + (-42.24) + (-51.12) + (-2) + (3.2) + (11.34)\\]becomes:\\[\\hat{Y} = 116.83\\]Giving predicted value \\(\\hat{Y}\\) = 116.83, two decimal places.Likewise Participant 3 :\\[\\hat{Y} = 197.65 + (-5.28 \\times 5) + (-5.68 \\times 6) + (-0.4 \\times 8) + (0.64 \\times 8) + (1.89 \\times 9)\\]start work , dealing multiplications first, see:\\[\\hat{Y} = 197.65 + (-26.4) + (-34.08) + (-3.2) + (5.12) + (17.01)\\]becomes:\\[\\hat{Y} = 156.1\\]Giving predicted value \\(\\hat{Y}\\) = 156.1, two decimal places.finally Participant 4 :\\[\\hat{Y} = 197.65 + (-5.28 \\times 5) + (-5.68 \\times 6) + (-0.4 \\times 9) + (0.64 \\times 9) + (1.89 \\times 8)\\]start work , dealing multiplications first, see:\\[\\hat{Y} = 197.65 + (-26.4) + (-34.08) + (-3.6) + (5.76) + (15.12)\\]becomes:\\[\\hat{Y} = 154.45\\]Giving predicted value \\(\\hat{Y}\\) = 154.45, two decimal places.summary, based model, measured values, predict following values:Participant 1, \\(\\hat{Y}\\) = 115.58Participant 2, \\(\\hat{Y}\\) = 116.83Participant 3, \\(\\hat{Y}\\) = 156.1Participant 4, \\(\\hat{Y}\\) = 154.45","code":""},{"path":"one-way-between-subjects-tables.html","id":"one-way-between-subjects-tables","chapter":"14 One-Way Between-Subjects tables","heading":"14 One-Way Between-Subjects tables","text":"chapter currently development eventually show complete ANOVAs ANOVA tables hand.","code":""},{"path":"one-way-between-subjects-tables.html","id":"the-anova-table","chapter":"14 One-Way Between-Subjects tables","heading":"14.1 The ANOVA table","text":"One-Way -Subjects Scenario: research team investigating influence mainstream media life happiness. record Life Happiness scores 0 100 higher scores meaning happy life large cohort participants split participants two groups; Group 1 (n = 72) Group 2 (n = 81). researchers want check whether difference two groups participants terms Life Happiness. Calculate F one-way ANOVA output table comparing mean Life Happiness scores across two groups participants state whether significant difference groups . Sums Squares (\\(SS\\)) given .order complete table need :determine degrees freedom (\\(df\\)) Within componentsuse \\(df\\) calculate Mean Squares (\\(MS\\))use Mean Squares calculate F-valueDegrees FreedomIn ANOVA two degrees freedom. first degrees freedom related number groups/conditions/models usually called \\(df_{}\\), \\(df_{Condition}\\), \\(df_{Model}\\). refer idea. Regardless call , df calculated :\\[df_{} = k - 1\\]\\(k\\) number conditions groups.second degrees freedom related number participants/observations/data-points usually called \\(df_{Within}\\) \\(df_{Model}\\); referring idea. df calculated :\\[df_{within} = N - k\\]\\(N\\) total number participants whole experiment \\(k\\) number conditions groups. \\(df_{within}\\) can also phrased :\\[df_{within} = \\sum_1^k(n_{k}-1)\\]can read taking 1 away \\(n\\) group (\\(k\\)) summing values together. example, total 20 participants experiment (\\(N = 20\\)) split 2 groups (\\(k = 2\\)) 10 per group (\\(n = 10\\)), :\\[df_{within} = (10-1)+(10-1) = 18\\]\\(N-k\\) (.e. 20 - 2 = 18), \\(N-k\\) easier think , use approach ., using two formulas information given us, first see two groups. :\\[df_{} = k - 1 = 2 - 1 = 1\\]Next see n = 72 Group 1, n = 81 Group 2, meaning total number participants N = 72 + 81 = 153. put formula \\(df_{Within}\\) see:\\[df_{Within} = N-k = 153 - 2 = 151\\]Meaning \\(df_{}\\) = 1, \\(df_{Within}\\) = 151, can fill table :Mean SquaresGreat! Now next step calculate Mean Square value (.e. Groups) Within (.e. Residuals) components. Mean Square really abbreviation Mean Sums Squares Sums Squares component divided degrees freedom. words:\\[MS = \\frac{SS}{df}\\]Looking table information need calculate \\(MS_{}\\) \\(MS_{Within}\\). look like:\\[MS_{} = \\frac{SS_{}}{df_{}} = \\frac{44.56}{1} = 44.56\\]\\[MS_{Within} = \\frac{SS_{Within}}{df_{Within}} = \\frac{2126.3}{151} = 14.081457\\]Meaning \\(MS_{}\\) = 44.56 \\(MS_{Within}\\) = 14.081457, can add ANOVA table :F-valueAwesome. Finally, need calculate F-value ratio \\(MS_{}\\) \\(MS_{Within}\\), can written :\\[F = \\frac{MS_{}}{MS_{Within}}\\]put numbers see:\\[F = \\frac{MS_{}}{MS_{Within}} = \\frac{44.56}{14.081457} = 3.1644453\\]Giving us F-value F = 3.16 (two decimal places), can now put table complete table :Effect sizeThere effect sizes people use ANOVA one common ones called partial eta-squared symbol \\(\\eta_p^2\\) (\\(\\eta\\) symbol \"eta\", pronounced \"eat-ah\", \\(_p^2\\) indicating \"partial\" \"squared\"). formula partial eta-squared :\\[\\eta_{p^2} = \\frac{SS_{}}{SS_{}+SS_{Within}}\\], know :\\(SS_{}\\) = 44.56 \\(SS_{Within}\\) = 2126.3And start fill formula see:\\[\\eta_p^2 = \\frac{44.56}{44.56 + 2126.3} = \\frac{44.56}{2170.86} = 0.0205264\\]Meaning analysis effect size \\(\\eta_p^2\\) = 0.02 (two decimal places).Write-UPThe standard APA format writing ANOVA usually:\nF(\\(df_{}\\), \\(df_{Within}\\)) = F-value, p = p-value, \\(\\eta_p^2\\) = effectsize-value\nknow two dfs know F-value effect size, need now determine significance.Determining SignificanceIf look critical values look-table \\(df_{}\\) = 1, \\(df_{Within}\\) = 151, \\(\\alpha = .05\\), see closest \\(df_{}\\) = 1, \\(df_{Within}\\) = 100, critical value \\(F_{crit}\\) = 3.94. Given F-value smaller \\(F_{crit}\\) can say result significant, written F(1, 151) = 3.16, p > .05, \\(\\eta_p^2\\) = 0.02.Remember: writing report, analysed data R, see p-value actually p = 0.07747604, written p = 0.077","code":""},{"path":"one-way-between-subjects-tables.html","id":"look-up-table-6","chapter":"14 One-Way Between-Subjects tables","heading":"14.2 Look-Up table","text":"Remembering \\(F_{crit}\\) value smallest F-value need find significant effect, find \\(F_{crit}\\) dfs, assuming \\(\\alpha = .05\\). \\(F\\)-value calculated equal larger \\(F_{crit}\\) test significant. table, fit page, \\(df_{}\\) written df1, \\(df_{Within}\\) written df2.","code":""},{"path":"one-way-within-subjects-tables.html","id":"one-way-within-subjects-tables","chapter":"15 One-Way Within-Subjects tables","heading":"15 One-Way Within-Subjects tables","text":"Notes:chapter currently development eventually show complete ANOVAs ANOVA tables hand.show similar groups within groups ANOVA , tweaked study One-Way -Subjects Scenario previously introduced.use term repeated measures within-subjects interchangably hereMy thanks Dr Helena Paterson building chapter.","code":""},{"path":"one-way-within-subjects-tables.html","id":"the-anova-table-1","chapter":"15 One-Way Within-Subjects tables","heading":"15.1 The ANOVA table","text":"One-Way Within-Subjects Scenario: research team investigating influence mainstream media life happiness. record Life Happiness scores 0 100 higher scores meaning happy life large cohort participants (n = 153) record life happiness scores two time points; happiness intervention intervention. researchers want check whether difference terms Life Happiness due intervention. Calculate F one-way ANOVA output table comparing mean Life Happiness scores across two time points state whether significant difference pre- post-intervention happiness scores. Sums Squares (\\(SS\\)) given .order complete table need :determine degrees freedom (\\(df\\)) Within componentsuse \\(df\\) calculate Mean Squares (\\(MS\\))use Mean Squares calculate F-valueDegrees FreedomIn ANOVA two degrees freedom. first degrees freedom related number groups/conditions/models usually called \\(df_{}\\), \\(df_{Condition}\\), \\(df_{Model}\\). refer idea. Regardless call , df calculated :\\[df_{} = k - 1\\]\\(k\\) number conditions groups.second degrees freedom related number participants/observations/data-points usually called \\(df_{Within}\\) \\(df_{Model}\\); referring idea. df calculated :\\[df_{within} = ((N \\times k) - 1) - (N - 1) - (k - 1)\\]\\(N\\) total number participants whole experiment \\(k\\) number conditions times observed participants. \\(N \\times k\\) essentially observations study collected \\(k\\) data points \\(N\\) participants.example, total 5 participants experiment (\\(N\\) = 5) measured three times dependent variable (\\(k\\) = 3) :\\[df_{within} = ((5 \\times 3)-1) - (5-1) - (3-1) = 8\\]However, \\(df_{within}\\) can also phrased simply :\\[df_{within} = (N-1)(k-1)\\]can read :subtracting one total number participants, \\(N\\),subtracting one total number conditions, \\(k\\),multiplying two values together., assuming five participants three groups, look like :\\[df_{within} = (N-1)(k-1) = (5 - 1) \\times (3 - 1) = 4 \\times 2 = 8\\], returning original study looking , first see person's happiness measured twice (intervention) - meaning \\(k\\) = 2. :\\[df_{} = (k-1) = 2 - 1 = 1\\]Next see total number participants \\(N\\) = 153. put formula \\(df_{Within}\\) see:\\[df_{Within} = (N-1)\\times(k-1) = (153 - 1)\\times(2 - 1) = 152\\]Meaning \\(df_{}\\) = 1, \\(df_{Within}\\) = 152, can fill table :Mean SquaresGreat! Now next step calculate Mean Square value (.e. Groups) Within (.e. Residuals) components. Mean Square really abbreviation Mean Sums Squares Sums Squares component divided degrees freedom. words:\\[MS = \\frac{SS}{df}\\]Looking table information need calculate \\(MS_{}\\) \\(MS_{Within}\\). look like:\\[MS_{} = \\frac{SS_{}}{df_{}} = \\frac{44.56}{1} = 44.56\\]\\[MS_{Within} = \\frac{SS_{Within}}{df_{Within}} = \\frac{2126.3}{152} = 13.9888158\\]Meaning \\(MS_{}\\) = 44.56 \\(MS_{Within}\\) = 13.9888158, can add ANOVA table :F-valueAwesome. Finally, need calculate F-value ratio \\(MS_{}\\) \\(MS_{Within}\\), can written :\\[F = \\frac{MS_{}}{MS_{Within}}\\]put numbers see:\\[F = \\frac{MS_{}}{MS_{Within}} = \\frac{44.56}{13.9888158} = 3.1854019\\]Giving us F-value F = 3.19 (two decimal places), can now put table complete table :Effect sizeThere effect sizes people use ANOVA one common ones called partial eta-squared symbol \\(\\eta_p^2\\) (\\(\\eta\\) symbol \"eta\", pronounced \"eat-ah\", \\(_p^2\\) indicating \"partial\" \"squared\"). formula partial eta-squared :\\[\\eta_{p^2} = \\frac{SS_{}}{SS_{}+SS_{Within}}\\], know :\\(SS_{}\\) = 44.56 \\(SS_{Within}\\) = 2126.3And start fill formula see:\\[\\eta_p^2 = \\frac{44.56}{44.56 + 2126.3} = \\frac{44.56}{2170.86} = 0.0205264\\]Meaning analysis effect size \\(\\eta_p^2\\) = 0.02 (two decimal places).Write-UPThe standard APA format writing ANOVA usually:\nF(\\(df_{}\\), \\(df_{Within}\\)) = F-value, p = p-value, \\(\\eta_p^2\\) = effectsize-value\nknow two dfs know F-value effect size, need now determine significance.Determining SignificanceIf look critical values look-table \\(df_{}\\) = 1, \\(df_{Within}\\) = 152, \\(\\alpha = .05\\), see closest \\(df_{}\\) = 1, \\(df_{Within}\\) = 100, critical value \\(F_{crit}\\) = 3.94. Given F-value smaller \\(F_{crit}\\) can say result significant, written F(1, 152) = 3.19, p > .05, \\(\\eta_p^2\\) = 0.02.Remember: writing report, analysed data R, see p-value actually p = 0.0760836, written p = 0.076","code":""},{"path":"one-way-within-subjects-tables.html","id":"look-up-table-7","chapter":"15 One-Way Within-Subjects tables","heading":"15.2 Look-Up table","text":"Remembering \\(F_{crit}\\) value smallest F-value need find significant effect, find \\(F_{crit}\\) dfs, assuming \\(\\alpha = .05\\). \\(F\\)-value calculated equal larger \\(F_{crit}\\) test significant. table, fit page, \\(df_{}\\) written df1, \\(df_{Within}\\) written df2.","code":""},{"path":"random-formulas.html","id":"random-formulas","chapter":"16 Random formulas","heading":"16 Random formulas","text":"formulas eventually move somewhere makes sense now need home :","code":""},{"path":"random-formulas.html","id":"t-value-to-r-value","chapter":"16 Random formulas","heading":"16.1 t-value to r-value","text":"know conversion t-value r-value :\\[r = \\sqrt\\frac{t^2}{t^2 + df}\\]conversion r-value t-value :\\[t = \\sqrt\\frac{df * r^2}{1-r^2}\\]formulas, \\(df\\) degrees freedom respective analysis carried . example, carried correlation r-value want t-value, use df correlation make conversion. Likewise, carried t-test want r-value, use df t-test make conversion.","code":""},{"path":"the-rounding-chapter.html","id":"the-rounding-chapter","chapter":"17 The Rounding Chapter","heading":"17 The Rounding Chapter","text":"One stumbling block people face first working statistics rounding values appropriately. chapter contains examples try help check rounding correctly.Rounding PsychologyThe idea behind rounding reduces numbers shown output makes values readable. example, instead presenting mean M = 12.4251126, present M = 12.43.First thing understand level want round . Often see things written \"rounded two decimal places\" \"3 d.p.\" d.p. short decimal places. telling number values decimal point output rounded . \"rounded two decimal places\" means show two numbers decimal point, whereas \"rounded three decimal places\" means show three numbers decimal point. table gives overview mean various decimal places guide:principle behind rounding look value position level want round see \"less 5\" \"equal greater 5\". value \"less 5\" round - meaning value stays . value \"equal greater 5\" round - meaning value goes next value. example easier look .","code":""},{"path":"the-rounding-chapter.html","id":"worked-example","chapter":"17 The Rounding Chapter","heading":"17.1 Worked Example","text":"say want round M = 12.4251126 different levels.Rounding three decimal placesFirst lets round three decimal places. need look value fourth decimal place. value fourth decimal place 1. value less 5, round 12.4251126 becomes 12.425Rounding two decimal placesLets now round M = 12.4251126 two decimal places - two values decimal point. need look value third decimal place. value third decimal place 5. value equal greater 5, round 12.4251126 becomes 12.43","code":""},{"path":"the-rounding-chapter.html","id":"test-yourself-4","chapter":"17 The Rounding Chapter","heading":"17.2 Test Yourself","text":"Example 1Now examples just see can follow .reason answer 0.47 question asks two decimal places need look third decimal value original number - instance 1. value less 5, round 0.472 becomes 0.47Example 2The reason answer -1.85 question asks two decimal places need look third decimal value original number - instance 4. value less 5, round -1.855 becomes -1.85Example 3The reason answer -1.066 question asks three decimal places need look fourth decimal value original number - instance 0. value less 5, round -1.0661 becomes -1.066Example 4The reason answer -2.083 question asks three decimal places need look fourth decimal value original number - instance 1. value less 5, round -2.0831 becomes -2.083Example 5The reason answer 0.019 question asks three decimal places need look fourth decimal value original number - instance 5. value equal greater 5, round 0.0186 becomes 0.019","code":""},{"path":"license.html","id":"license","chapter":"License","heading":"License","text":"book licensed Creative Commons Attribution-ShareAlike 4.0 International License (CC--SA 4.0). free share adapt book. must give appropriate credit, provide link license, indicate changes made. adapt material, must distribute contributions license original.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
