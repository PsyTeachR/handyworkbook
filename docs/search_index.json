[
["index.html", "A Handy Workbook for Research Methods and Statistics Overview", " A Handy Workbook for Research Methods and Statistics Last Update: 2020-12-13 Overview PLEASE NOTE THIS BOOK IS IN EARLY STAGES OF DEVELOPMENT AND MAY VERY WELL CONTAIN MISTAKES Authors: Phil McAleer Aim: A Handy Workbook to help students understand Research Methods and Statistics through worked examples and self-tests. Contact: This book is a living document and will be regularly checked and updated for improvements. Should you have any issues using the book or queries, please contact Phil McAleer. R Version: This book has been written with R version 3.5.1 (2018-07-02) Randomising Seed: In chapters that use some level of randomisation, where we have remembered, the seed is set as 1409. "],
["one-sample-chi-square.html", "Chapter 1 One-Sample Chi-Square 1.1 The Worked Example 1.2 Test Yourself 1.3 ChiSquare Look-up Table", " Chapter 1 One-Sample Chi-Square 1.1 The Worked Example Here is our data: Values A B C D Observed 4 5 8 15 And if we add on a column showing the total number of participants, adding all the numbers in the different conditions together, (i.e. 4 + 5 + 8 + 15 = 32), then we get: Values A B C D Total Observed 4 5 8 15 32 Now the formula for the chi-square is: \\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] The Expected values for each condition, in a one-sample chi-square assuming a uniform (equal) distribution is calculated by \\(N \\times \\frac{1}{k}\\) where \\(k\\) is the number of conditions and \\(N\\) is the total number of participants. This can also be written more straightforward as \\(N/k\\). That means that in our example the expected value in each condition would be: \\[Expected = \\frac{N}{k} = \\frac{32}{4} = 8\\] Let’s now add those Expected values to our table which looks like: Values A B C D Total Observed 4 5 8 15 32 Expected 8 8 8 8 32 We now have our data, let’s start putting it into the formula, which we said was: \\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] Which really means: \\[\\chi^2 = \\frac{(Observed_{A} - Expected_{A})^2}{Expected_{A}} + \\frac{(Observed_{B} - Expected_{B})^2}{Expected_{B}} + \\frac{(Observed_{C} - Expected_{C})^2}{Expected_{C}} + \\\\ \\frac{(Observed_{D} - Expected_{D})^2}{Expected_{D}}\\] So \\[\\chi^2 = \\frac{(4 - 8)^2}{8}+\\frac{(5 - 8)^2}{8}+\\frac{(8 - 8)^2}{8}+\\frac{(15 - 8)^2}{8}\\] Which becomes: \\[\\chi^2 = \\frac{(-4)^2}{8} + \\frac{(-3)^2}{8} + \\frac{(0)^2}{8} + \\frac{(7)^2}{8}\\] And if we now square the top halves (the numerators): \\[\\chi^2 = \\frac{16}{8} + \\frac{9}{8} + \\frac{0}{8} + \\frac{49}{8}\\] Then divide the top half by the bottom half for each condition: \\[\\chi^2 = {2}+{1.125}+{0}+{6.125}\\] And finally add them altogether \\[\\chi^2 = 9.25\\] So we find that \\(\\chi^2 = 9.25\\) The degrees of freedom in this test is \\(k - 1\\) and given that we have 4 conditions: \\[df = k - 1\\] \\[df = 4 - 1\\] \\[df = 3\\] The effect size A common effect size for the one-sample chi-square test is \\(\\phi\\) (pronounced “ph-aye” and can be written as “phi”). The formula for \\(\\phi\\) is: \\[\\phi = \\sqrt\\frac{\\chi^2}{N}\\] And if we know that \\(\\chi^2 =9.25\\) and that \\(N = 32\\), then putting them into the formula we get: \\[\\phi = \\sqrt\\frac{9.25}{32}\\] \\[\\phi = 0.5376453\\] The write-up If we were to look at a critical value look-up table, we would see that the critical value associated with a \\(df = 3\\) at \\(\\alpha = .05\\), to three decimal places, is \\(\\chi^2_{crit} = 7.815\\). As the chi-square value of this test (i.e. \\(\\chi^2 = 9.25\\)) is larger than \\(\\chi^2_{crit}\\) then we can say that our test is significant, and as such would be written up as \\(\\chi^2(df = 3, N = 32) = 9.25,p &lt; .05\\). Finally, if our test was significant then all we need to do is state the condition with the highest frequency (i.e. the mode), which in this case is Condition D 1.2 Test Yourself 1.2.1 DataSet 1 Here is our data: Values A B C D Observed 14 19 2 20 Show me the working and answer And if we add on a column showing the total number of participants, adding all the numbers in the different conditions together, (i.e. 14 + 19 + 2 + 20 = 55), then we get: Values A B C D Total Observed 14 19 2 20 55 Now the formula for the chi-square is: \\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] The Expected values for each condition, in a one-sample chi-square assuming a uniform (equal) distribution is calculated by \\(N \\times \\frac{1}{k}\\) where \\(k\\) is the number of conditions and \\(N\\) is the total number of participants. This can also be written more straightforward as \\(N/k\\). That means that in our example the expected value in each condition would be: \\[Expected = \\frac{N}{k} = \\frac{55}{4} = 13.75\\] Let’s now add those Expected values to our table which looks like: Values A B C D Total Observed 14.00 19.00 2.00 20.00 55 Expected 13.75 13.75 13.75 13.75 55 We now have our data, let’s start putting it into the formula, which we said was: \\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] So \\[\\chi^2 = \\frac{(14 - 13.75)^2}{13.75}+\\frac{(19 - 13.75)^2}{13.75}+\\frac{(2 - 13.75)^2}{13.75}+\\frac{(20 - 13.75)^2}{13.75}\\] Which becomes: \\[\\chi^2 = \\frac{(0.25)^2}{13.75} + \\frac{(5.25)^2}{13.75} + \\frac{(-11.75)^2}{13.75} + \\frac{(6.25)^2}{13.75}\\] And if we now square the top halves (the numerators): \\[\\chi^2 = \\frac{0.0625}{13.75} + \\frac{27.5625}{13.75} + \\frac{138.0625}{13.75} + \\frac{39.0625}{13.75}\\] Then divide the top half by the bottom half for each condition: \\[\\chi^2 = {0.0045455}+{2.0045455}+{10.0409091}+{2.8409091}\\] And finally add them altogether \\[\\chi^2 = 14.8909091\\] So we find that \\(\\chi^2 = 14.8909091\\) The degrees of freedom in this test is \\(k - 1\\) and given that we have 4 conditions: \\[df = k - 1\\] \\[df = 4 - 1\\] \\[df = 3\\] The effect size A common effect size for the one-sample chi-square test is \\(\\phi\\) (pronounced “ph-aye” and can be written as “phi”). The formula for \\(\\phi\\) is: \\[\\phi = \\sqrt\\frac{\\chi^2}{N}\\] And if we know that \\(\\chi^2 =14.8909091\\) and that \\(N = 55\\), then putting them into the formula we get: \\[\\phi = \\sqrt\\frac{14.8909091}{55}\\] \\[\\phi = 0.5203305\\] The write-up If we were to look at a critical value look-up table, we would see that the critical value associated with a \\(df = 3\\) at \\(\\alpha = .05\\), to three decimal places, is \\(\\chi^2_{crit} = 7.815\\). As the chi-square value of this test (i.e. \\(\\chi^2 = 14.8909091\\)) is larger than \\(\\chi^2_{crit}\\) then we can say that our test is significant, and as such would be written up as \\(\\chi^2(df = 3, N = 55) = 14.8909091,p &lt; .05\\). Finally, if our test was significant then all we need to do is state the condition with the highest frequency (i.e. the mode), which in this case is Condition D 1.2.2 DataSet 2 Here is our data: Values A B C D Observed 2 8 7 20 Show me the working and answer And if we add on a column showing the total number of participants, adding all the numbers in the different conditions together, (i.e. 2 + 8 + 7 + 20 = 37), then we get: Values A B C D Total Observed 2 8 7 20 37 Now the formula for the chi-square is: \\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] The Expected values for each condition, in a one-sample chi-square assuming a uniform (equal) distribution is calculated by \\(N \\times \\frac{1}{k}\\) where \\(k\\) is the number of conditions and \\(N\\) is the total number of participants. This can also be written more straightforward as \\(N/k\\). That means that in our example the expected value in each condition would be: \\[Expected = \\frac{N}{k} = \\frac{37}{4} = 9.25\\] Let’s now add those Expected values to our table which looks like: Values A B C D Total Observed 2.00 8.00 7.00 20.00 37 Expected 9.25 9.25 9.25 9.25 37 We now have our data, let’s start putting it into the formula, which we said was: \\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] So \\[\\chi^2 = \\frac{(2 - 9.25)^2}{9.25}+\\frac{(8 - 9.25)^2}{9.25}+\\frac{(7 - 9.25)^2}{9.25}+\\frac{(20 - 9.25)^2}{9.25}\\] Which becomes: \\[\\chi^2 = \\frac{(-7.25)^2}{9.25} + \\frac{(-1.25)^2}{9.25} + \\frac{(-2.25)^2}{9.25} + \\frac{(10.75)^2}{9.25}\\] And if we now square the top halves (the numerators): \\[\\chi^2 = \\frac{52.5625}{9.25} + \\frac{1.5625}{9.25} + \\frac{5.0625}{9.25} + \\frac{115.5625}{9.25}\\] Then divide the top half by the bottom half for each condition: \\[\\chi^2 = {5.6824324}+{0.1689189}+{0.5472973}+{12.4932432}\\] And finally add them altogether \\[\\chi^2 = 18.8918919\\] So we find that \\(\\chi^2 = 18.8918919\\) The degrees of freedom in this test is \\(k - 1\\) and given that we have 4 conditions: \\[df = k - 1\\] \\[df = 4 - 1\\] \\[df = 3\\] The effect size A common effect size for the one-sample chi-square test is \\(\\phi\\) (pronounced “ph-aye” and can be written as “phi”). The formula for \\(\\phi\\) is: \\[\\phi = \\sqrt\\frac{\\chi^2}{N}\\] And if we know that \\(\\chi^2 =18.8918919\\) and that \\(N = 37\\), then putting them into the formula we get: \\[\\phi = \\sqrt\\frac{18.8918919}{37}\\] \\[\\phi = 0.714557\\] The write-up If we were to look at a critical value look-up table, we would see that the critical value associated with a \\(df = 3\\) at \\(\\alpha = .05\\), to three decimal places, is \\(\\chi^2_{crit} = 7.815\\). As the chi-square value of this test (i.e. \\(\\chi^2 = 18.8918919\\)) is larger than \\(\\chi^2_{crit}\\) then we can say that our test is significant, and as such would be written up as \\(\\chi^2(df = 3, N = 37) = 18.8918919,p &lt; .05\\). Finally, if our test was significant then all we need to do is state the condition with the highest frequency (i.e. the mode), which in this case is Condition D 1.2.3 DataSet 3 Here is our data: Values A B C D Observed 5 10 14 11 Show me the working and answer And if we add on a column showing the total number of participants, adding all the numbers in the different conditions together, (i.e. 5 + 10 + 14 + 11 = 40), then we get: Values A B C D Total Observed 5 10 14 11 40 Now the formula for the chi-square is: \\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] The Expected values for each condition, in a one-sample chi-square assuming a uniform (equal) distribution is calculated by \\(N \\times \\frac{1}{k}\\) where \\(k\\) is the number of conditions and \\(N\\) is the total number of participants. This can also be written more straightforward as \\(N/k\\). That means that in our example the expected value in each condition would be: \\[Expected = \\frac{N}{k} = \\frac{40}{4} = 10\\] Let’s now add those Expected values to our table which looks like: Values A B C D Total Observed 5 10 14 11 40 Expected 10 10 10 10 40 We now have our data, let’s start putting it into the formula, which we said was: \\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] So \\[\\chi^2 = \\frac{(5 - 10)^2}{10}+\\frac{(10 - 10)^2}{10}+\\frac{(14 - 10)^2}{10}+\\frac{(11 - 10)^2}{10}\\] Which becomes: \\[\\chi^2 = \\frac{(-5)^2}{10} + \\frac{(0)^2}{10} + \\frac{(4)^2}{10} + \\frac{(1)^2}{10}\\] And if we now square the top halves (the numerators): \\[\\chi^2 = \\frac{25}{10} + \\frac{0}{10} + \\frac{16}{10} + \\frac{1}{10}\\] Then divide the top half by the bottom half for each condition: \\[\\chi^2 = {2.5}+{0}+{1.6}+{0.1}\\] And finally add them altogether \\[\\chi^2 = 4.2\\] So we find that \\(\\chi^2 = 4.2\\) The degrees of freedom in this test is \\(k - 1\\) and given that we have 4 conditions: \\[df = k - 1\\] \\[df = 4 - 1\\] \\[df = 3\\] The effect size A common effect size for the one-sample chi-square test is \\(\\phi\\) (pronounced “ph-aye” and can be written as “phi”). The formula for \\(\\phi\\) is: \\[\\phi = \\sqrt\\frac{\\chi^2}{N}\\] And if we know that \\(\\chi^2 =4.2\\) and that \\(N = 40\\), then putting them into the formula we get: \\[\\phi = \\sqrt\\frac{4.2}{40}\\] \\[\\phi = 0.324037\\] The write-up If we were to look at a critical value look-up table, we would see that the critical value associated with a \\(df = 3\\) at \\(\\alpha = .05\\), to three decimal places, is \\(\\chi^2_{crit} = 7.815\\). As the chi-square value of this test (i.e. \\(\\chi^2 = 4.2\\)) is smaller than \\(\\chi^2_{crit}\\) then we can say that our test is non-significant, and as such would be written up as \\(\\chi^2(df = 3, N = 40) = 4.2,p &gt; .05\\). Finally, if our test was significant then all we need to do is state the condition with the highest frequency (i.e. the mode), which in this case is Condition C 1.3 ChiSquare Look-up Table df \\(\\alpha = .05\\) 1 3.841 2 5.991 3 7.815 4 9.488 5 11.07 6 12.592 7 14.067 8 15.507 9 16.919 10 18.307 "],
["chi-square-cross-tabulation.html", "Chapter 2 Chi-Square Cross-Tabulation 2.1 The Worked Example 2.2 Test Yourself 2.3 ChiSquare Look-up Table", " Chapter 2 Chi-Square Cross-Tabulation 2.1 The Worked Example Here is our data: Groups Yes No A 88 93 B 160 59 We are going to need to know the Column Totals and Row Totals and the Total number of participants (N), so lets calculate them add them to our tables: Group A Row Total = 88 + 93 = 181 Group B Row Total = 160 + 59 = 219 Yes Column Total = 88 + 160 = 248 No Column Total = 93 + 59 = 152 N = 88 + 93 +160 + 59 = 400 And if we add those to our table we see: Groups Yes No Totals A 88 93 181 B 160 59 219 Totals 248 152 400 Now the formula for the chi-square is: \\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] The Expected values for each condition, in the cross-tabulation in a few ways but the one we will use here is probably the easiest to use and it is: \\[Expected = \\frac{Total_{row} \\times Total_{column}}{N_{total}}\\] This is the same as other versions you might have seen such as: \\[Expected = \\frac{Total_{row}}{N_{total}} \\times \\frac{Total_{column}}{N_{total}} \\times N_{total}\\] The will both give the same result. So using the first approach we would see that the Expected values are: For Group A people that said Yes: \\[Expected_{A-Yes} = \\frac{181 \\times 248}{400} = \\frac{44888}{400} = 112.22\\] For Group A people that said No: \\[Expected_{A-No} = \\frac{181 \\times 152}{400} = \\frac{27512}{400} = 68.78\\] For Group B people that said Yes: \\[Expected_{B-Yes} = \\frac{219 \\times 248}{400} = \\frac{54312}{400} = 135.78\\] For Group B people that said No: \\[Expected_{B-No} = \\frac{219 \\times 152}{400} = \\frac{33288}{400} = 83.22\\] We now have our data, let’s start putting it into the formula, which we said was: \\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] Which really means: \\[\\chi^2 = \\frac{(Observed_{A-Yes} - Expected_{A-Yes})^2}{Expected_{A-Yes}} + \\frac{(Observed_{A-No} - Expected_{A-No})^2}{Expected_{A-No}} + \\\\ \\frac{(Observed_{B-Yes} - Expected_{B-Yes})^2}{Expected_{B-Yes}} + \\frac{(Observed_{B-No} - Expected_{B-No})^2}{Expected_{B-No}}\\] And if we start putting in the values, becomes: \\[\\chi^2 = \\frac{(88 - 112.22)^2}{112.22}+ \\frac{(93 - 68.78)^2}{68.78}+\\frac{(160 - 135.78)^2}{135.78}+\\frac{(59 - 83.22)^2}{83.22}\\] And if we start to tidy those top halves up a little it becomes: \\[\\chi^2 = \\frac{(-24.22)^2}{112.22}+ \\frac{(24.22)^2}{68.78}+\\frac{(24.22)^2}{135.78}+\\frac{(-24.22)^2}{83.22}\\] And now we square those top halves to give: \\[\\chi^2 = \\frac{586.6084}{112.22} + \\frac{586.6084}{68.78} + \\frac{586.6084}{135.78} + \\frac{586.6084}{83.22} \\] And then divide the top halves by the bottom halves \\[\\chi^2 = {5.2273071} + {8.5287642} + {4.3202858} + {7.0488873}\\] And then we sum them altogether to find: \\[\\chi^2 = 25.1252443 \\] Meaning that, rounded to two decimal places, we find \\(\\chi^2 = 25.13\\) Degrees of Freedom The degrees of freedom for the cross-tabulation is calculated as: \\[df = (Rows - 1) \\times (Columns - 1)\\] Which is read as the number of Rows minus 1 times the number of Columns minus 1. If we look at our original data again: Groups Yes No A 88 93 B 160 59 Looking at the table we see we have 2 rows and 2 columns of actual observed data (not looking at the titles and group names), so: \\[Rows - 1 = 2 - 1 = 1\\] And \\[Columns - 1 = 2 - 1 = 1\\] Meaning that: \\[df = (Rows - 1) \\times (Columns - 1)\\] which becomes: \\[df = (2 - 1) \\times (2 - 1)\\] And reduces to: \\[df = (1) \\times (1)\\] leaving us with: \\[df = 1\\] so we see that \\(df = 1\\) The effect size One of the common effect sizes for a cross-tabulation chi-square test is Cramer’s \\(V\\) and is calculated as: \\[V = \\sqrt\\frac{\\chi^2}{N \\times \\min(C-1, R-1)}\\] The key thing to note is \\(\\min(C-1, R-1)\\) which is read as the minimum of EITHER the number of Columns (C) minus 1 OR the number of Rows (R) minus 1; whichever of those two values is smallest. And the minimum of Columns minus 1 or Rows minus 1 is: \\[\\min(C-1, R-1) = \\min( 2 - 1, 2 - 1)\\] \\[\\min(C-1, R-1) = \\min( 1, 1)\\] which gives us: \\[\\min(C-1, R-1) = 1\\] And now we can start completing the Cramer’s \\(V\\) formula as we know: \\(\\chi^2 = 25.13\\) \\(N = 400\\) \\(\\min(C-1, R-1) = 1\\) Giving us: \\[V = \\sqrt\\frac{25.13}{400 \\times 1}\\] And if we deal with the bottom half first we get: \\[V = \\sqrt\\frac{25.13}{400}\\] Then if we divide the top by the bottom we get \\[V = \\sqrt{0.062825}\\] Giving us: \\[V = 0.2506492\\] So we see that, rounded to two decimal places, the effect size is \\(V = 0.25\\) The write-up If we were to look at a critical value look-up table, we would see that the critical value associated with a \\(df = 1\\) at \\(\\alpha = .05\\), to three decimal places, is \\(\\chi^2_{crit} = 3.841\\). As the chi-square value of this test (i.e. \\(\\chi^2 = 25.13\\)) is larger than \\(\\chi^2_{crit}\\) then we can say that our test is significant, and as such would be written up as \\(\\chi^2(df = 1, N = 400) = 25.13,p &lt; .05, V = 0.25\\). If our test was significant then we would go on to carry out the relevant one-sample chi-squares to breakdown how the association manifests itself. The key thing to remember however is that in these one-sample chi-squares, following the cross-tabulation, you MUST use the expected values from the cross-tabulation and do not calculate new expected values. For instance if you were looking at the one-sample chi-square within Group A, then you would use the expected values of \\(Expected_{A-Yes} = 112.22\\) and \\(Expected_{A-No} = 68.78\\) to compare against the observed values of \\(Observed_{A-Yes} = 88\\) and \\(Observed_{A-No} = 93\\) as such: \\[\\chi^2 = \\frac{(88 - 112.22)^2}{112.22}+ \\frac{(93 - 68.78)^2}{68.78}\\] Which if you walk the process through you find: \\[\\chi^2 = 13.7560713\\] Meaning that, rounded to two decimal places, we find \\(\\chi^2 = 13.76\\) To Be Continued 2.2 Test Yourself 2.2.1 DataSet 1 To Be Added 2.3 ChiSquare Look-up Table df \\(\\alpha = .05\\) 1 3.841 2 5.991 3 7.815 4 9.488 5 11.07 6 12.592 7 14.067 8 15.507 9 16.919 10 18.307 "],
["between-subjects-students-t-test.html", "Chapter 3 Between-Subjects Student’s t-test 3.1 The Worked Example 3.2 Test Yourself 3.3 Look-Up table", " Chapter 3 Between-Subjects Student’s t-test between-subjects t-test: Compare two groups or conditions where the participants are different in each group and have not been matched or are only matched on broad demographics, e.g. only age. 3.1 The Worked Example Here is your data: Group N Mean SD A 47 26.45 2.44 B 47 28.38 2.88 Let’s look at the main t-test formula: \\[t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p \\times \\sqrt{\\frac{1}{N_1} + \\frac{1}{N_2}}}\\] Now, from the table above we know: the mean of Group A is \\(\\bar{X_1} = 26.45\\), the mean of Group B is \\(\\bar{X_2} = 28.38\\), the N of Group A is \\(N_1 = 47\\), and the N of Group B is \\(N_2 = 47\\), which we can put into the equation right now: \\[t = \\frac{26.45 - 28.38}{s_p \\times \\sqrt{\\frac{1}{47} + \\frac{1}{47}}}\\] And now we can see that the only thing we don’t yet know is the pooled standard deviation (\\(s_p\\)). Let’s look at that formula: Calculating the pooled standard deviation \\[s_p = \\sqrt{\\frac{(n_1 -1) \\times s^2_{X_1} + (n_2 -1)\\times s^2_{X_2}}{n_1 + n_2 - 2}}\\] And if we start to fill in some details: \\[s_p = \\sqrt{\\frac{(47 -1) \\times s^2_{X_1} + (47 -1)\\times s^2_{X_2}}{47 + 47 - 2}}\\] Now looking at the formula, it is clear we are missing: \\(s^2_{X_1}\\) - the variance of Group A (could be written as \\(s^2_{A}\\)) \\(s^2_{X_2}\\) - the variance of Group B (could be written as \\(s^2_{B}\\)) What we do know though, from the table, is the standard deviations of both groups (\\(SD_A\\) = 2.44; \\(SD_B\\) = 2.88), and we know that variance of a group is equal to the standard deviation squared. So: \\(s^2_{X_1}\\) = \\(s^2_A\\) = \\(SD_A \\times SD_A\\) = \\(2.44 \\times 2.44\\) = \\(5.9536\\) \\(s^2_{X_2}\\) = \\(s^2_B\\) = \\(SD_B \\times SD_B\\) = \\(2.88 \\times 2.88\\) = \\(8.2944\\) And if we now add those values to our formula we get: \\[s_p = \\sqrt{\\frac{(47 -1) \\times 5.9536 + (47 -1)\\times 8.2944}{47 + 47 - 2}}\\] And we can then start working through the formula, taking each stage in turn to make sure we don’t make mistakes. Let’s get rid of the brackets first: \\[s_p = \\sqrt{\\frac{(46 \\times 5.9536) + (46 \\times 8.2944)}{92}}\\] Now we deal with the multiplications: \\[s_p = \\sqrt{\\frac{273.8656 + 381.5424}{92}}\\] Let’s tidy up that top half of the equation (the numerator): \\[s_p = \\sqrt{\\frac{655.408}{92}}\\] Which if we then divide the numerator by the denominator (the bottom half), and then take the square root of that we get: \\[s_p = \\sqrt{7.124}\\] Giving a pooled standard deviation of: \\[s_p = 2.6690822\\] Meaning that our pooled standard deviation, rounded to three decimal places, is \\(s_p = 2.669\\) and we can now add that to the t-test formula to give us: Calculating the t-value \\[t = \\frac{26.45 - 28.38}{2.669 \\times \\sqrt{\\frac{1}{47} + \\frac{1}{47}}}\\] And again we just start working through the formula. Let’s deal with the fractions relating to sample size first: \\[t = \\frac{26.45 - 28.38}{2.669 \\times \\sqrt{0.0212766 + 0.0212766}}\\] Which we can tidy up a little to give: \\[t = \\frac{-1.93}{2.669 \\times \\sqrt{0.0425532}}\\] And if we sort out the square root on the denominator we are left with: \\[t = \\frac{-1.93}{2.669 \\times 0.2062842}\\] We can then tidy up the denominator to give us: \\[t = \\frac{-1.93}{0.5505727}\\] Which we can finally solve to give us a t-value, rounded to two decimal places, of \\(t = -3.51\\) Degrees of Freedom Great! Now we just need the degrees of freedom where the formula is: \\[df = (n_1 - 1) + (n_2 - 1)\\] And we already know that: the N of Group A is \\(N_1 = 47\\), and the N of Group B is \\(N_2 = 47\\), So putting them into the equation we get: \\[df = (47 - 1) + (47 - 1)\\] \\[df = 46 + 46\\] \\[df = 92\\] Effect Size: Cohen’s d And finally Cohen’s d, the effect size: \\[d = \\frac{2t}{\\sqrt{df}}\\] Which, based on the info above, we know: \\(t = -3.51\\) \\(df = 92\\) Putting them into the formula we get: \\[d = \\frac{2 \\times -3.51}{\\sqrt{92}}\\] And if we tidy the nominator and the denominator we get: \\[d = \\frac{-7.02}{9.591663}\\] Which we can then solve to learn that \\(d = -0.73\\) Determining Significance If we were to look at a critical values look-up table for \\(df = 92\\) and \\(\\alpha = .05\\) (two-tailed), we would see that the critical value is \\(t_{crit} = 1.986\\). Given that our t-value, ignoring polarity and just looking at the absolute value, so \\(t = 3.51\\), is equal to or larger than our \\(t_{crit}\\) then we can say our result is significant, and as such would be written up as t(92) = 3.51, p &lt; .05, d = 0.73 Remember: If you were writing this up as a report, and analysis the data in R, then you would see the p-value was actually p = 6.959109810^{-4}, and would be written up as p &lt; .001 3.2 Test Yourself 3.2.1 DataSet 1 Here is your data: Group N Mean SD A 48 13.13 2.28 B 48 14.06 2.43 Show me the working and answer Let’s look at the main t-test formula: \\[t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p \\times \\sqrt{\\frac{1}{N_1} + \\frac{1}{N_2}}}\\] Now, from the table above we know: the mean of Group A is \\(\\bar{X_1} = 13.13\\), the mean of Group B is \\(\\bar{X_2} = 14.06\\), the N of Group A is \\(N_1 = 48\\), and the N of Group B is \\(N_2 = 48\\), which we can put into the equation right now: \\[t = \\frac{13.13 - 14.06}{s_p \\times \\sqrt{\\frac{1}{48} + \\frac{1}{48}}}\\] And now we can see that the only thing we don’t yet know is the pooled standard deviation (\\(s_p\\)). Let’s look at that formula: \\[s_p = \\sqrt{\\frac{(n_1 -1) \\times s^2_{X_1} + (n_2 -1)\\times s^2_{X_2}}{n_1 + n_2 - 2}}\\] And if we start to fill in some details: \\[s_p = \\sqrt{\\frac{(48 -1) \\times s^2_{X_1} + (48 -1)\\times s^2_{X_2}}{48 + 48 - 2}}\\] Now looking at the formula, it is clear we are missing: \\(s^2_{X_1}\\) - the variance of Group A (could be written as \\(s^2_{A}\\)) \\(s^2_{X_2}\\) - the variance of Group B (could be written as \\(s^2_{B}\\)) What we do know though, from the table, is the standard deviations of both groups (\\(SD_A\\) = 2.28; \\(SD_B\\) = 2.43), and we know that variance of a group is equal to the standard deviation squared. So: \\(s^2_{X_1}\\) = \\(s^2_A\\) = \\(SD_A \\times SD_A\\) = \\(2.28 \\times 2.28\\) = \\(5.1984\\) \\(s^2_{X_2}\\) = \\(s^2_B\\) = \\(SD_B \\times SD_B\\) = \\(2.43 \\times 2.43\\) = \\(5.9049\\) And if we now add those values to our formula we get: \\[s_p = \\sqrt{\\frac{(48 -1) \\times 5.1984 + (48 -1)\\times 5.9049}{48 + 48 - 2}}\\] And we can then start working through the formula, taking each stage in turn to make sure we don’t make mistakes. Let’s get rid of the brackets first: \\[s_p = \\sqrt{\\frac{(47 \\times 5.1984) + (47 \\times 5.9049)}{94}}\\] Now we deal with the multiplications: \\[s_p = \\sqrt{\\frac{244.3248 + 277.5303}{94}}\\] Let’s tidy up that top half of the equation (the numerator): \\[s_p = \\sqrt{\\frac{521.8551}{94}}\\] Which if we then divide the numerator by the denominator (the bottom half), and then take the square root of that we get: \\[s_p = \\sqrt{5.55165}\\] Giving a pooled standard deviation of: \\[s_p = 2.356194\\] Meaning that our pooled standard deviation, rounded to three decimal places, is \\(s_p = 2.356\\) and we can now add that to the t-test formula to give us: \\[t = \\frac{13.13 - 14.06}{2.356 \\times \\sqrt{\\frac{1}{48} + \\frac{1}{48}}}\\] And again we just start working through the formula. Let’s deal with the fractions relating to sample size first: \\[t = \\frac{13.13 - 14.06}{2.356 \\times \\sqrt{0.0208333 + 0.0208333}}\\] Which we can tidy up a little to give: \\[t = \\frac{-0.93}{2.356 \\times \\sqrt{0.0416667}}\\] And if we sort out the square root on the denominator we are left with: \\[t = \\frac{-0.93}{2.356 \\times 0.2041241}\\] We can then tidy up the denominator to give us: \\[t = \\frac{-0.93}{0.4809165}\\] Which we can finally solve to give us a t-value, rounded to two decimal places, of \\(t = -1.93\\) Great! Now we just need the degrees of freedom where the formula is: \\[df = (n_1 - 1) + (n_2 - 1)\\] And we already know that: the N of Group A is \\(N_1 = 48\\), and the N of Group B is \\(N_2 = 48\\), So putting them into the equation we get: \\[df = (48 - 1) + (48 - 1)\\] \\[df = 47 + 47\\] \\[df = 94\\] And finally Cohen’s d, the effect size: \\[d = \\frac{2t}{\\sqrt{df}}\\] Which, based on the info above, we know: \\(t = -1.93\\) \\(df = 94\\) Putting them into the formula we get: \\[d = \\frac{2 \\times -1.93}{\\sqrt{94}}\\] And if we tidy the nominator and the denominator we get: \\[d = \\frac{-3.86}{9.6953597}\\] Which we can then solve to learn that \\(d = -0.4\\) Determining Significance If we were to look at a critical values look-up table for \\(df = 94\\) and \\(\\alpha = .05\\) (two-tailed), we would see that the critical value is \\(t_{crit} = 1.986\\). Given that our t-value, ignoring polarity and just looking at the absolute value, so \\(t = 1.93\\), is smaller than our \\(t_{crit}\\) then we can say our result is non-significant, and as such would be written up as t(94) = 1.93, p &gt; .05, d = 0.4 Remember: If you were writing this up as a report, and analysis the data in R, then you would see the p-value was actually p = 0.0566217, and would be written up as p = 0.057 3.2.2 DataSet 2 Here is your data: Group N Mean SD A 17 12.93 1.33 B 17 12.47 1.67 Show me the working and answer Let’s look at the main t-test formula: \\[t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p \\times \\sqrt{\\frac{1}{N_1} + \\frac{1}{N_2}}}\\] Now, from the table above we know: the mean of Group A is \\(\\bar{X_1} = 12.93\\), the mean of Group B is \\(\\bar{X_2} = 12.47\\), the N of Group A is \\(N_1 = 17\\), and the N of Group B is \\(N_2 = 17\\), which we can put into the equation right now: \\[t = \\frac{12.93 - 12.47}{s_p \\times \\sqrt{\\frac{1}{17} + \\frac{1}{17}}}\\] And now we can see that the only thing we don’t yet know is the pooled standard deviation (\\(s_p\\)). Let’s look at that formula: \\[s_p = \\sqrt{\\frac{(n_1 -1) \\times s^2_{X_1} + (n_2 -1)\\times s^2_{X_2}}{n_1 + n_2 - 2}}\\] And if we start to fill in some details: \\[s_p = \\sqrt{\\frac{(17 -1) \\times s^2_{X_1} + (17 -1)\\times s^2_{X_2}}{17 + 17 - 2}}\\] Now looking at the formula, it is clear we are missing: \\(s^2_{X_1}\\) - the variance of Group A (could be written as \\(s^2_{A}\\)) \\(s^2_{X_2}\\) - the variance of Group B (could be written as \\(s^2_{B}\\)) What we do know though, from the table, is the standard deviations of both groups (\\(SD_A\\) = 1.33; \\(SD_B\\) = 1.67), and we know that variance of a group is equal to the standard deviation squared. So: \\(s^2_{X_1}\\) = \\(s^2_A\\) = \\(SD_A \\times SD_A\\) = \\(1.33 \\times 1.33\\) = \\(1.7689\\) \\(s^2_{X_2}\\) = \\(s^2_B\\) = \\(SD_B \\times SD_B\\) = \\(1.67 \\times 1.67\\) = \\(2.7889\\) And if we now add those values to our formula we get: \\[s_p = \\sqrt{\\frac{(17 -1) \\times 1.7689 + (17 -1)\\times 2.7889}{17 + 17 - 2}}\\] And we can then start working through the formula, taking each stage in turn to make sure we don’t make mistakes. Let’s get rid of the brackets first: \\[s_p = \\sqrt{\\frac{(16 \\times 1.7689) + (16 \\times 2.7889)}{32}}\\] Now we deal with the multiplications: \\[s_p = \\sqrt{\\frac{28.3024 + 44.6224}{32}}\\] Let’s tidy up that top half of the equation (the numerator): \\[s_p = \\sqrt{\\frac{72.9248}{32}}\\] Which if we then divide the numerator by the denominator (the bottom half), and then take the square root of that we get: \\[s_p = \\sqrt{2.2789}\\] Giving a pooled standard deviation of: \\[s_p = 1.5096026\\] Meaning that our pooled standard deviation, rounded to three decimal places, is \\(s_p = 1.51\\) and we can now add that to the t-test formula to give us: \\[t = \\frac{12.93 - 12.47}{1.51 \\times \\sqrt{\\frac{1}{17} + \\frac{1}{17}}}\\] And again we just start working through the formula. Let’s deal with the fractions relating to sample size first: \\[t = \\frac{12.93 - 12.47}{1.51 \\times \\sqrt{0.0588235 + 0.0588235}}\\] Which we can tidy up a little to give: \\[t = \\frac{0.46}{1.51 \\times \\sqrt{0.1176471}}\\] And if we sort out the square root on the denominator we are left with: \\[t = \\frac{0.46}{1.51 \\times 0.3429972}\\] We can then tidy up the denominator to give us: \\[t = \\frac{0.46}{0.5179257}\\] Which we can finally solve to give us a t-value, rounded to two decimal places, of \\(t = 0.89\\) Great! Now we just need the degrees of freedom where the formula is: \\[df = (n_1 - 1) + (n_2 - 1)\\] And we already know that: the N of Group A is \\(N_1 = 17\\), and the N of Group B is \\(N_2 = 17\\), So putting them into the equation we get: \\[df = (17 - 1) + (17 - 1)\\] \\[df = 16 + 16\\] \\[df = 32\\] And finally Cohen’s d, the effect size: \\[d = \\frac{2t}{\\sqrt{df}}\\] Which, based on the info above, we know: \\(t = 0.89\\) \\(df = 32\\) Putting them into the formula we get: \\[d = \\frac{2 \\times 0.89}{\\sqrt{32}}\\] And if we tidy the nominator and the denominator we get: \\[d = \\frac{1.78}{5.6568542}\\] Which we can then solve to learn that \\(d = 0.31\\) Determining Significance If we were to look at a critical values look-up table for \\(df = 32\\) and \\(\\alpha = .05\\) (two-tailed), we would see that the critical value is \\(t_{crit} = 2.037\\). Given that our t-value, ignoring polarity and just looking at the absolute value, so \\(t = 0.89\\), is smaller than our \\(t_{crit}\\) then we can say our result is non-significant, and as such would be written up as t(32) = 0.89, p &gt; .05, d = 0.31 Remember: If you were writing this up as a report, and analysis the data in R, then you would see the p-value was actually p = 0.3801084, and would be written up as p = 0.377 3.2.3 DataSet 3 Here is your data: Group N Mean SD A 23 53.99 4.37 B 23 53.30 3.29 Show me the working and answer Let’s look at the main t-test formula: \\[t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p \\times \\sqrt{\\frac{1}{N_1} + \\frac{1}{N_2}}}\\] Now, from the table above we know: the mean of Group A is \\(\\bar{X_1} = 53.99\\), the mean of Group B is \\(\\bar{X_2} = 53.3\\), the N of Group A is \\(N_1 = 23\\), and the N of Group B is \\(N_2 = 23\\), which we can put into the equation right now: \\[t = \\frac{53.99 - 53.3}{s_p \\times \\sqrt{\\frac{1}{23} + \\frac{1}{23}}}\\] And now we can see that the only thing we don’t yet know is the pooled standard deviation (\\(s_p\\)). Let’s look at that formula: \\[s_p = \\sqrt{\\frac{(n_1 -1) \\times s^2_{X_1} + (n_2 -1)\\times s^2_{X_2}}{n_1 + n_2 - 2}}\\] And if we start to fill in some details: \\[s_p = \\sqrt{\\frac{(23 -1) \\times s^2_{X_1} + (23 -1)\\times s^2_{X_2}}{23 + 23 - 2}}\\] Now looking at the formula, it is clear we are missing: \\(s^2_{X_1}\\) - the variance of Group A (could be written as \\(s^2_{A}\\)) \\(s^2_{X_2}\\) - the variance of Group B (could be written as \\(s^2_{B}\\)) What we do know though, from the table, is the standard deviations of both groups (\\(SD_A\\) = 4.37; \\(SD_B\\) = 3.29), and we know that variance of a group is equal to the standard deviation squared. So: \\(s^2_{X_1}\\) = \\(s^2_A\\) = \\(SD_A \\times SD_A\\) = \\(4.37 \\times 4.37\\) = \\(19.0969\\) \\(s^2_{X_2}\\) = \\(s^2_B\\) = \\(SD_B \\times SD_B\\) = \\(3.29 \\times 3.29\\) = \\(10.8241\\) And if we now add those values to our formula we get: \\[s_p = \\sqrt{\\frac{(23 -1) \\times 19.0969 + (23 -1)\\times 10.8241}{23 + 23 - 2}}\\] And we can then start working through the formula, taking each stage in turn to make sure we don’t make mistakes. Let’s get rid of the brackets first: \\[s_p = \\sqrt{\\frac{(22 \\times 19.0969) + (22 \\times 10.8241)}{44}}\\] Now we deal with the multiplications: \\[s_p = \\sqrt{\\frac{420.1318 + 238.1302}{44}}\\] Let’s tidy up that top half of the equation (the numerator): \\[s_p = \\sqrt{\\frac{658.262}{44}}\\] Which if we then divide the numerator by the denominator (the bottom half), and then take the square root of that we get: \\[s_p = \\sqrt{14.9605}\\] Giving a pooled standard deviation of: \\[s_p = 3.8678806\\] Meaning that our pooled standard deviation, rounded to three decimal places, is \\(s_p = 3.868\\) and we can now add that to the t-test formula to give us: \\[t = \\frac{53.99 - 53.3}{3.868 \\times \\sqrt{\\frac{1}{23} + \\frac{1}{23}}}\\] And again we just start working through the formula. Let’s deal with the fractions relating to sample size first: \\[t = \\frac{53.99 - 53.3}{3.868 \\times \\sqrt{0.0434783 + 0.0434783}}\\] Which we can tidy up a little to give: \\[t = \\frac{0.69}{3.868 \\times \\sqrt{0.0869565}}\\] And if we sort out the square root on the denominator we are left with: \\[t = \\frac{0.69}{3.868 \\times 0.2948839}\\] We can then tidy up the denominator to give us: \\[t = \\frac{0.69}{1.140611}\\] Which we can finally solve to give us a t-value, rounded to two decimal places, of \\(t = 0.6\\) Great! Now we just need the degrees of freedom where the formula is: \\[df = (n_1 - 1) + (n_2 - 1)\\] And we already know that: the N of Group A is \\(N_1 = 23\\), and the N of Group B is \\(N_2 = 23\\), So putting them into the equation we get: \\[df = (23 - 1) + (23 - 1)\\] \\[df = 22 + 22\\] \\[df = 44\\] And finally Cohen’s d, the effect size: \\[d = \\frac{2t}{\\sqrt{df}}\\] Which, based on the info above, we know: \\(t = 0.6\\) \\(df = 44\\) Putting them into the formula we get: \\[d = \\frac{2 \\times 0.6}{\\sqrt{44}}\\] And if we tidy the nominator and the denominator we get: \\[d = \\frac{1.2}{6.6332496}\\] Which we can then solve to learn that \\(d = 0.18\\) Determining Significance If we were to look at a critical values look-up table for \\(df = 44\\) and \\(\\alpha = .05\\) (two-tailed), we would see that the critical value is \\(t_{crit} = 2.015\\). Given that our t-value, ignoring polarity and just looking at the absolute value, so \\(t = 0.6\\), is smaller than our \\(t_{crit}\\) then we can say our result is non-significant, and as such would be written up as t(44) = 0.6, p &gt; .05, d = 0.18 Remember: If you were writing this up as a report, and analysis the data in R, then you would see the p-value was actually p = 0.551584, and would be written up as p = 0.543 3.3 Look-Up table Remembering that the \\(t_{crit}\\) value is the smallest t-value you need to find a significant effect, find the \\(t_{crit}\\) for your df, assuming \\(\\alpha = .05\\). If the \\(t\\) value you calculated is equal to or larger than \\(t_{crit}\\) then your test is significant. df \\(\\alpha = .05\\) 1 12.706 2 4.303 3 3.182 4 2.776 5 2.571 6 2.447 7 2.365 8 2.306 9 2.262 10 2.228 15 2.131 20 2.086 30 2.042 40 2.021 50 2.009 60 2 70 1.994 80 1.99 90 1.987 100 1.984 "],
["within-subjects-t-test.html", "Chapter 4 Within-Subjects t-test 4.1 The Worked Example 4.2 Test Yourself 4.3 Look-Up table", " Chapter 4 Within-Subjects t-test within-subjects t-test: Compare two conditions where the participants are the same in both conditions (or more rarely are different participants that have been highly matched on a number of demographics such as IQ, reading ability, etc - must be matched on a number of demographics). 4.1 The Worked Example Let’s say that this is our starting data: Participants PreTest PostTest 1 60 68 2 64 75 3 56 62 4 82 85 5 74 73 6 79 85 7 63 64 8 59 59 9 72 73 10 66 70 The first thing we need to do is calculate the difference between the PostTest and the PreTest for each participant, based on \\(D = PostTest - PreTest\\). So for example: Participant 1 would be: 68 - 60 = 8 Participant 2 would be: 75 - 64 = 11 etc And if we do that for each Participant and added a column of the differences (\\(D\\)) then we would see: Participants PreTest PostTest D 1 60 68 8 2 64 75 11 3 56 62 6 4 82 85 3 5 74 73 -1 6 79 85 6 7 63 64 1 8 59 59 0 9 72 73 1 10 66 70 4 Now, the within-subjects t-test formula is: \\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\] We can see that \\(N = 10\\), but we need to calculate \\(\\bar{D}\\) (called D-Bar, the mean of the \\(D\\) column) and \\(SD_{D}\\). Calculating D-bar So the \\(\\bar{D}\\) formula is the same as the mean formula: \\[\\bar{D} = \\frac{\\sum{D}}{N}\\] Where \\(D\\) is \\(PostTest - PreTest\\) for each Participant. Then: \\[\\bar{D} = \\frac{(68 - 60) + (75 - 64) + (62 - 56) + (85 - 82) + (73 - 74) + \\\\ (85- 79) + (64 - 63) + (59 - 59) + (73 - 72) + (70 - 66)}{10}\\] Which if we resolve all the brackets becomes: \\[\\bar{D} = \\frac{8 + 11 + 6 + 3 + -1 + 6 + 1 + 0 + 1 + 2}{10}\\] And if we sum the top half together \\[\\bar{D} = \\frac{39}{10}\\] Leaving us with: \\[\\bar{D} = 3.9\\] So we find that \\(\\bar{D}\\) = 3.9, which is the mean difference between the Post test and Pre test values. The Standard Deviation of D The standard deviation formula is: \\[SD = \\sqrt\\frac{(X - \\bar{X})^2}{N-1}\\] Which if we translate to using D, becomes: \\[SD_{D} = \\sqrt\\frac{(D - \\bar{D})^2}{N-1}\\] Then: \\[SD_{D} =\\sqrt\\frac{(8 - 3.9)^2 + (11 - 3.9)^2 + (6 - 3.9)^2 + (3 - 3.9)^2 + (-1 - 3.9)^2 + \\\\ (6 - 3.9)^2 + (1 - 3.9)^2 + (0 - 3.9)^2 + (1 - 3.9)^2 + (4 - 3.9)^2}{10 - 1}\\] And if we start stepping through this analysis by dealing with the brackets: \\[SD_{D} =\\sqrt\\frac{(4.1)^2 + (7.1)^2 + (2.1)^2 + (-0.9)^2 + (-4.9)^2 + \\\\ (2.1)^2 + (-2.9)^2 + (-3.9)^2 + (-2.9)^2 + (0.1)^2}{10 - 1}\\] And then we square those brackets \\[SD_{D} =\\sqrt\\frac{16.81 + 50.41 + 4.41 + 0.81 + 24.01 + 4.41 + 8.41 + 15.21 + 8.41 + 0.01}{10 - 1}\\] And sum up all the values on the top half: \\[SD_{D} =\\sqrt\\frac{132.9}{10 - 1}\\] And then we need to sort out the bottom half \\[SD_{D} =\\sqrt\\frac{132.9}{9}\\] Which by dividing the top half by the bottom half reduces down to: \\[SD_{D} =\\sqrt{14.7666667}\\] And then we finally take the square root, which leaves us with: \\[SD_{D} =3.8427421\\] And so we find that the \\(SD_{D}\\) = 3.8427421 which to two decimal places would be, \\(SD_{D} = 3.84\\) Calculating the t-value And finally the t-test formula is: \\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\] Then if we start filling in the values we know from above we see: \\[t = \\frac{3.9}{\\frac{3.8427421}{\\sqrt{10}}} \\] And if we deal with the square root first: \\[t = \\frac{3.9}{\\frac{3.8427421}{3.1622777}} \\] And divide \\(SD_{D}\\) by \\(\\sqrt{N}\\) - tidying up the bottom of the formula: \\[t = \\frac{3.9}{1.2151817} \\] And then solve for \\(t\\) by dividing the top half by the bottom half gives us: \\[t = 3.2093965 \\] And so, rounding to two decimal places, we find that \\(t = 3.21\\) Degrees of Freedom Great! Now we just need the degrees of freedom where the formula is: \\[df = N - 1\\] And we already know that \\(N= 10\\) and putting them into the equation we get: \\[df = 10 - 1\\] Which reduces to: \\[df = 9\\] Meaning that we find a \\(df = 9\\) Effect Size - Cohen’s d And finally Cohen’s d, the effect size. One of the common formulas based on knowing the t-value and the N is: \\[d = \\frac{t}{\\sqrt{N}}\\] Which, based on the info above, we know: \\(t = 3.21\\) \\(N = 10\\) And putting those into the formula we get: \\[d = \\frac{3.21}{\\sqrt{10}}\\] Which gives us: \\[d = \\frac{3.21}{3.1622777}\\] And so: \\[d = 1.0150911\\] Meaning that the effect size, to two decimal places, is d = 1.01. Determining Significance If we were to look at a critical values look-up table for \\(df = 9\\) and \\(\\alpha = .05\\) (two-tailed), we would see that the critical value is \\(t_{crit} = 2.262\\). Given that our t-value, ignoring polarity and just looking at the absolute value, so \\(t = 3.21\\), is equal to or larger than our \\(t_{crit}\\) then we can say our result is significant, and as such would be written up as t(9) = 3.21, p &lt; .05, d = 1.01. Remember: If you were writing this up as a report, and analysis the data in R, then you would see the p-value was actually p = 0.011, and would be written up as p = 0.011 4.2 Test Yourself 4.2.1 DataSet 1 Let’s say that this is our starting data: Participants PreTest PostTest 1 71 66 2 78 75 3 53 54 4 73 67 5 79 75 6 60 62 7 75 74 8 52 52 9 55 48 10 62 60 Show me the working and answer The first thing we need to do is calculate the difference between the PostTest and the PreTest for each participant, based on \\(D = PostTest - PreTest\\). So for example: Participant 1 would be: 66 - 71 = -5 Participant 2 would be: 75 - 78 = -3 etc And if we do that for each Participant and added a column of the differences (\\(D\\)) then we would see: Participants PreTest PostTest D 1 71 66 -5 2 78 75 -3 3 53 54 1 4 73 67 -6 5 79 75 -4 6 60 62 2 7 75 74 -1 8 52 52 0 9 55 48 -7 10 62 60 -2 Now, the within-subjects t-test formula is: \\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\] We can see that \\(N = 10\\), but we need to calculate \\(\\bar{D}\\) (called D-Bar, the mean of the \\(D\\) column) and \\(SD_{D}\\). Calculating D-bar So the \\(\\bar{D}\\) formula is the same as the mean formula: \\[\\bar{D} = \\frac{\\sum{D}}{N}\\] Where \\(D\\) is \\(PostTest - PreTest\\) for each Participant. Then: \\[\\bar{D} = \\frac{(66 - 71) + (75 - 78) + (54 - 53) + (67 - 73) + (75 - 79) + \\\\ (62- 60) + (74 - 75) + (52 - 52) + (48 - 55) + (60 - 62)}{10}\\] Which if we resolve all the brackets becomes: \\[\\bar{D} = \\frac{-5 + -3 + 1 + -6 + -4 + 2 + -1 + 0 + -7 + 4}{10}\\] And if we sum the top half together \\[\\bar{D} = \\frac{-25}{10}\\] Leaving us with: \\[\\bar{D} = -2.5\\] So we find that \\(\\bar{D}\\) = -2.5, which is the mean difference between the Post test and Pre test values. The Standard Deviation of D The standard deviation formula is: \\[SD = \\sqrt\\frac{(X - \\bar{X})^2}{N-1}\\] Which if we translate to using D, becomes: \\[SD_{D} = \\sqrt\\frac{(D - \\bar{D})^2}{N-1}\\] Then: \\[SD_{D} =\\sqrt\\frac{(-5 - -2.5)^2 + (-3 - -2.5)^2 + (1 - -2.5)^2 + (-6 - -2.5)^2 + (-4 - -2.5)^2 + \\\\ (2 - -2.5)^2 + (-1 - -2.5)^2 + (0 - -2.5)^2 + (-7 - -2.5)^2 + (-2 - -2.5)^2}{10 - 1}\\] And if we start stepping through this analysis by dealing with the brackets: \\[SD_{D} =\\sqrt\\frac{(-2.5)^2 + (-0.5)^2 + (3.5)^2 + (-3.5)^2 + (-1.5)^2 + \\\\ (4.5)^2 + (1.5)^2 + (2.5)^2 + (-4.5)^2 + (0.5)^2}{10 - 1}\\] And then we square those brackets \\[SD_{D} =\\sqrt\\frac{6.25 + 0.25 + 12.25 + 12.25 + 2.25 + 20.25 + 2.25 + 6.25 + 20.25 + 0.25}{10 - 1}\\] And sum up all the values on the top half: \\[SD_{D} =\\sqrt\\frac{82.5}{10 - 1}\\] And then we need to sort out the bottom half \\[SD_{D} =\\sqrt\\frac{82.5}{9}\\] Which by dividing the top half by the bottom half reduces down to: \\[SD_{D} =\\sqrt{9.1666667}\\] And then we finally take the square root, which leaves us with: \\[SD_{D} =3.0276504\\] And so we find that the \\(SD_{D}\\) = 3.0276504 which to two decimal places would be, \\(SD_{D} = 3.03\\) Calculating the t-value And finally the t-test formula is: \\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\] Then if we start filling in the values we know from above we see: \\[t = \\frac{-2.5}{\\frac{3.0276504}{\\sqrt{10}}} \\] And if we deal with the square root first: \\[t = \\frac{-2.5}{\\frac{3.0276504}{3.1622777}} \\] And divide \\(SD_{D}\\) by \\(\\sqrt{N}\\) - tidying up the bottom of the formula: \\[t = \\frac{-2.5}{0.9574271} \\] And then solve for \\(t\\) by dividing the top half by the bottom half gives us: \\[t = -2.6111648 \\] And so, rounding to two decimal places, we find that \\(t = -2.61\\) Degrees of Freedom Great! Now we just need the degrees of freedom where the formula is: \\[df = N - 1\\] And we already know that \\(N= 10\\) and putting them into the equation we get: \\[df = 10 - 1\\] Which reduces to: \\[df = 9\\] Meaning that we find a \\(df = 9\\) Effect Size - Cohen’s d And finally Cohen’s d, the effect size. One of the common formulas based on knowing the t-value and the N is: \\[d = \\frac{t}{\\sqrt{N}}\\] Which, based on the info above, we know: \\(t = -2.61\\) \\(N = 10\\) And putting those into the formula we get: \\[d = \\frac{-2.61}{\\sqrt{10}}\\] Which gives us: \\[d = \\frac{-2.61}{3.1622777}\\] And so: \\[d = -0.8253545\\] Meaning that the effect size, to two decimal places, is d = -0.83. Determining Significance If we were to look at a critical values look-up table for \\(df = 9\\) and \\(\\alpha = .05\\) (two-tailed), we would see that the critical value is \\(t_{crit} = 2.262\\). Given that our t-value, ignoring polarity and just looking at the absolute value, so \\(t = 2.61\\), is equal to or larger than our \\(t_{crit}\\) then we can say our result is not significant, and as such would be written up as t(9) = 2.61, p &lt; .05, d = 0.83. Remember: If you were writing this up as a report, and analysis the data in R, then you would see the p-value was actually p = 0.028, and would be written up as p = 0.028 4.2.2 DataSet 2 Let’s say that this is our starting data: Participants PreTest PostTest 1 70 66 2 79 80 3 56 52 4 63 64 5 50 52 6 59 52 7 65 59 8 62 64 9 74 74 10 66 67 Show me the working and answer The first thing we need to do is calculate the difference between the PostTest and the PreTest for each participant, based on \\(D = PostTest - PreTest\\). So for example: Participant 1 would be: 66 - 70 = -4 Participant 2 would be: 80 - 79 = 1 etc And if we do that for each Participant and added a column of the differences (\\(D\\)) then we would see: Participants PreTest PostTest D 1 70 66 -4 2 79 80 1 3 56 52 -4 4 63 64 1 5 50 52 2 6 59 52 -7 7 65 59 -6 8 62 64 2 9 74 74 0 10 66 67 1 Now, the within-subjects t-test formula is: \\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\] We can see that \\(N = 10\\), but we need to calculate \\(\\bar{D}\\) (called D-Bar, the mean of the \\(D\\) column) and \\(SD_{D}\\). Calculating D-bar So the \\(\\bar{D}\\) formula is the same as the mean formula: \\[\\bar{D} = \\frac{\\sum{D}}{N}\\] Where \\(D\\) is \\(PostTest - PreTest\\) for each Participant. Then: \\[\\bar{D} = \\frac{(66 - 70) + (80 - 79) + (52 - 56) + (64 - 63) + (52 - 50) + \\\\ (52- 59) + (59 - 65) + (64 - 62) + (74 - 74) + (67 - 66)}{10}\\] Which if we resolve all the brackets becomes: \\[\\bar{D} = \\frac{-4 + 1 + -4 + 1 + 2 + -7 + -6 + 2 + 0 + 0}{10}\\] And if we sum the top half together \\[\\bar{D} = \\frac{-14}{10}\\] Leaving us with: \\[\\bar{D} = -1.4\\] So we find that \\(\\bar{D}\\) = -1.4, which is the mean difference between the Post test and Pre test values. The Standard Deviation of D The standard deviation formula is: \\[SD = \\sqrt\\frac{(X - \\bar{X})^2}{N-1}\\] Which if we translate to using D, becomes: \\[SD_{D} = \\sqrt\\frac{(D - \\bar{D})^2}{N-1}\\] Then: \\[SD_{D} =\\sqrt\\frac{(-4 - -1.4)^2 + (1 - -1.4)^2 + (-4 - -1.4)^2 + (1 - -1.4)^2 + (2 - -1.4)^2 + \\\\ (-7 - -1.4)^2 + (-6 - -1.4)^2 + (2 - -1.4)^2 + (0 - -1.4)^2 + (1 - -1.4)^2}{10 - 1}\\] And if we start stepping through this analysis by dealing with the brackets: \\[SD_{D} =\\sqrt\\frac{(-2.6)^2 + (2.4)^2 + (-2.6)^2 + (2.4)^2 + (3.4)^2 + \\\\ (-5.6)^2 + (-4.6)^2 + (3.4)^2 + (1.4)^2 + (2.4)^2}{10 - 1}\\] And then we square those brackets \\[SD_{D} =\\sqrt\\frac{6.76 + 5.76 + 6.76 + 5.76 + 11.56 + 31.36 + 21.16 + 11.56 + 1.96 + 5.76}{10 - 1}\\] And sum up all the values on the top half: \\[SD_{D} =\\sqrt\\frac{108.4}{10 - 1}\\] And then we need to sort out the bottom half \\[SD_{D} =\\sqrt\\frac{108.4}{9}\\] Which by dividing the top half by the bottom half reduces down to: \\[SD_{D} =\\sqrt{12.0444444}\\] And then we finally take the square root, which leaves us with: \\[SD_{D} =3.4705107\\] And so we find that the \\(SD_{D}\\) = 3.4705107 which to two decimal places would be, \\(SD_{D} = 3.47\\) Calculating the t-value And finally the t-test formula is: \\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\] Then if we start filling in the values we know from above we see: \\[t = \\frac{-1.4}{\\frac{3.4705107}{\\sqrt{10}}} \\] And if we deal with the square root first: \\[t = \\frac{-1.4}{\\frac{3.4705107}{3.1622777}} \\] And divide \\(SD_{D}\\) by \\(\\sqrt{N}\\) - tidying up the bottom of the formula: \\[t = \\frac{-1.4}{1.0974718} \\] And then solve for \\(t\\) by dividing the top half by the bottom half gives us: \\[t = -1.2756592 \\] And so, rounding to two decimal places, we find that \\(t = -1.28\\) Degrees of Freedom Great! Now we just need the degrees of freedom where the formula is: \\[df = N - 1\\] And we already know that \\(N= 10\\) and putting them into the equation we get: \\[df = 10 - 1\\] Which reduces to: \\[df = 9\\] Meaning that we find a \\(df = 9\\) Effect Size - Cohen’s d And finally Cohen’s d, the effect size. One of the common formulas based on knowing the t-value and the N is: \\[d = \\frac{t}{\\sqrt{N}}\\] Which, based on the info above, we know: \\(t = -1.28\\) \\(N = 10\\) And putting those into the formula we get: \\[d = \\frac{-1.28}{\\sqrt{10}}\\] Which gives us: \\[d = \\frac{-1.28}{3.1622777}\\] And so: \\[d = -0.4047715\\] Meaning that the effect size, to two decimal places, is d = -0.4. Determining Significance If we were to look at a critical values look-up table for \\(df = 9\\) and \\(\\alpha = .05\\) (two-tailed), we would see that the critical value is \\(t_{crit} = 2.262\\). Given that our t-value, ignoring polarity and just looking at the absolute value, so \\(t = 1.28\\), is smaller than our \\(t_{crit}\\) then we can say our result is not significant, and as such would be written up as t(9) = 1.28, p &gt; .05, d = 0.4. Remember: If you were writing this up as a report, and analysis the data in R, then you would see the p-value was actually p = 0.234, and would be written up as p = 0.234 4.2.3 DataSet 3 Let’s say that this is our starting data: Participants PreTest PostTest 1 78 71 2 60 53 3 76 73 4 56 52 5 62 56 6 73 69 7 61 58 8 70 65 9 52 52 10 65 64 Show me the working and answer The first thing we need to do is calculate the difference between the PostTest and the PreTest for each participant, based on \\(D = PostTest - PreTest\\). So for example: Participant 1 would be: 71 - 78 = -7 Participant 2 would be: 53 - 60 = -7 etc And if we do that for each Participant and added a column of the differences (\\(D\\)) then we would see: Participants PreTest PostTest D 1 78 71 -7 2 60 53 -7 3 76 73 -3 4 56 52 -4 5 62 56 -6 6 73 69 -4 7 61 58 -3 8 70 65 -5 9 52 52 0 10 65 64 -1 Now, the within-subjects t-test formula is: \\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\] We can see that \\(N = 10\\), but we need to calculate \\(\\bar{D}\\) (called D-Bar, the mean of the \\(D\\) column) and \\(SD_{D}\\). Calculating D-bar So the \\(\\bar{D}\\) formula is the same as the mean formula: \\[\\bar{D} = \\frac{\\sum{D}}{N}\\] Where \\(D\\) is \\(PostTest - PreTest\\) for each Participant. Then: \\[\\bar{D} = \\frac{(71 - 78) + (53 - 60) + (73 - 76) + (52 - 56) + (56 - 62) + \\\\ (69- 73) + (58 - 61) + (65 - 70) + (52 - 52) + (64 - 65)}{10}\\] Which if we resolve all the brackets becomes: \\[\\bar{D} = \\frac{-7 + -7 + -3 + -4 + -6 + -4 + -3 + -5 + 0 + 6}{10}\\] And if we sum the top half together \\[\\bar{D} = \\frac{-40}{10}\\] Leaving us with: \\[\\bar{D} = -4\\] So we find that \\(\\bar{D}\\) = -4, which is the mean difference between the Post test and Pre test values. The Standard Deviation of D The standard deviation formula is: \\[SD = \\sqrt\\frac{(X - \\bar{X})^2}{N-1}\\] Which if we translate to using D, becomes: \\[SD_{D} = \\sqrt\\frac{(D - \\bar{D})^2}{N-1}\\] Then: \\[SD_{D} =\\sqrt\\frac{(-7 - -4)^2 + (-7 - -4)^2 + (-3 - -4)^2 + (-4 - -4)^2 + (-6 - -4)^2 + \\\\ (-4 - -4)^2 + (-3 - -4)^2 + (-5 - -4)^2 + (0 - -4)^2 + (-1 - -4)^2}{10 - 1}\\] And if we start stepping through this analysis by dealing with the brackets: \\[SD_{D} =\\sqrt\\frac{(-3)^2 + (-3)^2 + (1)^2 + (0)^2 + (-2)^2 + \\\\ (0)^2 + (1)^2 + (-1)^2 + (4)^2 + (3)^2}{10 - 1}\\] And then we square those brackets \\[SD_{D} =\\sqrt\\frac{9 + 9 + 1 + 0 + 4 + 0 + 1 + 1 + 16 + 9}{10 - 1}\\] And sum up all the values on the top half: \\[SD_{D} =\\sqrt\\frac{50}{10 - 1}\\] And then we need to sort out the bottom half \\[SD_{D} =\\sqrt\\frac{50}{9}\\] Which by dividing the top half by the bottom half reduces down to: \\[SD_{D} =\\sqrt{5.5555556}\\] And then we finally take the square root, which leaves us with: \\[SD_{D} =2.3570226\\] And so we find that the \\(SD_{D}\\) = 2.3570226 which to two decimal places would be, \\(SD_{D} = 2.36\\) Calculating the t-value And finally the t-test formula is: \\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\] Then if we start filling in the values we know from above we see: \\[t = \\frac{-4}{\\frac{2.3570226}{\\sqrt{10}}} \\] And if we deal with the square root first: \\[t = \\frac{-4}{\\frac{2.3570226}{3.1622777}} \\] And divide \\(SD_{D}\\) by \\(\\sqrt{N}\\) - tidying up the bottom of the formula: \\[t = \\frac{-4}{0.745356} \\] And then solve for \\(t\\) by dividing the top half by the bottom half gives us: \\[t = -5.3665631 \\] And so, rounding to two decimal places, we find that \\(t = -5.37\\) Degrees of Freedom Great! Now we just need the degrees of freedom where the formula is: \\[df = N - 1\\] And we already know that \\(N= 10\\) and putting them into the equation we get: \\[df = 10 - 1\\] Which reduces to: \\[df = 9\\] Meaning that we find a \\(df = 9\\) Effect Size - Cohen’s d And finally Cohen’s d, the effect size. One of the common formulas based on knowing the t-value and the N is: \\[d = \\frac{t}{\\sqrt{N}}\\] Which, based on the info above, we know: \\(t = -5.37\\) \\(N = 10\\) And putting those into the formula we get: \\[d = \\frac{-5.37}{\\sqrt{10}}\\] Which gives us: \\[d = \\frac{-5.37}{3.1622777}\\] And so: \\[d = -1.6981431\\] Meaning that the effect size, to two decimal places, is d = -1.7. Determining Significance If we were to look at a critical values look-up table for \\(df = 9\\) and \\(\\alpha = .05\\) (two-tailed), we would see that the critical value is \\(t_{crit} = 2.262\\). Given that our t-value, ignoring polarity and just looking at the absolute value, so \\(t = 5.37\\), is equal to or larger than our \\(t_{crit}\\) then we can say our result is not significant, and as such would be written up as t(9) = 5.37, p &lt; .05, d = 1.7. Remember: If you were writing this up as a report, and analysis the data in R, then you would see the p-value was actually p = 0, and would be written up as p &lt; .001 4.3 Look-Up table Remembering that the \\(t_{crit}\\) value is the smallest t-value you need to find a significant effect, find the \\(t_{crit}\\) for your df, assuming \\(\\alpha = .05\\). If the \\(t\\) value you calculated is equal to or larger than \\(t_{crit}\\) then your test is significant. df \\(\\alpha = .05\\) 1 12.706 2 4.303 3 3.182 4 2.776 5 2.571 6 2.447 7 2.365 8 2.306 9 2.262 10 2.228 15 2.131 20 2.086 30 2.042 40 2.021 50 2.009 60 2 70 1.994 80 1.99 90 1.987 100 1.984 "],
["references.html", "Chapter 5 References", " Chapter 5 References "]
]
