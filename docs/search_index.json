[
["index.html", "A Handy Workbook for Research Methods and Statistics Overview", " A Handy Workbook for Research Methods and Statistics Last Update: 2020-12-07 Overview PLEASE NOTE THIS BOOK IS IN EARLY STAGES OF DEVELOPMENT AND MAY VERY WELL CONTAIN MISTAKES Authors: Phil McAleer Aim: A Handy Workbook to help students understand Research Methods and Statistics through worked examples and self-tests. Contact: This book is a living document and will be regularly checked and updated for improvements. Should you have any issues using the book or queries, please contact Phil McAleer. R Version: This book has been written with R version 3.5.1 (2018-07-02) Randomising Seed: In chapters that use some level of randomisation, where we have remembered, the seed is set as 1409. "],
["one-sample-chi-square.html", "Chapter 1 One-Sample Chi-Square 1.1 The Worked Example 1.2 Test Yourself 1.3 ChiSquare Look-up Table", " Chapter 1 One-Sample Chi-Square 1.1 The Worked Example Here is our data: Values A B C D Observed 4 5 8 15 And if we add on a column showing the total number of participants, adding all the numbers in the different conditions together, (i.e. 4 + 5 + 8 + 15 = 32), then we get: Values A B C D Total Observed 4 5 8 15 32 Now the formula for the chi-square is: \\[x^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] The Expected values for each condition, in a one-sample chi-square assuming a uniform (equal) distribution is calculated by \\(N \\times \\frac{1}{k}\\) where \\(k\\) is the number of conditions and \\(N\\) is the total number of participants. This can also be written more straightforward as \\(N/k\\). That means that in our example the expected value in each condition would be: \\[Expected = \\frac{N}{k} = \\frac{32}{4} = 8\\] Let’s now add those Expected values to our table which looks like: Values A B C D Total Observed 4 5 8 15 32 Expected 8 8 8 8 32 We now have our data, let’s start putting it into the formula, which we said was: \\[x^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] Which really means: \\[x^2 = \\frac{(Observed_{A} - Expected_{A})^2}{Expected_{A}} + \\frac{(Observed_{B} - Expected_{B})^2}{Expected_{B}} + \\frac{(Observed_{C} - Expected_{C})^2}{Expected_{C}} + \\\\ \\frac{(Observed_{D} - Expected_{D})^2}{Expected_{D}}\\] So \\[x^2 = \\frac{(4 - 8)^2}{8}+\\frac{(5 - 8)^2}{8}+\\frac{(8 - 8)^2}{8}+\\frac{(15 - 8)^2}{8}\\] Which becomes: \\[x^2 = \\frac{(-4)^2}{8} + \\frac{(-3)^2}{8} + \\frac{(0)^2}{8} + \\frac{(7)^2}{8}\\] And if we now square the top halves (the numerators): \\[x^2 = \\frac{16}{8} + \\frac{9}{8} + \\frac{0}{8} + \\frac{49}{8}\\] Then divide the top half by the bottom half for each condition: \\[x^2 = {2}+{1.125}+{0}+{6.125}\\] And finally add them altogether \\[x^2 = 9.25\\] So we find that \\(x^2 = 9.25\\) The degrees of freedom in this test is \\(k - 1\\) and given that we have 4 conditions: \\[df = k - 1\\] \\[df = 4 - 1\\] \\[df = 3\\] The effect size A common effect size for the one-sample chi-square test is \\(\\phi\\) (pronounced “ph-aye” and can be written as “phi”). The formula for \\(\\phi\\) is: \\[\\phi = \\frac{\\chi^2}{N}\\] And if we know that \\(\\chi^2 =9.25\\) and that \\(N = 32\\), then putting them into the formula we get: \\[\\phi = \\frac{9.25}{32}\\] \\[\\phi = 0.2890625\\] The write-up If we were to look at a critical value look-up table, we would see that the critical value associated with a \\(df = 3\\) at \\(\\alpha = .05\\), to three decimal places, is \\(x^2_{crit} = 7.815\\). As the chi-square value of this test (i.e. \\(x^2 = 9.25\\)) is larger than \\(x^2_{crit}\\) then we can say that our test is significant, and as such would be written up as \\(x^2(df = 3, N = 32) = 9.25,p &lt; .05\\). Finally, if our test was significant then all we need to do is state the condition with the highest frequency (i.e. the mode), which in this case is Condition D 1.2 Test Yourself 1.2.1 DataSet 1 Here is our data: Values A B C D Observed 14 19 2 20 Show me the working and answer And if we add on a column showing the total number of participants, adding all the numbers in the different conditions together, (i.e. 14 + 19 + 2 + 20 = 55), then we get: Values A B C D Total Observed 14 19 2 20 55 Now the formula for the chi-square is: \\[x^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] The Expected values for each condition, in a one-sample chi-square assuming a uniform (equal) distribution is calculated by \\(N \\times \\frac{1}{k}\\) where \\(k\\) is the number of conditions and \\(N\\) is the total number of participants. This can also be written more straightforward as \\(N/k\\). That means that in our example the expected value in each condition would be: \\[Expected = \\frac{N}{k} = \\frac{55}{4} = 13.75\\] Let’s now add those Expected values to our table which looks like: Values A B C D Total Observed 14.00 19.00 2.00 20.00 55 Expected 13.75 13.75 13.75 13.75 55 We now have our data, let’s start putting it into the formula, which we said was: \\[x^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] So \\[x^2 = \\frac{(14 - 13.75)^2}{13.75}+\\frac{(19 - 13.75)^2}{13.75}+\\frac{(2 - 13.75)^2}{13.75}+\\frac{(20 - 13.75)^2}{13.75}\\] Which becomes: \\[x^2 = \\frac{(0.25)^2}{13.75} + \\frac{(5.25)^2}{13.75} + \\frac{(-11.75)^2}{13.75} + \\frac{(6.25)^2}{13.75}\\] And if we now square the top halves (the numerators): \\[x^2 = \\frac{0.0625}{13.75} + \\frac{27.5625}{13.75} + \\frac{138.0625}{13.75} + \\frac{39.0625}{13.75}\\] Then divide the top half by the bottom half for each condition: \\[x^2 = {0.0045455}+{2.0045455}+{10.0409091}+{2.8409091}\\] And finally add them altogether \\[x^2 = 14.8909091\\] So we find that \\(x^2 = 14.8909091\\) The degrees of freedom in this test is \\(k - 1\\) and given that we have 4 conditions: \\[df = k - 1\\] \\[df = 4 - 1\\] \\[df = 3\\] The effect size A common effect size for the one-sample chi-square test is \\(\\phi\\) (pronounced “ph-aye” and can be written as “phi”). The formula for \\(\\phi\\) is: \\[\\phi = \\frac{\\chi^2}{N}\\] And if we know that \\(\\chi^2 =14.8909091\\) and that \\(N = 55\\), then putting them into the formula we get: \\[\\phi = \\frac{14.8909091}{55}\\] \\[\\phi = 0.2707438\\] The write-up If we were to look at a critical value look-up table, we would see that the critical value associated with a \\(df = 3\\) at \\(\\alpha = .05\\), to three decimal places, is \\(x^2_{crit} = 7.815\\). As the chi-square value of this test (i.e. \\(x^2 = 14.8909091\\)) is larger than \\(x^2_{crit}\\) then we can say that our test is significant, and as such would be written up as \\(x^2(df = 3, N = 55) = 14.8909091,p &lt; .05\\). Finally, if our test was significant then all we need to do is state the condition with the highest frequency (i.e. the mode), which in this case is Condition D 1.2.2 DataSet 2 Here is our data: Values A B C D Observed 2 8 7 20 Show me the working and answer And if we add on a column showing the total number of participants, adding all the numbers in the different conditions together, (i.e. 2 + 8 + 7 + 20 = 37), then we get: Values A B C D Total Observed 2 8 7 20 37 Now the formula for the chi-square is: \\[x^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] The Expected values for each condition, in a one-sample chi-square assuming a uniform (equal) distribution is calculated by \\(N \\times \\frac{1}{k}\\) where \\(k\\) is the number of conditions and \\(N\\) is the total number of participants. This can also be written more straightforward as \\(N/k\\). That means that in our example the expected value in each condition would be: \\[Expected = \\frac{N}{k} = \\frac{37}{4} = 9.25\\] Let’s now add those Expected values to our table which looks like: Values A B C D Total Observed 2.00 8.00 7.00 20.00 37 Expected 9.25 9.25 9.25 9.25 37 We now have our data, let’s start putting it into the formula, which we said was: \\[x^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] So \\[x^2 = \\frac{(2 - 9.25)^2}{9.25}+\\frac{(8 - 9.25)^2}{9.25}+\\frac{(7 - 9.25)^2}{9.25}+\\frac{(20 - 9.25)^2}{9.25}\\] Which becomes: \\[x^2 = \\frac{(-7.25)^2}{9.25} + \\frac{(-1.25)^2}{9.25} + \\frac{(-2.25)^2}{9.25} + \\frac{(10.75)^2}{9.25}\\] And if we now square the top halves (the numerators): \\[x^2 = \\frac{52.5625}{9.25} + \\frac{1.5625}{9.25} + \\frac{5.0625}{9.25} + \\frac{115.5625}{9.25}\\] Then divide the top half by the bottom half for each condition: \\[x^2 = {5.6824324}+{0.1689189}+{0.5472973}+{12.4932432}\\] And finally add them altogether \\[x^2 = 18.8918919\\] So we find that \\(x^2 = 18.8918919\\) The degrees of freedom in this test is \\(k - 1\\) and given that we have 4 conditions: \\[df = k - 1\\] \\[df = 4 - 1\\] \\[df = 3\\] The effect size A common effect size for the one-sample chi-square test is \\(\\phi\\) (pronounced “ph-aye” and can be written as “phi”). The formula for \\(\\phi\\) is: \\[\\phi = \\frac{\\chi^2}{N}\\] And if we know that \\(\\chi^2 =18.8918919\\) and that \\(N = 37\\), then putting them into the formula we get: \\[\\phi = \\frac{18.8918919}{37}\\] \\[\\phi = 0.5105917\\] The write-up If we were to look at a critical value look-up table, we would see that the critical value associated with a \\(df = 3\\) at \\(\\alpha = .05\\), to three decimal places, is \\(x^2_{crit} = 7.815\\). As the chi-square value of this test (i.e. \\(x^2 = 18.8918919\\)) is larger than \\(x^2_{crit}\\) then we can say that our test is significant, and as such would be written up as \\(x^2(df = 3, N = 37) = 18.8918919,p &lt; .05\\). Finally, if our test was significant then all we need to do is state the condition with the highest frequency (i.e. the mode), which in this case is Condition D 1.2.3 DataSet 3 Here is our data: Values A B C D Observed 5 10 14 11 Show me the working and answer And if we add on a column showing the total number of participants, adding all the numbers in the different conditions together, (i.e. 5 + 10 + 14 + 11 = 40), then we get: Values A B C D Total Observed 5 10 14 11 40 Now the formula for the chi-square is: \\[x^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] The Expected values for each condition, in a one-sample chi-square assuming a uniform (equal) distribution is calculated by \\(N \\times \\frac{1}{k}\\) where \\(k\\) is the number of conditions and \\(N\\) is the total number of participants. This can also be written more straightforward as \\(N/k\\). That means that in our example the expected value in each condition would be: \\[Expected = \\frac{N}{k} = \\frac{40}{4} = 10\\] Let’s now add those Expected values to our table which looks like: Values A B C D Total Observed 5 10 14 11 40 Expected 10 10 10 10 40 We now have our data, let’s start putting it into the formula, which we said was: \\[x^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] So \\[x^2 = \\frac{(5 - 10)^2}{10}+\\frac{(10 - 10)^2}{10}+\\frac{(14 - 10)^2}{10}+\\frac{(11 - 10)^2}{10}\\] Which becomes: \\[x^2 = \\frac{(-5)^2}{10} + \\frac{(0)^2}{10} + \\frac{(4)^2}{10} + \\frac{(1)^2}{10}\\] And if we now square the top halves (the numerators): \\[x^2 = \\frac{25}{10} + \\frac{0}{10} + \\frac{16}{10} + \\frac{1}{10}\\] Then divide the top half by the bottom half for each condition: \\[x^2 = {2.5}+{0}+{1.6}+{0.1}\\] And finally add them altogether \\[x^2 = 4.2\\] So we find that \\(x^2 = 4.2\\) The degrees of freedom in this test is \\(k - 1\\) and given that we have 4 conditions: \\[df = k - 1\\] \\[df = 4 - 1\\] \\[df = 3\\] The effect size A common effect size for the one-sample chi-square test is \\(\\phi\\) (pronounced “ph-aye” and can be written as “phi”). The formula for \\(\\phi\\) is: \\[\\phi = \\frac{\\chi^2}{N}\\] And if we know that \\(\\chi^2 =4.2\\) and that \\(N = 40\\), then putting them into the formula we get: \\[\\phi = \\frac{4.2}{40}\\] \\[\\phi = 0.105\\] The write-up If we were to look at a critical value look-up table, we would see that the critical value associated with a \\(df = 3\\) at \\(\\alpha = .05\\), to three decimal places, is \\(x^2_{crit} = 7.815\\). As the chi-square value of this test (i.e. \\(x^2 = 4.2\\)) is smaller than \\(x^2_{crit}\\) then we can say that our test is non-significant, and as such would be written up as \\(x^2(df = 3, N = 40) = 4.2,p &gt; .05\\). Finally, if our test was significant then all we need to do is state the condition with the highest frequency (i.e. the mode), which in this case is Condition C 1.3 ChiSquare Look-up Table df \\(\\alpha = .05\\) 1 3.841 2 5.991 3 7.815 4 9.488 5 11.07 6 12.592 7 14.067 8 15.507 9 16.919 10 18.307 "],
["between-subjects-students-t-test.html", "Chapter 2 Between-Subjects Student’s t-test 2.1 The Worked Example 2.2 Test Yourself 2.3 Look-Up table", " Chapter 2 Between-Subjects Student’s t-test 2.1 The Worked Example Here is your data: Group N Mean SD A 47 26.45 2.44 B 47 28.38 2.88 Let’s look at the main t-test formula: \\[t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p \\times \\sqrt{\\frac{1}{N_1} + \\frac{1}{N_2}}}\\] Now, from the table above we know: the mean of Group A is \\(\\bar{X_1} = 26.45\\), the mean of Group B is \\(\\bar{X_2} = 28.38\\), the N of Group A is \\(N_1 = 47\\), and the N of Group B is \\(N_2 = 47\\), which we can put into the equation right now: \\[t = \\frac{26.45 - 28.38}{s_p \\times \\sqrt{\\frac{1}{47} + \\frac{1}{47}}}\\] And now we can see that the only thing we don’t yet know is the pooled standard deviation (\\(s_p\\)). Let’s look at that formula: \\[s_p = \\sqrt{\\frac{(n_1 -1) \\times s^2_{X_1} + (n_2 -1)\\times s^2_{X_2}}{n_1 + n_2 - 2}}\\] And if we start to fill in some details: \\[s_p = \\sqrt{\\frac{(47 -1) \\times s^2_{X_1} + (47 -1)\\times s^2_{X_2}}{47 + 47 - 2}}\\] Now looking at the formula, it is clear we are missing: \\(s^2_{X_1}\\) - the variance of Group A (could be written as \\(s^2_{A}\\)) \\(s^2_{X_2}\\) - the variance of Group B (could be written as \\(s^2_{B}\\)) What we do know though, from the table, is the standard deviations of both groups (\\(SD_A\\) = 2.44; \\(SD_B\\) = 2.88), and we know that variance of a group is equal to the standard deviation squared. So: \\(s^2_{X_1}\\) = \\(s^2_A\\) = \\(SD_A \\times SD_A\\) = \\(2.44 \\times 2.44\\) = \\(5.9536\\) \\(s^2_{X_2}\\) = \\(s^2_B\\) = \\(SD_B \\times SD_B\\) = \\(2.88 \\times 2.88\\) = \\(8.2944\\) And if we now add those values to our formula we get: \\[s_p = \\sqrt{\\frac{(47 -1) \\times 5.9536 + (47 -1)\\times 8.2944}{47 + 47 - 2}}\\] And we can then start working through the formula, taking each stage in turn to make sure we don’t make mistakes. Let’s get rid of the brackets first: \\[s_p = \\sqrt{\\frac{(46 \\times 5.9536) + (46 \\times 8.2944)}{92}}\\] Now we deal with the multiplications: \\[s_p = \\sqrt{\\frac{273.8656 + 381.5424}{92}}\\] Let’s tidy up that top half of the equation (the numerator): \\[s_p = \\sqrt{\\frac{655.408}{92}}\\] Which if we then divide the numerator by the denominator (the bottom half), and then take the square root of that we get: \\[s_p = \\sqrt{7.124}\\] Giving a pooled standard deviation of: \\[s_p = 2.6690822\\] Meaning that our pooled standard deviation, rounded to three decimal places, is \\(s_p = 2.669\\) and we can now add that to the t-test formula to give us: \\[t = \\frac{26.45 - 28.38}{2.669 \\times \\sqrt{\\frac{1}{47} + \\frac{1}{47}}}\\] And again we just start working through the formula. Let’s deal with the fractions relating to sample size first: \\[t = \\frac{26.45 - 28.38}{2.669 \\times \\sqrt{0.0212766 + 0.0212766}}\\] Which we can tidy up a little to give: \\[t = \\frac{-1.93}{2.669 \\times \\sqrt{0.0425532}}\\] And if we sort out the square root on the denominator we are left with: \\[t = \\frac{-1.93}{2.669 \\times 0.2062842}\\] We can then tidy up the denominator to give us: \\[t = \\frac{-1.93}{0.5505727}\\] Which we can finally solve to give us a t-value, rounded to two decimal places, of \\(t = -3.51\\) Great! Now we just need the degrees of freedom where the formula is: \\[df = (n_1 - 1) + (n_2 - 1)\\] And we already know that: the N of Group A is \\(N_1 = 47\\), and the N of Group B is \\(N_2 = 47\\), So putting them into the equation we get: \\[df = (47 - 1) + (47 - 1)\\] \\[df = 46 + 46\\] \\[df = 92\\] And finally Cohen’s d, the effect size: \\[d = \\frac{2t}{\\sqrt{df}}\\] Which, based on the info above, we know: \\(t = -3.51\\) \\(df = 92\\) Putting them into the formula we get: \\[d = \\frac{2 \\times -3.51}{\\sqrt{92}}\\] And if we tidy the nominator and the denominator we get: \\[d = \\frac{-7.02}{9.591663}\\] Which we can then resolve to learn that \\(d = -0.73\\) Determining Significance If we were to look at a critical values look-up table for \\(df = 92\\) and \\(\\alpha = .05\\) (two-tailed), we would see that the critical value is \\(t_{crit} = 1.986\\). Given that our t-value, ignoring polarity and just looking at the absolute value, so \\(t = 3.51\\), is equal to or larger than our \\(t_{crit}\\) then we can say our result is significant, and as such would be written up as t(92) = 3.51, p &lt; .05, d = 0.73 Remember: If you were writing this up as a report, and analysis the data in R, then you would see the p-value was actually p = 6.959109810^{-4}, and would be written up as p &lt; .001 2.2 Test Yourself 2.2.1 Example 1 Here is your data: Group N Mean SD A 48 13.13 2.28 B 48 14.06 2.43 Show me the answer Let’s look at the main t-test formula: \\[t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p \\times \\sqrt{\\frac{1}{N_1} + \\frac{1}{N_2}}}\\] Now, from the table above we know: the mean of Group A is \\(\\bar{X_1} = 13.13\\), the mean of Group B is \\(\\bar{X_2} = 14.06\\), the N of Group A is \\(N_1 = 48\\), and the N of Group B is \\(N_2 = 48\\), which we can put into the equation right now: \\[t = \\frac{13.13 - 14.06}{s_p \\times \\sqrt{\\frac{1}{48} + \\frac{1}{48}}}\\] And now we can see that the only thing we don’t yet know is the pooled standard deviation (\\(s_p\\)). Let’s look at that formula: \\[s_p = \\sqrt{\\frac{(n_1 -1) \\times s^2_{X_1} + (n_2 -1)\\times s^2_{X_2}}{n_1 + n_2 - 2}}\\] And if we start to fill in some details: \\[s_p = \\sqrt{\\frac{(48 -1) \\times s^2_{X_1} + (48 -1)\\times s^2_{X_2}}{48 + 48 - 2}}\\] Now looking at the formula, it is clear we are missing: \\(s^2_{X_1}\\) - the variance of Group A (could be written as \\(s^2_{A}\\)) \\(s^2_{X_2}\\) - the variance of Group B (could be written as \\(s^2_{B}\\)) What we do know though, from the table, is the standard deviations of both groups (\\(SD_A\\) = 2.28; \\(SD_B\\) = 2.43), and we know that variance of a group is equal to the standard deviation squared. So: \\(s^2_{X_1}\\) = \\(s^2_A\\) = \\(SD_A \\times SD_A\\) = \\(2.28 \\times 2.28\\) = \\(5.1984\\) \\(s^2_{X_2}\\) = \\(s^2_B\\) = \\(SD_B \\times SD_B\\) = \\(2.43 \\times 2.43\\) = \\(5.9049\\) And if we now add those values to our formula we get: \\[s_p = \\sqrt{\\frac{(48 -1) \\times 5.1984 + (48 -1)\\times 5.9049}{48 + 48 - 2}}\\] And we can then start working through the formula, taking each stage in turn to make sure we don’t make mistakes. Let’s get rid of the brackets first: \\[s_p = \\sqrt{\\frac{(47 \\times 5.1984) + (47 \\times 5.9049)}{94}}\\] Now we deal with the multiplications: \\[s_p = \\sqrt{\\frac{244.3248 + 277.5303}{94}}\\] Let’s tidy up that top half of the equation (the numerator): \\[s_p = \\sqrt{\\frac{521.8551}{94}}\\] Which if we then divide the numerator by the denominator (the bottom half), and then take the square root of that we get: \\[s_p = \\sqrt{5.55165}\\] Giving a pooled standard deviation of: \\[s_p = 2.356194\\] Meaning that our pooled standard deviation, rounded to three decimal places, is \\(s_p = 2.356\\) and we can now add that to the t-test formula to give us: \\[t = \\frac{13.13 - 14.06}{2.356 \\times \\sqrt{\\frac{1}{48} + \\frac{1}{48}}}\\] And again we just start working through the formula. Let’s deal with the fractions relating to sample size first: \\[t = \\frac{13.13 - 14.06}{2.356 \\times \\sqrt{0.0208333 + 0.0208333}}\\] Which we can tidy up a little to give: \\[t = \\frac{-0.93}{2.356 \\times \\sqrt{0.0416667}}\\] And if we sort out the square root on the denominator we are left with: \\[t = \\frac{-0.93}{2.356 \\times 0.2041241}\\] We can then tidy up the denominator to give us: \\[t = \\frac{-0.93}{0.4809165}\\] Which we can finally solve to give us a t-value, rounded to two decimal places, of \\(t = -1.93\\) Great! Now we just need the degrees of freedom where the formula is: \\[df = (n_1 - 1) + (n_2 - 1)\\] And we already know that: the N of Group A is \\(N_1 = 48\\), and the N of Group B is \\(N_2 = 48\\), So putting them into the equation we get: \\[df = (48 - 1) + (48 - 1)\\] \\[df = 47 + 47\\] \\[df = 94\\] And finally Cohen’s d, the effect size: \\[d = \\frac{2t}{\\sqrt{df}}\\] Which, based on the info above, we know: \\(t = -1.93\\) \\(df = 94\\) Putting them into the formula we get: \\[d = \\frac{2 \\times -1.93}{\\sqrt{94}}\\] And if we tidy the nominator and the denominator we get: \\[d = \\frac{-3.86}{9.6953597}\\] Which we can then resolve to learn that \\(d = -0.4\\) Determining Significance If we were to look at a critical values look-up table for \\(df = 94\\) and \\(\\alpha = .05\\) (two-tailed), we would see that the critical value is \\(t_{crit} = 1.986\\). Given that our t-value, ignoring polarity and just looking at the absolute value, so \\(t = 1.93\\), is smaller than our \\(t_{crit}\\) then we can say our result is non-significant, and as such would be written up as t(94) = 1.93, p &gt; .05, d = 0.4 Remember: If you were writing this up as a report, and analysis the data in R, then you would see the p-value was actually p = 0.0566217, and would be written up as p = 0.057 2.2.2 Example 2 Here is your data: Group N Mean SD A 17 12.93 1.33 B 17 12.47 1.67 Show me the answer Let’s look at the main t-test formula: \\[t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p \\times \\sqrt{\\frac{1}{N_1} + \\frac{1}{N_2}}}\\] Now, from the table above we know: the mean of Group A is \\(\\bar{X_1} = 12.93\\), the mean of Group B is \\(\\bar{X_2} = 12.47\\), the N of Group A is \\(N_1 = 17\\), and the N of Group B is \\(N_2 = 17\\), which we can put into the equation right now: \\[t = \\frac{12.93 - 12.47}{s_p \\times \\sqrt{\\frac{1}{17} + \\frac{1}{17}}}\\] And now we can see that the only thing we don’t yet know is the pooled standard deviation (\\(s_p\\)). Let’s look at that formula: \\[s_p = \\sqrt{\\frac{(n_1 -1) \\times s^2_{X_1} + (n_2 -1)\\times s^2_{X_2}}{n_1 + n_2 - 2}}\\] And if we start to fill in some details: \\[s_p = \\sqrt{\\frac{(17 -1) \\times s^2_{X_1} + (17 -1)\\times s^2_{X_2}}{17 + 17 - 2}}\\] Now looking at the formula, it is clear we are missing: \\(s^2_{X_1}\\) - the variance of Group A (could be written as \\(s^2_{A}\\)) \\(s^2_{X_2}\\) - the variance of Group B (could be written as \\(s^2_{B}\\)) What we do know though, from the table, is the standard deviations of both groups (\\(SD_A\\) = 1.33; \\(SD_B\\) = 1.67), and we know that variance of a group is equal to the standard deviation squared. So: \\(s^2_{X_1}\\) = \\(s^2_A\\) = \\(SD_A \\times SD_A\\) = \\(1.33 \\times 1.33\\) = \\(1.7689\\) \\(s^2_{X_2}\\) = \\(s^2_B\\) = \\(SD_B \\times SD_B\\) = \\(1.67 \\times 1.67\\) = \\(2.7889\\) And if we now add those values to our formula we get: \\[s_p = \\sqrt{\\frac{(17 -1) \\times 1.7689 + (17 -1)\\times 2.7889}{17 + 17 - 2}}\\] And we can then start working through the formula, taking each stage in turn to make sure we don’t make mistakes. Let’s get rid of the brackets first: \\[s_p = \\sqrt{\\frac{(16 \\times 1.7689) + (16 \\times 2.7889)}{32}}\\] Now we deal with the multiplications: \\[s_p = \\sqrt{\\frac{28.3024 + 44.6224}{32}}\\] Let’s tidy up that top half of the equation (the numerator): \\[s_p = \\sqrt{\\frac{72.9248}{32}}\\] Which if we then divide the numerator by the denominator (the bottom half), and then take the square root of that we get: \\[s_p = \\sqrt{2.2789}\\] Giving a pooled standard deviation of: \\[s_p = 1.5096026\\] Meaning that our pooled standard deviation, rounded to three decimal places, is \\(s_p = 1.51\\) and we can now add that to the t-test formula to give us: \\[t = \\frac{12.93 - 12.47}{1.51 \\times \\sqrt{\\frac{1}{17} + \\frac{1}{17}}}\\] And again we just start working through the formula. Let’s deal with the fractions relating to sample size first: \\[t = \\frac{12.93 - 12.47}{1.51 \\times \\sqrt{0.0588235 + 0.0588235}}\\] Which we can tidy up a little to give: \\[t = \\frac{0.46}{1.51 \\times \\sqrt{0.1176471}}\\] And if we sort out the square root on the denominator we are left with: \\[t = \\frac{0.46}{1.51 \\times 0.3429972}\\] We can then tidy up the denominator to give us: \\[t = \\frac{0.46}{0.5179257}\\] Which we can finally solve to give us a t-value, rounded to two decimal places, of \\(t = 0.89\\) Great! Now we just need the degrees of freedom where the formula is: \\[df = (n_1 - 1) + (n_2 - 1)\\] And we already know that: the N of Group A is \\(N_1 = 17\\), and the N of Group B is \\(N_2 = 17\\), So putting them into the equation we get: \\[df = (17 - 1) + (17 - 1)\\] \\[df = 16 + 16\\] \\[df = 32\\] And finally Cohen’s d, the effect size: \\[d = \\frac{2t}{\\sqrt{df}}\\] Which, based on the info above, we know: \\(t = 0.89\\) \\(df = 32\\) Putting them into the formula we get: \\[d = \\frac{2 \\times 0.89}{\\sqrt{32}}\\] And if we tidy the nominator and the denominator we get: \\[d = \\frac{1.78}{5.6568542}\\] Which we can then resolve to learn that \\(d = 0.31\\) Determining Significance If we were to look at a critical values look-up table for \\(df = 32\\) and \\(\\alpha = .05\\) (two-tailed), we would see that the critical value is \\(t_{crit} = 2.037\\). Given that our t-value, ignoring polarity and just looking at the absolute value, so \\(t = 0.89\\), is smaller than our \\(t_{crit}\\) then we can say our result is non-significant, and as such would be written up as t(32) = 0.89, p &gt; .05, d = 0.31 Remember: If you were writing this up as a report, and analysis the data in R, then you would see the p-value was actually p = 0.3801084, and would be written up as p = 0.377 2.2.3 Example 3 Here is your data: Group N Mean SD A 23 53.99 4.37 B 23 53.30 3.29 Show me the answer Let’s look at the main t-test formula: \\[t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p \\times \\sqrt{\\frac{1}{N_1} + \\frac{1}{N_2}}}\\] Now, from the table above we know: the mean of Group A is \\(\\bar{X_1} = 53.99\\), the mean of Group B is \\(\\bar{X_2} = 53.3\\), the N of Group A is \\(N_1 = 23\\), and the N of Group B is \\(N_2 = 23\\), which we can put into the equation right now: \\[t = \\frac{53.99 - 53.3}{s_p \\times \\sqrt{\\frac{1}{23} + \\frac{1}{23}}}\\] And now we can see that the only thing we don’t yet know is the pooled standard deviation (\\(s_p\\)). Let’s look at that formula: \\[s_p = \\sqrt{\\frac{(n_1 -1) \\times s^2_{X_1} + (n_2 -1)\\times s^2_{X_2}}{n_1 + n_2 - 2}}\\] And if we start to fill in some details: \\[s_p = \\sqrt{\\frac{(23 -1) \\times s^2_{X_1} + (23 -1)\\times s^2_{X_2}}{23 + 23 - 2}}\\] Now looking at the formula, it is clear we are missing: \\(s^2_{X_1}\\) - the variance of Group A (could be written as \\(s^2_{A}\\)) \\(s^2_{X_2}\\) - the variance of Group B (could be written as \\(s^2_{B}\\)) What we do know though, from the table, is the standard deviations of both groups (\\(SD_A\\) = 4.37; \\(SD_B\\) = 3.29), and we know that variance of a group is equal to the standard deviation squared. So: \\(s^2_{X_1}\\) = \\(s^2_A\\) = \\(SD_A \\times SD_A\\) = \\(4.37 \\times 4.37\\) = \\(19.0969\\) \\(s^2_{X_2}\\) = \\(s^2_B\\) = \\(SD_B \\times SD_B\\) = \\(3.29 \\times 3.29\\) = \\(10.8241\\) And if we now add those values to our formula we get: \\[s_p = \\sqrt{\\frac{(23 -1) \\times 19.0969 + (23 -1)\\times 10.8241}{23 + 23 - 2}}\\] And we can then start working through the formula, taking each stage in turn to make sure we don’t make mistakes. Let’s get rid of the brackets first: \\[s_p = \\sqrt{\\frac{(22 \\times 19.0969) + (22 \\times 10.8241)}{44}}\\] Now we deal with the multiplications: \\[s_p = \\sqrt{\\frac{420.1318 + 238.1302}{44}}\\] Let’s tidy up that top half of the equation (the numerator): \\[s_p = \\sqrt{\\frac{658.262}{44}}\\] Which if we then divide the numerator by the denominator (the bottom half), and then take the square root of that we get: \\[s_p = \\sqrt{14.9605}\\] Giving a pooled standard deviation of: \\[s_p = 3.8678806\\] Meaning that our pooled standard deviation, rounded to three decimal places, is \\(s_p = 3.868\\) and we can now add that to the t-test formula to give us: \\[t = \\frac{53.99 - 53.3}{3.868 \\times \\sqrt{\\frac{1}{23} + \\frac{1}{23}}}\\] And again we just start working through the formula. Let’s deal with the fractions relating to sample size first: \\[t = \\frac{53.99 - 53.3}{3.868 \\times \\sqrt{0.0434783 + 0.0434783}}\\] Which we can tidy up a little to give: \\[t = \\frac{0.69}{3.868 \\times \\sqrt{0.0869565}}\\] And if we sort out the square root on the denominator we are left with: \\[t = \\frac{0.69}{3.868 \\times 0.2948839}\\] We can then tidy up the denominator to give us: \\[t = \\frac{0.69}{1.140611}\\] Which we can finally solve to give us a t-value, rounded to two decimal places, of \\(t = 0.6\\) Great! Now we just need the degrees of freedom where the formula is: \\[df = (n_1 - 1) + (n_2 - 1)\\] And we already know that: the N of Group A is \\(N_1 = 23\\), and the N of Group B is \\(N_2 = 23\\), So putting them into the equation we get: \\[df = (23 - 1) + (23 - 1)\\] \\[df = 22 + 22\\] \\[df = 44\\] And finally Cohen’s d, the effect size: \\[d = \\frac{2t}{\\sqrt{df}}\\] Which, based on the info above, we know: \\(t = 0.6\\) \\(df = 44\\) Putting them into the formula we get: \\[d = \\frac{2 \\times 0.6}{\\sqrt{44}}\\] And if we tidy the nominator and the denominator we get: \\[d = \\frac{1.2}{6.6332496}\\] Which we can then resolve to learn that \\(d = 0.18\\) Determining Significance If we were to look at a critical values look-up table for \\(df = 44\\) and \\(\\alpha = .05\\) (two-tailed), we would see that the critical value is \\(t_{crit} = 2.015\\). Given that our t-value, ignoring polarity and just looking at the absolute value, so \\(t = 0.6\\), is smaller than our \\(t_{crit}\\) then we can say our result is non-significant, and as such would be written up as t(44) = 0.6, p &gt; .05, d = 0.18 Remember: If you were writing this up as a report, and analysis the data in R, then you would see the p-value was actually p = 0.551584, and would be written up as p = 0.543 2.3 Look-Up table Remembering that the \\(t_{crit}\\) value is the smallest t-value you need to find a significant effect, find the \\(t_{crit}\\) for your df, assuming \\(\\alpha = .05\\). If the \\(t-value\\) you calculated is equal to or larger than \\(t_{crit}\\) then your test is significant. df \\(\\alpha = .05\\) 5 2.571 10 2.228 15 2.131 20 2.086 30 2.042 40 2.021 50 2.009 60 2 70 1.994 80 1.99 90 1.987 100 1.984 "],
["within-subjects-t-test.html", "Chapter 3 Within-Subjects t-test 3.1 The Worked Example 3.2 Test Yourself 3.3 Look-Up table", " Chapter 3 Within-Subjects t-test 3.1 The Worked Example Let’s say that this is our starting data: Participants PreTest PostTest 1 60 68 2 64 75 3 56 62 4 82 85 5 74 73 6 79 85 7 63 64 8 59 59 9 72 73 10 66 70 The first thing we need to do is calculate the difference between the PostTest and the PreTest for each participant, based on \\(D = PostTest - PreTest\\). So for example: Participant 1 would be: 68 - 60 = 8 Participant 2 would be: 75 - 64 = 11 etc And if we do that for each Participant and added a column of the differences (\\(D\\)) then we would see: Participants PreTest PostTest D 1 60 68 8 2 64 75 11 3 56 62 6 4 82 85 3 5 74 73 -1 6 79 85 6 7 63 64 1 8 59 59 0 9 72 73 1 10 66 70 4 Now, the within-subjects t-test formula is: \\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\] We can see that \\(N = 10\\), but we need to calculate \\(\\bar{D}\\) (called D-Bar, the mean of the \\(D\\) column) and \\(SD_{D}\\). So the \\(\\bar{D}\\) formula is the same as the mean formula: \\[\\bar{D} = \\frac{\\sum{D}}{N}\\] Where \\(D\\) is \\(PostTest - PreTest\\) for each Participant. Then: \\[\\bar{D} = \\frac{(68 - 60) + (75 - 64) + (62 - 56) + (85 - 82) + (73 - 74) + \\\\ (85- 79) + (64 - 63) + (59 - 59) + (73 - 72) + (70 - 66)}{10}\\] \\[\\bar{D} = \\frac{8 + 11 + 6 + 3 + -1 + 6 + 1 + 0 + 1 + 2}{10}\\] \\[\\bar{D} = \\frac{39}{10}\\] \\[\\bar{D} = 3.9\\] So we find that \\(\\bar{D}\\) = 3.9 The standard deviation formula is: \\[SD = \\sqrt\\frac{(X - \\bar{X})^2}{N-1}\\] Which if we translate to using D, becomes: \\[SD_{D} = \\sqrt\\frac{(D - \\bar{D})^2}{N-1}\\] Then: \\[SD_{D} =\\sqrt\\frac{(8 - 3.9)^2 + (11 - 3.9)^2 + (6 - 3.9)^2 + (3 - 3.9)^2 + (-1 - 3.9)^2 + \\\\ (6 - 3.9)^2 + (1 - 3.9)^2 + (0 - 3.9)^2 + (1 - 3.9)^2 + (4 - 3.9)^2}{10 - 1}\\] \\[SD_{D} =\\sqrt\\frac{(4.1)^2 + (7.1)^2 + (2.1)^2 + (-0.9)^2 + (-4.9)^2 + (2.1)^2 + (-2.9)^2 + (-3.9)^2 + (-2.9)^2 + (0.1)^2}{10 - 1}\\] \\[SD_{D} =\\sqrt\\frac{16.81 + 50.41 + 4.41 + 0.81 + 24.01 + 4.41 + 8.41 + 15.21 + 8.41 + 0.01}{10 - 1}\\] \\[SD_{D} =\\sqrt\\frac{132.9}{10 - 1}\\] \\[SD_{D} =\\sqrt\\frac{132.9}{9}\\] \\[SD_{D} =\\sqrt{14.7666667}\\] \\[SD_{D} =3.8427421\\] And the \\(SD_{D}\\) = 3.8427421 And the t-test formula is: \\[t = \\frac{\\bar{D}}{\\frac{SD_{D}}{\\sqrt{N}}}\\] Then: \\[t = \\frac{3.9}{\\frac{3.8427421}{\\sqrt{10}}} \\] \\[t = \\frac{3.9}{\\frac{3.8427421}{3.1622777}} \\] \\[t = \\frac{3.9}{1.2151817} \\] \\[t = 3.2093965 \\] And so \\(t = 3.21\\) 3.2 Test Yourself 3.3 Look-Up table Remembering that the \\(t_{crit}\\) value is the smallest t-value you need to find a significant effect, find the \\(t_{crit}\\) for your df, assuming \\(\\alpha = .05\\). If the \\(t-value\\) you calculated is equal to or larger than \\(t_{crit}\\) then your test is significant. df \\(\\alpha = .05\\) 5 2.571 10 2.228 15 2.131 20 2.086 30 2.042 40 2.021 50 2.009 60 2 70 1.994 80 1.99 90 1.987 100 1.984 "],
["references.html", "Chapter 4 References", " Chapter 4 References "]
]
